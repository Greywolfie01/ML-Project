{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin by importing all required libraries\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_decision_forests as tfdf\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data format:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
       "0          0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
       "1        109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
       "2         43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
       "3          0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
       "4        303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
       "\n",
       "   Transported  \n",
       "0        False  \n",
       "1         True  \n",
       "2        False  \n",
       "3        False  \n",
       "4         True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame used for trees:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Transported</th>\n",
       "      <th>Deck</th>\n",
       "      <th>Side</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>24.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>58.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>16.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HomePlanet  CryoSleep  Destination   Age  RoomService  FoodCourt  \\\n",
       "0           1          0            2  39.0          0.0        0.0   \n",
       "1           0          0            2  24.0        109.0        9.0   \n",
       "2           1          0            2  58.0         43.0     3576.0   \n",
       "3           1          0            2  33.0          0.0     1283.0   \n",
       "4           0          0            2  16.0        303.0       70.0   \n",
       "\n",
       "   ShoppingMall     Spa  VRDeck  Transported  Deck  Side  \n",
       "0           0.0     0.0     0.0        False     1     0  \n",
       "1          25.0   549.0    44.0         True     5     1  \n",
       "2           0.0  6715.0    49.0        False     0     1  \n",
       "3         371.0  3329.0   193.0        False     0     1  \n",
       "4         151.0   565.0     2.0         True     5     1  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data\n",
    "train_df = pd.read_csv('csv_files/train.csv')\n",
    "\n",
    "# Preview data\n",
    "print('Raw data format:')\n",
    "display(train_df.head())\n",
    "\n",
    "# Determining the amount of missing data per column\n",
    "missing_data = train_df.isna().sum()\n",
    "\n",
    "# Calculating the percentage of missing data per column\n",
    "missing_percentage = (missing_data / len(train_df)) * 100\n",
    "\n",
    "missing_info = pd.DataFrame({\n",
    "    \"Missing Values\": missing_data,\n",
    "    \"Percentage\": missing_percentage\n",
    "})\n",
    "\n",
    "missing_info.sort_values(by=\"Missing Values\", ascending=False)\n",
    "\n",
    "# Imputers\n",
    "median_imputer = SimpleImputer(strategy='median')\n",
    "mode_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# List of numerical and categorical columns that need imputation\n",
    "numerical_cols = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "categorical_cols = ['HomePlanet', 'CryoSleep', 'Destination', 'VIP']\n",
    "\n",
    "# Imputation\n",
    "train_df[numerical_cols] = median_imputer.fit_transform(train_df[numerical_cols])\n",
    "train_df[categorical_cols] = mode_imputer.fit_transform(train_df[categorical_cols])\n",
    "\n",
    "\n",
    "# Assuming train_df is predefined\n",
    "decision_tree_df = train_df.copy()  # Use copy to avoid SettingWithCopyWarning\n",
    "\n",
    "# Drop unnecessary columns\n",
    "decision_tree_df.drop(columns=['PassengerId', 'Name', 'VIP'], inplace=True)\n",
    "\n",
    "decision_tree_df.dropna(subset=['Cabin'], inplace=True)\n",
    "\n",
    "# Split 'Cabin' into 'Deck' and 'Side'\n",
    "decision_tree_df['Deck'] = decision_tree_df['Cabin'].str.split('/').str[0]\n",
    "decision_tree_df['Side'] = decision_tree_df['Cabin'].str.split('/').str[2]\n",
    "\n",
    "decision_tree_df.drop(columns=['Cabin'], inplace=True) \n",
    "\n",
    "# Convert 'CryoSleep' boolean to int\n",
    "decision_tree_df['CryoSleep'] = decision_tree_df['CryoSleep'].astype(int)\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode categorical variables\n",
    "for col in ['HomePlanet', 'Destination', 'Deck', 'Side']:\n",
    "    decision_tree_df[col] = label_encoder.fit_transform(decision_tree_df[col])\n",
    "\n",
    "# After edits for decision trees\n",
    "print('DataFrame used for trees:')\n",
    "decision_tree_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: Convert boolean column to int\n",
    "decision_tree_df['Transported'] = decision_tree_df['Transported'].astype(int)\n",
    "\n",
    "# Split the DataFrame into features and the target\n",
    "features = decision_tree_df.drop('Transported', axis=1)\n",
    "target = decision_tree_df['Transported']\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X = decision_tree_df.drop(['Transported'], axis=1)  # Features\n",
    "y = decision_tree_df['Transported']  # Target variable\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=2)\n",
    "\n",
    "# Since the label column is not in X_train and X_val, concatenate it back for creating the TF dataset\n",
    "train_df = pd.concat([X_train, y_train], axis=1)\n",
    "val_df = pd.concat([X_val, y_val], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use /var/folders/8m/ktb56qhs1_b5w47663nfm5wh0000gn/T/tmpncb5tjlb as temporary training directory\n",
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.131881. Found 6795 examples.\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-03-21 20:35:53.5249 SAST kernel.cc:1233] Loading model from path /var/folders/8m/ktb56qhs1_b5w47663nfm5wh0000gn/T/tmpncb5tjlb/model/ with prefix dea5ce994b024f62\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:00:00.796178\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-03-21 20:35:53.8063 SAST decision_forest.cc:734] Model loaded with 300 root(s), 258224 node(s), and 11 input feature(s).\n",
      "[INFO 24-03-21 20:35:53.8063 SAST abstract_model.cc:1344] Engine \"RandomForestOptPred\" built\n",
      "[INFO 24-03-21 20:35:53.8063 SAST kernel.cc:1061] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0000e+00\n",
      "Loss on validation set: 0.0\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Sample of predicted labels: [0 0 0 0 0 0 0 0 0 0]\n",
      "Calculated validation accuracy: 0.5103\n",
      "Validation Precision: 0.0000\n",
      "Validation Recall: 0.0000\n",
      "Validation F1 Score: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Convert the pandas dataframes to tensorflow datasets\n",
    "train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_df, label=\"Transported\")\n",
    "val_ds = tfdf.keras.pd_dataframe_to_tf_dataset(val_df, label=\"Transported\")\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf_model = tfdf.keras.RandomForestModel()\n",
    "\n",
    "# Fit the model to the training data\n",
    "rf_model.fit(train_ds)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "loss = rf_model.evaluate(val_ds)\n",
    "print(f\"Loss on validation set: {loss}\")\n",
    "\n",
    "# Predict on the validation dataset\n",
    "predictions = rf_model.predict(val_ds)\n",
    "\n",
    "# If the predictions are probabilities, convert them to binary labels\n",
    "if predictions.ndim > 1 and predictions.shape[1] > 1:\n",
    "    # Assuming the positive class probabilities are in the second column for binary classification\n",
    "    predicted_labels = (predictions[:, 1] >= 0.5).astype(int)\n",
    "else:\n",
    "    # If predictions are already binary labels\n",
    "    predicted_labels = predictions.flatten().astype(int)  # Ensure binary labels and correct shape\n",
    "\n",
    "# Verify the content of predicted_labels\n",
    "print(\"Sample of predicted labels:\", predicted_labels[:10])\n",
    "\n",
    "# Ensure y_val_array is correctly formatted as a 1D binary array\n",
    "y_val_array = np.array(y_val).flatten()  # Flatten in case y_val is 2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use /var/folders/8m/ktb56qhs1_b5w47663nfm5wh0000gn/T/tmpy9sj120w as temporary training directory\n",
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.116396. Found 6795 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.027110\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0000e+00\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Num Trees: 50, Max Depth: 5, Validation Accuracy: 0.5021\n",
      "Use /var/folders/8m/ktb56qhs1_b5w47663nfm5wh0000gn/T/tmpqttrx9j6 as temporary training directory\n",
      "Reading training dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-03-21 20:32:12.0692 SAST kernel.cc:1233] Loading model from path /var/folders/8m/ktb56qhs1_b5w47663nfm5wh0000gn/T/tmpy9sj120w/model/ with prefix bca574fb743b4ffa\n",
      "[INFO 24-03-21 20:32:12.0709 SAST decision_forest.cc:734] Model loaded with 50 root(s), 1516 node(s), and 11 input feature(s).\n",
      "[INFO 24-03-21 20:32:12.0709 SAST abstract_model.cc:1344] Engine \"RandomForestOptPred\" built\n",
      "[INFO 24-03-21 20:32:12.0710 SAST kernel.cc:1061] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset read in 0:00:00.095121. Found 6795 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.071597\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0000e+00\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Num Trees: 50, Max Depth: 10, Validation Accuracy: 0.5021\n",
      "Use /var/folders/8m/ktb56qhs1_b5w47663nfm5wh0000gn/T/tmpyt1cr6io as temporary training directory\n",
      "Reading training dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-03-21 20:32:12.3626 SAST kernel.cc:1233] Loading model from path /var/folders/8m/ktb56qhs1_b5w47663nfm5wh0000gn/T/tmpqttrx9j6/model/ with prefix 496cd9c4fbfa486c\n",
      "[INFO 24-03-21 20:32:12.3790 SAST decision_forest.cc:734] Model loaded with 50 root(s), 16820 node(s), and 11 input feature(s).\n",
      "[INFO 24-03-21 20:32:12.3791 SAST kernel.cc:1061] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset read in 0:00:00.096862. Found 6795 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.147057\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0000e+00\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Num Trees: 50, Max Depth: None, Validation Accuracy: 0.5021\n",
      "Use /var/folders/8m/ktb56qhs1_b5w47663nfm5wh0000gn/T/tmpimlxj0_j as temporary training directory\n",
      "Reading training dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-03-21 20:32:12.7111 SAST kernel.cc:1233] Loading model from path /var/folders/8m/ktb56qhs1_b5w47663nfm5wh0000gn/T/tmpyt1cr6io/model/ with prefix fcef183cdd3147ab\n",
      "[INFO 24-03-21 20:32:12.7555 SAST decision_forest.cc:734] Model loaded with 50 root(s), 43640 node(s), and 11 input feature(s).\n",
      "[INFO 24-03-21 20:32:12.7555 SAST kernel.cc:1061] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset read in 0:00:00.092134. Found 6795 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.044696\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0000e+00\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Num Trees: 100, Max Depth: 5, Validation Accuracy: 0.5021\n",
      "Use /var/folders/8m/ktb56qhs1_b5w47663nfm5wh0000gn/T/tmpz49ol8cu as temporary training directory\n",
      "Reading training dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-03-21 20:32:13.0355 SAST kernel.cc:1233] Loading model from path /var/folders/8m/ktb56qhs1_b5w47663nfm5wh0000gn/T/tmpimlxj0_j/model/ with prefix 968375cebefa4ab5\n",
      "[INFO 24-03-21 20:32:13.0384 SAST decision_forest.cc:734] Model loaded with 100 root(s), 3028 node(s), and 11 input feature(s).\n",
      "[INFO 24-03-21 20:32:13.0384 SAST kernel.cc:1061] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset read in 0:00:00.095613. Found 6795 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.138976\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0000e+00\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Num Trees: 100, Max Depth: 10, Validation Accuracy: 0.5021\n",
      "Use /var/folders/8m/ktb56qhs1_b5w47663nfm5wh0000gn/T/tmp83ap7rrs as temporary training directory\n",
      "Reading training dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-03-21 20:32:13.3688 SAST kernel.cc:1233] Loading model from path /var/folders/8m/ktb56qhs1_b5w47663nfm5wh0000gn/T/tmpz49ol8cu/model/ with prefix 8f0ea520bc314bd8\n",
      "[INFO 24-03-21 20:32:13.4014 SAST decision_forest.cc:734] Model loaded with 100 root(s), 33948 node(s), and 11 input feature(s).\n",
      "[INFO 24-03-21 20:32:13.4014 SAST kernel.cc:1061] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset read in 0:00:00.093121. Found 6795 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.259212\n",
      "Compiling model...\n",
      "Model compiled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-03-21 20:32:13.8030 SAST kernel.cc:1233] Loading model from path /var/folders/8m/ktb56qhs1_b5w47663nfm5wh0000gn/T/tmp83ap7rrs/model/ with prefix aba2b56789df4a7a\n",
      "[INFO 24-03-21 20:32:13.8889 SAST decision_forest.cc:734] Model loaded with 100 root(s), 87700 node(s), and 11 input feature(s).\n",
      "[INFO 24-03-21 20:32:13.8890 SAST kernel.cc:1061] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0000e+00\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Num Trees: 100, Max Depth: None, Validation Accuracy: 0.5021\n",
      "Use /var/folders/8m/ktb56qhs1_b5w47663nfm5wh0000gn/T/tmpi54drm_s as temporary training directory\n",
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.090923. Found 6795 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.117083\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0000e+00\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Num Trees: 300, Max Depth: 5, Validation Accuracy: 0.5021\n",
      "Use /var/folders/8m/ktb56qhs1_b5w47663nfm5wh0000gn/T/tmp1pc006jd as temporary training directory\n",
      "Reading training dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-03-21 20:32:14.2475 SAST kernel.cc:1233] Loading model from path /var/folders/8m/ktb56qhs1_b5w47663nfm5wh0000gn/T/tmpi54drm_s/model/ with prefix 1accc6c860ac4696\n",
      "[INFO 24-03-21 20:32:14.2561 SAST decision_forest.cc:734] Model loaded with 300 root(s), 9094 node(s), and 11 input feature(s).\n",
      "[INFO 24-03-21 20:32:14.2561 SAST kernel.cc:1061] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset read in 0:00:00.099156. Found 6795 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.422908\n",
      "Compiling model...\n",
      "Model compiled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-03-21 20:32:14.8095 SAST kernel.cc:1233] Loading model from path /var/folders/8m/ktb56qhs1_b5w47663nfm5wh0000gn/T/tmp1pc006jd/model/ with prefix 2618e4d84416491b\n",
      "[INFO 24-03-21 20:32:14.9112 SAST decision_forest.cc:734] Model loaded with 300 root(s), 101326 node(s), and 11 input feature(s).\n",
      "[INFO 24-03-21 20:32:14.9112 SAST kernel.cc:1061] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0000e+00\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Num Trees: 300, Max Depth: 10, Validation Accuracy: 0.5021\n",
      "Use /var/folders/8m/ktb56qhs1_b5w47663nfm5wh0000gn/T/tmpivs3zetp as temporary training directory\n",
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.092646. Found 6795 examples.\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-03-21 20:32:15.6938 SAST kernel.cc:1233] Loading model from path /var/folders/8m/ktb56qhs1_b5w47663nfm5wh0000gn/T/tmpivs3zetp/model/ with prefix 402a0483a7b3454f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:00:00.779894\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-03-21 20:32:15.9541 SAST decision_forest.cc:734] Model loaded with 300 root(s), 262786 node(s), and 11 input feature(s).\n",
      "[INFO 24-03-21 20:32:15.9541 SAST kernel.cc:1061] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0000e+00\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "Num Trees: 300, Max Depth: None, Validation Accuracy: 0.5021\n",
      "Best Accuracy: 0.5021\n",
      "Best Hyperparameters: {'num_trees': 50, 'max_depth': 5}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_decision_forests as tfdf\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define a range of hyperparameters to test\n",
    "n_trees_options = [50, 100, 300]\n",
    "max_depth_options = [5, 10, None]  # 'None' means no maximum depth limit\n",
    "\n",
    "best_accuracy = 0\n",
    "best_params = {}\n",
    "\n",
    "for n_trees in n_trees_options:\n",
    "    for max_depth in max_depth_options:\n",
    "        # Initialize the Random Forest model with current hyperparameters\n",
    "        rf_model = tfdf.keras.RandomForestModel(num_trees=n_trees, max_depth=max_depth)\n",
    "\n",
    "        # Fit the model to the training data\n",
    "        rf_model.fit(train_ds)\n",
    "\n",
    "        # Evaluate the model on the validation set\n",
    "        loss = rf_model.evaluate(val_ds)\n",
    "\n",
    "        # Predict on the validation dataset\n",
    "        predictions = rf_model.predict(val_ds)\n",
    "\n",
    "        # If the predictions are probabilities, convert them to binary labels\n",
    "        if predictions.ndim > 1 and predictions.shape[1] > 1:\n",
    "            # Assuming the positive class probabilities are in the second column for binary classification\n",
    "            predicted_labels = (predictions[:, 1] >= 0.5).astype(int)\n",
    "        else:\n",
    "            # If predictions are already binary labels\n",
    "            predicted_labels = predictions.flatten().astype(int)  # Ensure binary labels and correct shape\n",
    "            \n",
    "        # Calculate the accuracy\n",
    "        accuracy = accuracy_score(y_val_array, predicted_labels)\n",
    "\n",
    "        print(f\"Num Trees: {n_trees}, Max Depth: {max_depth}, Validation Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "        # Update the best params if current model is better\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_params = {'num_trees': n_trees, 'max_depth': max_depth}\n",
    "\n",
    "print(f\"Best Accuracy: {best_accuracy:.4f}\")\n",
    "print(\"Best Hyperparameters:\", best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data format:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>G/3/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>27.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Nelly Carsoning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0018_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/4/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>19.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2823.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Lerome Peckers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0019_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>True</td>\n",
       "      <td>C/0/S</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>31.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sabih Unhearfus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0021_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>C/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>38.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6652.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>Meratz Caltilter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0023_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/5/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>20.0</td>\n",
       "      <td>False</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Brence Harperez</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0013_01      Earth      True  G/3/S  TRAPPIST-1e  27.0  False   \n",
       "1     0018_01      Earth     False  F/4/S  TRAPPIST-1e  19.0  False   \n",
       "2     0019_01     Europa      True  C/0/S  55 Cancri e  31.0  False   \n",
       "3     0021_01     Europa     False  C/1/S  TRAPPIST-1e  38.0  False   \n",
       "4     0023_01      Earth     False  F/5/S  TRAPPIST-1e  20.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck              Name  \n",
       "0          0.0        0.0           0.0     0.0     0.0   Nelly Carsoning  \n",
       "1          0.0        9.0           0.0  2823.0     0.0    Lerome Peckers  \n",
       "2          0.0        0.0           0.0     0.0     0.0   Sabih Unhearfus  \n",
       "3          0.0     6652.0           0.0   181.0   585.0  Meratz Caltilter  \n",
       "4         10.0        0.0         635.0     0.0     0.0   Brence Harperez  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame used for trees:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Deck</th>\n",
       "      <th>Side</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2823.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6652.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HomePlanet  CryoSleep  Destination   Age  RoomService  FoodCourt  \\\n",
       "0           0          1            2  27.0          0.0        0.0   \n",
       "1           0          0            2  19.0          0.0        9.0   \n",
       "2           1          1            0  31.0          0.0        0.0   \n",
       "3           1          0            2  38.0          0.0     6652.0   \n",
       "4           0          0            2  20.0         10.0        0.0   \n",
       "\n",
       "   ShoppingMall     Spa  VRDeck  Deck  Side  \n",
       "0           0.0     0.0     0.0     6     1  \n",
       "1           0.0  2823.0     0.0     5     1  \n",
       "2           0.0     0.0     0.0     2     1  \n",
       "3           0.0   181.0   585.0     2     1  \n",
       "4         635.0     0.0     0.0     5     1  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data\n",
    "train_df = pd.read_csv('csv_files/test.csv')\n",
    "\n",
    "# Preview data\n",
    "print('Raw data format:')\n",
    "display(train_df.head())\n",
    "\n",
    "# Determining the amount of missing data per column\n",
    "missing_data = train_df.isna().sum()\n",
    "\n",
    "# Calculating the percentage of missing data per column\n",
    "missing_percentage = (missing_data / len(train_df)) * 100\n",
    "\n",
    "missing_info = pd.DataFrame({\n",
    "    \"Missing Values\": missing_data,\n",
    "    \"Percentage\": missing_percentage\n",
    "})\n",
    "\n",
    "missing_info.sort_values(by=\"Missing Values\", ascending=False)\n",
    "\n",
    "# Imputers\n",
    "median_imputer = SimpleImputer(strategy='median')\n",
    "mode_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# List of numerical and categorical columns that need imputation\n",
    "numerical_cols = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "categorical_cols = ['HomePlanet', 'CryoSleep', 'Destination', 'VIP']\n",
    "\n",
    "# Imputation\n",
    "train_df[numerical_cols] = median_imputer.fit_transform(train_df[numerical_cols])\n",
    "train_df[categorical_cols] = mode_imputer.fit_transform(train_df[categorical_cols])\n",
    "\n",
    "\n",
    "# Assuming train_df is predefined\n",
    "decision_tree_df = train_df.copy()  # Use copy to avoid SettingWithCopyWarning\n",
    "\n",
    "# Drop unnecessary columns\n",
    "decision_tree_df.drop(columns=['PassengerId', 'Name', 'VIP'], inplace=True)\n",
    "\n",
    "decision_tree_df.dropna(subset=['Cabin'], inplace=True)\n",
    "\n",
    "# Split 'Cabin' into 'Deck' and 'Side'\n",
    "decision_tree_df['Deck'] = decision_tree_df['Cabin'].str.split('/').str[0]\n",
    "decision_tree_df['Side'] = decision_tree_df['Cabin'].str.split('/').str[2]\n",
    "\n",
    "decision_tree_df.drop(columns=['Cabin'], inplace=True) \n",
    "\n",
    "# Convert 'CryoSleep' boolean to int\n",
    "decision_tree_df['CryoSleep'] = decision_tree_df['CryoSleep'].astype(int)\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode categorical variables\n",
    "for col in ['HomePlanet', 'Destination', 'Deck', 'Side']:\n",
    "    decision_tree_df[col] = label_encoder.fit_transform(decision_tree_df[col])\n",
    "\n",
    "# After edits for decision trees\n",
    "print('DataFrame used for trees:')\n",
    "decision_tree_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
