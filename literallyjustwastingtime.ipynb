{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from scipy.stats import expon, reciprocal\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow import keras\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import keras_tuner as kt\n",
    "import deap\n",
    "import skopt\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.models import save_model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder\n",
    "import joblib\n",
    "\n",
    "def preprocess_data(file_path, is_train=True):\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Convert binary categorical features to 0 and 1\n",
    "    binary_features = ['CryoSleep', 'VIP']\n",
    "    df[binary_features] = df[binary_features].astype(bool).astype(int)\n",
    "    \n",
    "    # Feature Engineering\n",
    "    df['TotalSpending'] = df[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].sum(axis=1)\n",
    "    \n",
    "    # Conditionally set spending-related features to 0 for passengers in cryosleep\n",
    "    spending_features = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "    df.loc[df['CryoSleep'] == 1, spending_features] = 0\n",
    "    \n",
    "    # Age Group feature\n",
    "    df['AgeGroup'] = pd.cut(df['Age'], bins=[0, 12, 18, 60, 100], labels=['Child', 'Teen', 'Adult', 'Senior'])\n",
    "    \n",
    "    # Create interaction features\n",
    "    df['HomePlanet_TotalSpending'] = df['HomePlanet'].astype(str) + '_' + df['TotalSpending'].astype(str)\n",
    "    df['Destination_TotalSpending'] = df['Destination'].astype(str) + '_' + df['TotalSpending'].astype(str)\n",
    "    \n",
    "    # Extract components from 'Cabin'\n",
    "    if 'Cabin' in df.columns:\n",
    "        df[['Cabin_Deck', 'Cabin_Number', 'Cabin_Side']] = df['Cabin'].str.split('/', expand=True)\n",
    "        df['Cabin_Side'] = df['Cabin_Side'].map({'P': 1, 'S': 0})\n",
    "        df['Cabin_Number'] = pd.to_numeric(df['Cabin_Number'], errors='coerce')\n",
    "        df.drop('Cabin', axis=1, inplace=True)\n",
    "    \n",
    "    # One-hot encode categorical features\n",
    "    categorical_features = ['HomePlanet', 'Destination', 'AgeGroup']\n",
    "    if is_train:\n",
    "        one_hot_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "        encoded_features = one_hot_encoder.fit_transform(df[categorical_features])\n",
    "        encoded_feature_names = one_hot_encoder.get_feature_names_out(categorical_features)\n",
    "        joblib.dump(one_hot_encoder, 'one_hot_encoder.pkl')\n",
    "    else:\n",
    "        one_hot_encoder = joblib.load('one_hot_encoder.pkl')\n",
    "        encoded_features = one_hot_encoder.transform(df[categorical_features])\n",
    "        encoded_feature_names = one_hot_encoder.get_feature_names_out(categorical_features)\n",
    "    \n",
    "    encoded_features_df = pd.DataFrame(encoded_features.toarray(), columns=encoded_feature_names)\n",
    "    df = pd.concat([df, encoded_features_df], axis=1)\n",
    "    df.drop(categorical_features, axis=1, inplace=True)\n",
    "    \n",
    "    # Imputation and Scaling\n",
    "    numeric_features = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'Cabin_Number', 'Cabin_Side', 'TotalSpending']\n",
    "    if is_train:\n",
    "        imputer = KNNImputer(n_neighbors=5)\n",
    "        scaler = RobustScaler()  # Use RobustScaler instead of StandardScaler\n",
    "        df[numeric_features] = imputer.fit_transform(df[numeric_features])\n",
    "        df[numeric_features] = scaler.fit_transform(df[numeric_features])\n",
    "        joblib.dump(imputer, 'imputer.pkl')\n",
    "        joblib.dump(scaler, 'scaler.pkl')\n",
    "    else:\n",
    "        imputer = joblib.load('imputer.pkl')\n",
    "        scaler = joblib.load('scaler.pkl')\n",
    "        df[numeric_features] = imputer.transform(df[numeric_features])\n",
    "        df[numeric_features] = scaler.transform(df[numeric_features])\n",
    "    \n",
    "    if is_train:\n",
    "        # Convert 'Transported' to integer (True=1, False=0) for modeling\n",
    "        df['Transported'] = df['Transported'].astype(int)\n",
    "        \n",
    "        # Save the list of features used for training\n",
    "        train_features = [col for col in df.columns if col not in ['PassengerId', 'Name', 'Transported']]\n",
    "        joblib.dump(train_features, 'train_features.pkl')\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "def create_model(input_shape, layers, units, activation, dropout_rate, l1_reg, l2_reg, learning_rate):\n",
    "    model = Sequential()\n",
    "    for _ in range(layers):\n",
    "        model.add(Dense(units, activation=activation, kernel_regularizer=tf.keras.regularizers.l1_l2(l1=l1_reg, l2=l2_reg)))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Assuming binary classification\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def train_and_evaluate(model, X_train, y_train, X_val, y_val, epochs, batch_size):\n",
    "    class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "    class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    lr_scheduler = LearningRateScheduler(lambda epoch: 0.001 if epoch < 10 else 0.0005 if epoch < 20 else 0.0001)\n",
    "\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=batch_size, \n",
    "              class_weight=class_weight_dict, callbacks=[early_stopping, lr_scheduler], verbose=1)\n",
    "\n",
    "    val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
    "    return val_loss, val_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7525 - loss: 0.6974 - val_accuracy: 0.7786 - val_loss: 0.5671 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7881 - loss: 0.5549 - val_accuracy: 0.7798 - val_loss: 0.5581 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7930 - loss: 0.5415 - val_accuracy: 0.7855 - val_loss: 0.5454 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7903 - loss: 0.5391 - val_accuracy: 0.7815 - val_loss: 0.5650 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7971 - loss: 0.5162 - val_accuracy: 0.7757 - val_loss: 0.5414 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8001 - loss: 0.5046 - val_accuracy: 0.7821 - val_loss: 0.5371 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7962 - loss: 0.5127 - val_accuracy: 0.7855 - val_loss: 0.5262 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7898 - loss: 0.5104 - val_accuracy: 0.7706 - val_loss: 0.5204 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7925 - loss: 0.4905 - val_accuracy: 0.7855 - val_loss: 0.5111 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8013 - loss: 0.4872 - val_accuracy: 0.7803 - val_loss: 0.5105 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8015 - loss: 0.4798 - val_accuracy: 0.7838 - val_loss: 0.4953 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8048 - loss: 0.4631 - val_accuracy: 0.7861 - val_loss: 0.4872 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7965 - loss: 0.4663 - val_accuracy: 0.7792 - val_loss: 0.4873 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7991 - loss: 0.4662 - val_accuracy: 0.7849 - val_loss: 0.4798 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7988 - loss: 0.4691 - val_accuracy: 0.7878 - val_loss: 0.4843 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8074 - loss: 0.4550 - val_accuracy: 0.7849 - val_loss: 0.4726 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8040 - loss: 0.4529 - val_accuracy: 0.7855 - val_loss: 0.4759 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8108 - loss: 0.4415 - val_accuracy: 0.7867 - val_loss: 0.4729 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8152 - loss: 0.4374 - val_accuracy: 0.7855 - val_loss: 0.4645 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8044 - loss: 0.4426 - val_accuracy: 0.7884 - val_loss: 0.4659 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8020 - loss: 0.4386 - val_accuracy: 0.7867 - val_loss: 0.4606 - learning_rate: 1.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8084 - loss: 0.4291 - val_accuracy: 0.7861 - val_loss: 0.4583 - learning_rate: 1.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8108 - loss: 0.4235 - val_accuracy: 0.7890 - val_loss: 0.4553 - learning_rate: 1.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7957 - loss: 0.4378 - val_accuracy: 0.7861 - val_loss: 0.4562 - learning_rate: 1.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8034 - loss: 0.4300 - val_accuracy: 0.7855 - val_loss: 0.4566 - learning_rate: 1.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8099 - loss: 0.4223 - val_accuracy: 0.7855 - val_loss: 0.4547 - learning_rate: 1.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8086 - loss: 0.4298 - val_accuracy: 0.7861 - val_loss: 0.4540 - learning_rate: 1.0000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8052 - loss: 0.4248 - val_accuracy: 0.7855 - val_loss: 0.4573 - learning_rate: 1.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8012 - loss: 0.4294 - val_accuracy: 0.7867 - val_loss: 0.4562 - learning_rate: 1.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8027 - loss: 0.4314 - val_accuracy: 0.7855 - val_loss: 0.4582 - learning_rate: 1.0000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8103 - loss: 0.4290 - val_accuracy: 0.7861 - val_loss: 0.4555 - learning_rate: 1.0000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8154 - loss: 0.4259 - val_accuracy: 0.7855 - val_loss: 0.4540 - learning_rate: 1.0000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8076 - loss: 0.4185 - val_accuracy: 0.7855 - val_loss: 0.4520 - learning_rate: 1.0000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8127 - loss: 0.4233 - val_accuracy: 0.7867 - val_loss: 0.4538 - learning_rate: 1.0000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8113 - loss: 0.4183 - val_accuracy: 0.7838 - val_loss: 0.4531 - learning_rate: 1.0000e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8115 - loss: 0.4199 - val_accuracy: 0.7849 - val_loss: 0.4496 - learning_rate: 1.0000e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7984 - loss: 0.4311 - val_accuracy: 0.7901 - val_loss: 0.4518 - learning_rate: 1.0000e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8083 - loss: 0.4234 - val_accuracy: 0.7872 - val_loss: 0.4536 - learning_rate: 1.0000e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8018 - loss: 0.4273 - val_accuracy: 0.7867 - val_loss: 0.4534 - learning_rate: 1.0000e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8098 - loss: 0.4222 - val_accuracy: 0.7861 - val_loss: 0.4513 - learning_rate: 1.0000e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8181 - loss: 0.4098 - val_accuracy: 0.7872 - val_loss: 0.4511 - learning_rate: 1.0000e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8117 - loss: 0.4194 - val_accuracy: 0.7849 - val_loss: 0.4496 - learning_rate: 1.0000e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8111 - loss: 0.4218 - val_accuracy: 0.7867 - val_loss: 0.4522 - learning_rate: 1.0000e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8081 - loss: 0.4227 - val_accuracy: 0.7849 - val_loss: 0.4504 - learning_rate: 1.0000e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8163 - loss: 0.4116 - val_accuracy: 0.7867 - val_loss: 0.4501 - learning_rate: 1.0000e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8100 - loss: 0.4240 - val_accuracy: 0.7861 - val_loss: 0.4509 - learning_rate: 1.0000e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8138 - loss: 0.4160 - val_accuracy: 0.7844 - val_loss: 0.4496 - learning_rate: 1.0000e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8199 - loss: 0.4117 - val_accuracy: 0.7855 - val_loss: 0.4535 - learning_rate: 1.0000e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8068 - loss: 0.4252 - val_accuracy: 0.7878 - val_loss: 0.4520 - learning_rate: 1.0000e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7985 - loss: 0.4370 - val_accuracy: 0.7872 - val_loss: 0.4500 - learning_rate: 1.0000e-04\n",
      "Validation loss: 0.44929057359695435, Validation accuracy: 0.784933865070343\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE, SVMSMOTE\n",
    "\n",
    "# Assuming preprocess_data function is already defined\n",
    "train_df = preprocess_data('csv_files/train.csv', is_train=True)\n",
    "\n",
    "# Prepare features and target for the model\n",
    "features = [col for col in train_df.columns if col not in ['PassengerId', 'Name', 'Transported', 'Cabin_Deck', 'HomePlanet_TotalSpending', 'Destination_TotalSpending']]\n",
    "X = train_df[features]\n",
    "y = train_df['Transported']\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Handling class imbalance using SMOTE on the training set only\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "# Best hyperparameters\n",
    "best_params = {\n",
    "    'layers': 4,  \n",
    "    'units': 303,\n",
    "    'activation': 'swish',\n",
    "    'dropout_rate': 0.2193700315892974,\n",
    "    'l1_reg': 7.792297153882995e-06,\n",
    "    'l2_reg': 1.5847101210439079e-06,\n",
    "    'learning_rate': 0.002879047909793294\n",
    "}\n",
    "\n",
    "# Create the neural network model using best hyperparameters\n",
    "model = create_model(input_shape=X_resampled.shape[1], **best_params)\n",
    "\n",
    "# Train and evaluate the model\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "val_loss, val_acc = train_and_evaluate(model, X_resampled, y_resampled, X_val, y_val, epochs, batch_size)\n",
    "\n",
    "print(f'Validation loss: {val_loss}, Validation accuracy: {val_acc}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
