{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from scipy.stats import expon, reciprocal\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow import keras\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import keras_tuner as kt\n",
    "import deap\n",
    "import skopt\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.models import save_model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import joblib\n",
    "\n",
    "def preprocess_data(file_path, is_train=True):\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Convert binary categorical features to 0 and 1\n",
    "    binary_features = ['CryoSleep', 'VIP']\n",
    "    df[binary_features] = df[binary_features].astype(bool).astype(int)\n",
    "    \n",
    "    # Feature Engineering\n",
    "    df['TotalSpending'] = df[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].sum(axis=1)\n",
    "    \n",
    "    # Conditionally set spending-related features to 0 for passengers in cryosleep\n",
    "    spending_features = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "    df.loc[df['CryoSleep'] == 1, spending_features] = 0\n",
    "    \n",
    "    # Create interaction features\n",
    "    df['HomePlanet_TotalSpending'] = df['HomePlanet'].astype(str) + '_' + df['TotalSpending'].astype(str)\n",
    "    df['Destination_TotalSpending'] = df['Destination'].astype(str) + '_' + df['TotalSpending'].astype(str)\n",
    "    \n",
    "    # Extract components from 'Cabin'\n",
    "    if 'Cabin' in df.columns:\n",
    "        df[['Cabin_Deck', 'Cabin_Number', 'Cabin_Side']] = df['Cabin'].str.split('/', expand=True)\n",
    "        df['Cabin_Side'] = df['Cabin_Side'].map({'P': 1, 'S': 0})\n",
    "        df['Cabin_Number'] = pd.to_numeric(df['Cabin_Number'], errors='coerce')\n",
    "        df.drop('Cabin', axis=1, inplace=True)\n",
    "    \n",
    "    # One-hot encode multi-category features\n",
    "    multi_cat_features = ['HomePlanet', 'Destination']\n",
    "    if is_train:\n",
    "        one_hot_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "        encoded_features = one_hot_encoder.fit_transform(df[multi_cat_features])\n",
    "        encoded_feature_names = one_hot_encoder.get_feature_names_out(multi_cat_features)\n",
    "        joblib.dump(one_hot_encoder, 'one_hot_encoder.pkl')\n",
    "    else:\n",
    "        one_hot_encoder = joblib.load('one_hot_encoder.pkl')\n",
    "        encoded_features = one_hot_encoder.transform(df[multi_cat_features])\n",
    "        encoded_feature_names = one_hot_encoder.get_feature_names_out(multi_cat_features)\n",
    "    \n",
    "    encoded_features_df = pd.DataFrame(encoded_features.toarray(), columns=encoded_feature_names)\n",
    "    df = pd.concat([df, encoded_features_df], axis=1)\n",
    "    df.drop(multi_cat_features, axis=1, inplace=True)\n",
    "    \n",
    "    # Imputation and Scaling\n",
    "    numeric_features = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'Cabin_Number', 'Cabin_Side', 'TotalSpending']\n",
    "    if is_train:\n",
    "        imputer = KNNImputer(n_neighbors=5)\n",
    "        scaler = StandardScaler()\n",
    "        df[numeric_features] = imputer.fit_transform(df[numeric_features])\n",
    "        df[numeric_features] = scaler.fit_transform(df[numeric_features])\n",
    "        joblib.dump(imputer, 'imputer.pkl')\n",
    "        joblib.dump(scaler, 'scaler.pkl')\n",
    "    else:\n",
    "        imputer = joblib.load('imputer.pkl')\n",
    "        scaler = joblib.load('scaler.pkl')\n",
    "        df[numeric_features] = imputer.transform(df[numeric_features])\n",
    "        df[numeric_features] = scaler.transform(df[numeric_features])\n",
    "    \n",
    "    if is_train:\n",
    "        # Convert 'Transported' to integer (True=1, False=0) for modeling\n",
    "        df['Transported'] = df['Transported'].astype(int)\n",
    "        \n",
    "        # Save the list of features used for training\n",
    "        train_features = [col for col in df.columns if col not in ['PassengerId', 'Name', 'Transported', 'Cabin_Deck', 'HomePlanet_TotalSpending', 'Destination_TotalSpending']]\n",
    "        joblib.dump(train_features, 'train_features.pkl')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rahulnundlall/anaconda3/envs/ML/lib/python3.12/site-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 944us/step - accuracy: 0.7050 - loss: 0.5458 - val_accuracy: 0.7671 - val_loss: 0.4743\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - accuracy: 0.7865 - loss: 0.4575 - val_accuracy: 0.7734 - val_loss: 0.4645\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step - accuracy: 0.7736 - loss: 0.4714 - val_accuracy: 0.7809 - val_loss: 0.4599\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step - accuracy: 0.7759 - loss: 0.4653 - val_accuracy: 0.7717 - val_loss: 0.4713\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - accuracy: 0.7862 - loss: 0.4517 - val_accuracy: 0.7775 - val_loss: 0.4651\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721us/step - accuracy: 0.7760 - loss: 0.4586 - val_accuracy: 0.7700 - val_loss: 0.4639\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step - accuracy: 0.7890 - loss: 0.4420 - val_accuracy: 0.7803 - val_loss: 0.4592\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step - accuracy: 0.7873 - loss: 0.4410 - val_accuracy: 0.7769 - val_loss: 0.4581\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - accuracy: 0.7847 - loss: 0.4421 - val_accuracy: 0.7849 - val_loss: 0.4560\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - accuracy: 0.7950 - loss: 0.4391 - val_accuracy: 0.7763 - val_loss: 0.4651\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.7904 - loss: 0.4474 - val_accuracy: 0.7717 - val_loss: 0.4614\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - accuracy: 0.7853 - loss: 0.4416 - val_accuracy: 0.7849 - val_loss: 0.4494\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - accuracy: 0.7978 - loss: 0.4346 - val_accuracy: 0.7798 - val_loss: 0.4509\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - accuracy: 0.7995 - loss: 0.4278 - val_accuracy: 0.7780 - val_loss: 0.4546\n",
      "Epoch 15/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - accuracy: 0.7807 - loss: 0.4506 - val_accuracy: 0.7855 - val_loss: 0.4476\n",
      "Epoch 16/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - accuracy: 0.7927 - loss: 0.4323 - val_accuracy: 0.7815 - val_loss: 0.4477\n",
      "Epoch 17/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - accuracy: 0.8049 - loss: 0.4299 - val_accuracy: 0.7798 - val_loss: 0.4445\n",
      "Epoch 18/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - accuracy: 0.7981 - loss: 0.4244 - val_accuracy: 0.7826 - val_loss: 0.4409\n",
      "Epoch 19/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - accuracy: 0.7979 - loss: 0.4241 - val_accuracy: 0.7769 - val_loss: 0.4433\n",
      "Epoch 20/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - accuracy: 0.7931 - loss: 0.4278 - val_accuracy: 0.7844 - val_loss: 0.4407\n",
      "Epoch 21/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677us/step - accuracy: 0.7904 - loss: 0.4274 - val_accuracy: 0.7746 - val_loss: 0.4382\n",
      "Epoch 22/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - accuracy: 0.8040 - loss: 0.4133 - val_accuracy: 0.7826 - val_loss: 0.4357\n",
      "Epoch 23/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - accuracy: 0.7891 - loss: 0.4278 - val_accuracy: 0.7821 - val_loss: 0.4347\n",
      "Epoch 24/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.7962 - loss: 0.4242 - val_accuracy: 0.7757 - val_loss: 0.4290\n",
      "Epoch 25/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - accuracy: 0.8054 - loss: 0.4100 - val_accuracy: 0.7821 - val_loss: 0.4329\n",
      "Epoch 26/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - accuracy: 0.7869 - loss: 0.4267 - val_accuracy: 0.7907 - val_loss: 0.4280\n",
      "Epoch 27/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step - accuracy: 0.7985 - loss: 0.4232 - val_accuracy: 0.7821 - val_loss: 0.4345\n",
      "Epoch 28/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - accuracy: 0.7951 - loss: 0.4166 - val_accuracy: 0.7861 - val_loss: 0.4289\n",
      "Epoch 29/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - accuracy: 0.7970 - loss: 0.4239 - val_accuracy: 0.7867 - val_loss: 0.4286\n",
      "Epoch 30/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - accuracy: 0.7976 - loss: 0.4124 - val_accuracy: 0.7809 - val_loss: 0.4252\n",
      "Epoch 31/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - accuracy: 0.8011 - loss: 0.4099 - val_accuracy: 0.7907 - val_loss: 0.4236\n",
      "Epoch 32/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - accuracy: 0.8009 - loss: 0.4156 - val_accuracy: 0.7867 - val_loss: 0.4258\n",
      "Epoch 33/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - accuracy: 0.7996 - loss: 0.4116 - val_accuracy: 0.7861 - val_loss: 0.4231\n",
      "Epoch 34/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - accuracy: 0.8050 - loss: 0.4036 - val_accuracy: 0.7855 - val_loss: 0.4212\n",
      "Epoch 35/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - accuracy: 0.8090 - loss: 0.4040 - val_accuracy: 0.7815 - val_loss: 0.4337\n",
      "Epoch 36/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - accuracy: 0.7966 - loss: 0.4199 - val_accuracy: 0.7924 - val_loss: 0.4226\n",
      "Epoch 37/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574us/step - accuracy: 0.8062 - loss: 0.4107 - val_accuracy: 0.7970 - val_loss: 0.4219\n",
      "Epoch 38/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - accuracy: 0.8024 - loss: 0.4118 - val_accuracy: 0.7821 - val_loss: 0.4323\n",
      "Epoch 39/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - accuracy: 0.7907 - loss: 0.4181 - val_accuracy: 0.7918 - val_loss: 0.4261\n",
      "Epoch 40/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - accuracy: 0.8130 - loss: 0.3961 - val_accuracy: 0.7918 - val_loss: 0.4218\n",
      "Epoch 41/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - accuracy: 0.8036 - loss: 0.4083 - val_accuracy: 0.7878 - val_loss: 0.4204\n",
      "Epoch 42/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - accuracy: 0.8082 - loss: 0.3986 - val_accuracy: 0.7930 - val_loss: 0.4171\n",
      "Epoch 43/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - accuracy: 0.8130 - loss: 0.4020 - val_accuracy: 0.7947 - val_loss: 0.4181\n",
      "Epoch 44/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - accuracy: 0.8025 - loss: 0.4078 - val_accuracy: 0.7907 - val_loss: 0.4155\n",
      "Epoch 45/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.8055 - loss: 0.4045 - val_accuracy: 0.7976 - val_loss: 0.4159\n",
      "Epoch 46/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - accuracy: 0.8085 - loss: 0.4025 - val_accuracy: 0.7924 - val_loss: 0.4178\n",
      "Epoch 47/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - accuracy: 0.8117 - loss: 0.4073 - val_accuracy: 0.7970 - val_loss: 0.4176\n",
      "Epoch 48/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - accuracy: 0.7888 - loss: 0.4142 - val_accuracy: 0.7953 - val_loss: 0.4155\n",
      "Epoch 49/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - accuracy: 0.7947 - loss: 0.4106 - val_accuracy: 0.7947 - val_loss: 0.4156\n",
      "Epoch 50/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - accuracy: 0.8093 - loss: 0.3923 - val_accuracy: 0.7964 - val_loss: 0.4161\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 8.1102\n",
      "Function value obtained: -0.7953\n",
      "Current minimum: -0.7953\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "Epoch 1/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step - accuracy: 0.7417 - loss: 0.5132 - val_accuracy: 0.7809 - val_loss: 0.4495\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - accuracy: 0.8027 - loss: 0.4232 - val_accuracy: 0.7821 - val_loss: 0.4486\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7980 - loss: 0.4170 - val_accuracy: 0.7809 - val_loss: 0.4428\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414us/step - accuracy: 0.8027 - loss: 0.4105 - val_accuracy: 0.7780 - val_loss: 0.4479\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - accuracy: 0.8077 - loss: 0.4109 - val_accuracy: 0.7815 - val_loss: 0.4400\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - accuracy: 0.8097 - loss: 0.4039 - val_accuracy: 0.7775 - val_loss: 0.4377\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - accuracy: 0.7984 - loss: 0.4139 - val_accuracy: 0.7872 - val_loss: 0.4359\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - accuracy: 0.8208 - loss: 0.3933 - val_accuracy: 0.7855 - val_loss: 0.4353\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - accuracy: 0.8078 - loss: 0.3948 - val_accuracy: 0.7809 - val_loss: 0.4355\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - accuracy: 0.8076 - loss: 0.4027 - val_accuracy: 0.7844 - val_loss: 0.4369\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - accuracy: 0.8082 - loss: 0.4055 - val_accuracy: 0.7849 - val_loss: 0.4285\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.8157 - loss: 0.3847 - val_accuracy: 0.7844 - val_loss: 0.4307\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - accuracy: 0.8154 - loss: 0.3880 - val_accuracy: 0.7803 - val_loss: 0.4317\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - accuracy: 0.8129 - loss: 0.3917 - val_accuracy: 0.7890 - val_loss: 0.4311\n",
      "Epoch 15/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - accuracy: 0.8203 - loss: 0.3831 - val_accuracy: 0.7815 - val_loss: 0.4355\n",
      "Epoch 16/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.8156 - loss: 0.3918 - val_accuracy: 0.7803 - val_loss: 0.4313\n",
      "Epoch 17/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.8040 - loss: 0.4027 - val_accuracy: 0.7792 - val_loss: 0.4354\n",
      "Epoch 18/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.8218 - loss: 0.3810 - val_accuracy: 0.7832 - val_loss: 0.4449\n",
      "Epoch 19/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - accuracy: 0.8142 - loss: 0.3873 - val_accuracy: 0.7907 - val_loss: 0.4304\n",
      "Epoch 20/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - accuracy: 0.8048 - loss: 0.3974 - val_accuracy: 0.7861 - val_loss: 0.4327\n",
      "Epoch 21/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.8148 - loss: 0.3851 - val_accuracy: 0.7838 - val_loss: 0.4294\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 2.3664\n",
      "Function value obtained: -0.7849\n",
      "Current minimum: -0.7953\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "Epoch 1/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - accuracy: 0.7601 - loss: 0.4986 - val_accuracy: 0.7619 - val_loss: 0.4907\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431us/step - accuracy: 0.7840 - loss: 0.4640 - val_accuracy: 0.7642 - val_loss: 0.5124\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429us/step - accuracy: 0.7845 - loss: 0.4608 - val_accuracy: 0.7711 - val_loss: 0.4639\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434us/step - accuracy: 0.7755 - loss: 0.4737 - val_accuracy: 0.7688 - val_loss: 0.4936\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420us/step - accuracy: 0.7874 - loss: 0.4502 - val_accuracy: 0.7786 - val_loss: 0.4598\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432us/step - accuracy: 0.7931 - loss: 0.4506 - val_accuracy: 0.7614 - val_loss: 0.4758\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.7866 - loss: 0.4478 - val_accuracy: 0.7734 - val_loss: 0.4559\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - accuracy: 0.7901 - loss: 0.4350 - val_accuracy: 0.7694 - val_loss: 0.4696\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - accuracy: 0.7911 - loss: 0.4482 - val_accuracy: 0.7798 - val_loss: 0.4567\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427us/step - accuracy: 0.7859 - loss: 0.4403 - val_accuracy: 0.7867 - val_loss: 0.4528\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419us/step - accuracy: 0.7850 - loss: 0.4468 - val_accuracy: 0.7763 - val_loss: 0.4665\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427us/step - accuracy: 0.7870 - loss: 0.4487 - val_accuracy: 0.7740 - val_loss: 0.4500\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - accuracy: 0.7901 - loss: 0.4300 - val_accuracy: 0.7792 - val_loss: 0.4423\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435us/step - accuracy: 0.7899 - loss: 0.4327 - val_accuracy: 0.7740 - val_loss: 0.4623\n",
      "Epoch 15/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.7965 - loss: 0.4274 - val_accuracy: 0.7895 - val_loss: 0.4489\n",
      "Epoch 16/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614us/step - accuracy: 0.7968 - loss: 0.4252 - val_accuracy: 0.7769 - val_loss: 0.4449\n",
      "Epoch 17/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.8000 - loss: 0.4148 - val_accuracy: 0.7798 - val_loss: 0.4477\n",
      "Epoch 18/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428us/step - accuracy: 0.7911 - loss: 0.4342 - val_accuracy: 0.7803 - val_loss: 0.4439\n",
      "Epoch 19/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427us/step - accuracy: 0.8008 - loss: 0.4124 - val_accuracy: 0.7838 - val_loss: 0.4487\n",
      "Epoch 20/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - accuracy: 0.8072 - loss: 0.4122 - val_accuracy: 0.7901 - val_loss: 0.4486\n",
      "Epoch 21/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417us/step - accuracy: 0.7956 - loss: 0.4292 - val_accuracy: 0.7999 - val_loss: 0.4286\n",
      "Epoch 22/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - accuracy: 0.8046 - loss: 0.4080 - val_accuracy: 0.7878 - val_loss: 0.4461\n",
      "Epoch 23/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step - accuracy: 0.8005 - loss: 0.4162 - val_accuracy: 0.7867 - val_loss: 0.4324\n",
      "Epoch 24/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - accuracy: 0.7994 - loss: 0.4218 - val_accuracy: 0.7867 - val_loss: 0.4339\n",
      "Epoch 25/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414us/step - accuracy: 0.7976 - loss: 0.4134 - val_accuracy: 0.7838 - val_loss: 0.4410\n",
      "Epoch 26/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step - accuracy: 0.8016 - loss: 0.4092 - val_accuracy: 0.7867 - val_loss: 0.4331\n",
      "Epoch 27/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - accuracy: 0.8079 - loss: 0.4207 - val_accuracy: 0.7878 - val_loss: 0.4370\n",
      "Epoch 28/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - accuracy: 0.8028 - loss: 0.4196 - val_accuracy: 0.7792 - val_loss: 0.4629\n",
      "Epoch 29/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431us/step - accuracy: 0.8071 - loss: 0.4019 - val_accuracy: 0.7878 - val_loss: 0.4431\n",
      "Epoch 30/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - accuracy: 0.8071 - loss: 0.4071 - val_accuracy: 0.7895 - val_loss: 0.4365\n",
      "Epoch 31/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.8025 - loss: 0.4104 - val_accuracy: 0.7809 - val_loss: 0.4471\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 3.7115\n",
      "Function value obtained: -0.7999\n",
      "Current minimum: -0.7999\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "Epoch 1/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7530 - loss: 0.4946 - val_accuracy: 0.7752 - val_loss: 0.4502\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7967 - loss: 0.4240 - val_accuracy: 0.7780 - val_loss: 0.4395\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8002 - loss: 0.4193 - val_accuracy: 0.7803 - val_loss: 0.4364\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8112 - loss: 0.3990 - val_accuracy: 0.7884 - val_loss: 0.4391\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8107 - loss: 0.3997 - val_accuracy: 0.7769 - val_loss: 0.4331\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8089 - loss: 0.3959 - val_accuracy: 0.7901 - val_loss: 0.4207\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8118 - loss: 0.3954 - val_accuracy: 0.7861 - val_loss: 0.4258\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8020 - loss: 0.3976 - val_accuracy: 0.7867 - val_loss: 0.4218\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8171 - loss: 0.3838 - val_accuracy: 0.7867 - val_loss: 0.4313\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8089 - loss: 0.3872 - val_accuracy: 0.7947 - val_loss: 0.4201\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8179 - loss: 0.3786 - val_accuracy: 0.7872 - val_loss: 0.4190\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8210 - loss: 0.3786 - val_accuracy: 0.7895 - val_loss: 0.4241\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8233 - loss: 0.3741 - val_accuracy: 0.7890 - val_loss: 0.4220\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8228 - loss: 0.3651 - val_accuracy: 0.7861 - val_loss: 0.4368\n",
      "Epoch 15/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8259 - loss: 0.3590 - val_accuracy: 0.7982 - val_loss: 0.4200\n",
      "Epoch 16/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8327 - loss: 0.3634 - val_accuracy: 0.7849 - val_loss: 0.4275\n",
      "Epoch 17/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8255 - loss: 0.3548 - val_accuracy: 0.7901 - val_loss: 0.4443\n",
      "Epoch 18/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8336 - loss: 0.3581 - val_accuracy: 0.7890 - val_loss: 0.4403\n",
      "Epoch 19/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8349 - loss: 0.3458 - val_accuracy: 0.7999 - val_loss: 0.4271\n",
      "Epoch 20/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8364 - loss: 0.3364 - val_accuracy: 0.7987 - val_loss: 0.4309\n",
      "Epoch 21/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8218 - loss: 0.3554 - val_accuracy: 0.7901 - val_loss: 0.4303\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 8.6213\n",
      "Function value obtained: -0.7872\n",
      "Current minimum: -0.7999\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "Epoch 1/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - accuracy: 0.5903 - loss: 0.6766 - val_accuracy: 0.7545 - val_loss: 0.5354\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.7389 - loss: 0.5350 - val_accuracy: 0.7608 - val_loss: 0.4909\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - accuracy: 0.7649 - loss: 0.4897 - val_accuracy: 0.7665 - val_loss: 0.4782\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - accuracy: 0.7831 - loss: 0.4635 - val_accuracy: 0.7648 - val_loss: 0.4726\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.7770 - loss: 0.4586 - val_accuracy: 0.7688 - val_loss: 0.4702\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - accuracy: 0.7825 - loss: 0.4541 - val_accuracy: 0.7700 - val_loss: 0.4683\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - accuracy: 0.7774 - loss: 0.4553 - val_accuracy: 0.7706 - val_loss: 0.4661\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - accuracy: 0.7781 - loss: 0.4644 - val_accuracy: 0.7734 - val_loss: 0.4649\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - accuracy: 0.7877 - loss: 0.4590 - val_accuracy: 0.7717 - val_loss: 0.4636\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - accuracy: 0.7904 - loss: 0.4458 - val_accuracy: 0.7706 - val_loss: 0.4630\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - accuracy: 0.7864 - loss: 0.4480 - val_accuracy: 0.7723 - val_loss: 0.4630\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - accuracy: 0.7778 - loss: 0.4597 - val_accuracy: 0.7734 - val_loss: 0.4614\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - accuracy: 0.7776 - loss: 0.4527 - val_accuracy: 0.7734 - val_loss: 0.4613\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.7876 - loss: 0.4482 - val_accuracy: 0.7757 - val_loss: 0.4613\n",
      "Epoch 15/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - accuracy: 0.7817 - loss: 0.4492 - val_accuracy: 0.7734 - val_loss: 0.4603\n",
      "Epoch 16/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - accuracy: 0.7783 - loss: 0.4567 - val_accuracy: 0.7752 - val_loss: 0.4604\n",
      "Epoch 17/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - accuracy: 0.7792 - loss: 0.4490 - val_accuracy: 0.7734 - val_loss: 0.4602\n",
      "Epoch 18/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - accuracy: 0.7933 - loss: 0.4431 - val_accuracy: 0.7769 - val_loss: 0.4591\n",
      "Epoch 19/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - accuracy: 0.7748 - loss: 0.4550 - val_accuracy: 0.7740 - val_loss: 0.4596\n",
      "Epoch 20/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - accuracy: 0.7814 - loss: 0.4622 - val_accuracy: 0.7775 - val_loss: 0.4596\n",
      "Epoch 21/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - accuracy: 0.7855 - loss: 0.4522 - val_accuracy: 0.7752 - val_loss: 0.4594\n",
      "Epoch 22/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - accuracy: 0.7856 - loss: 0.4629 - val_accuracy: 0.7792 - val_loss: 0.4598\n",
      "Epoch 23/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.7804 - loss: 0.4539 - val_accuracy: 0.7746 - val_loss: 0.4588\n",
      "Epoch 24/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427us/step - accuracy: 0.7929 - loss: 0.4447 - val_accuracy: 0.7792 - val_loss: 0.4572\n",
      "Epoch 25/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - accuracy: 0.7930 - loss: 0.4437 - val_accuracy: 0.7786 - val_loss: 0.4580\n",
      "Epoch 26/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - accuracy: 0.7750 - loss: 0.4645 - val_accuracy: 0.7775 - val_loss: 0.4577\n",
      "Epoch 27/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.7963 - loss: 0.4416 - val_accuracy: 0.7780 - val_loss: 0.4580\n",
      "Epoch 28/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - accuracy: 0.7874 - loss: 0.4486 - val_accuracy: 0.7769 - val_loss: 0.4580\n",
      "Epoch 29/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.7836 - loss: 0.4517 - val_accuracy: 0.7769 - val_loss: 0.4570\n",
      "Epoch 30/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417us/step - accuracy: 0.7910 - loss: 0.4404 - val_accuracy: 0.7803 - val_loss: 0.4572\n",
      "Epoch 31/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.7872 - loss: 0.4445 - val_accuracy: 0.7798 - val_loss: 0.4575\n",
      "Epoch 32/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414us/step - accuracy: 0.7923 - loss: 0.4379 - val_accuracy: 0.7763 - val_loss: 0.4557\n",
      "Epoch 33/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414us/step - accuracy: 0.7971 - loss: 0.4354 - val_accuracy: 0.7803 - val_loss: 0.4565\n",
      "Epoch 34/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - accuracy: 0.7882 - loss: 0.4467 - val_accuracy: 0.7792 - val_loss: 0.4562\n",
      "Epoch 35/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.7964 - loss: 0.4335 - val_accuracy: 0.7786 - val_loss: 0.4558\n",
      "Epoch 36/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.7983 - loss: 0.4395 - val_accuracy: 0.7780 - val_loss: 0.4568\n",
      "Epoch 37/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.7789 - loss: 0.4516 - val_accuracy: 0.7780 - val_loss: 0.4557\n",
      "Epoch 38/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - accuracy: 0.7987 - loss: 0.4350 - val_accuracy: 0.7786 - val_loss: 0.4552\n",
      "Epoch 39/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - accuracy: 0.7888 - loss: 0.4379 - val_accuracy: 0.7803 - val_loss: 0.4556\n",
      "Epoch 40/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - accuracy: 0.7884 - loss: 0.4438 - val_accuracy: 0.7798 - val_loss: 0.4561\n",
      "Epoch 41/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - accuracy: 0.7945 - loss: 0.4354 - val_accuracy: 0.7786 - val_loss: 0.4555\n",
      "Epoch 42/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - accuracy: 0.7969 - loss: 0.4321 - val_accuracy: 0.7798 - val_loss: 0.4557\n",
      "Epoch 43/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - accuracy: 0.7803 - loss: 0.4486 - val_accuracy: 0.7757 - val_loss: 0.4557\n",
      "Epoch 44/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - accuracy: 0.7998 - loss: 0.4317 - val_accuracy: 0.7763 - val_loss: 0.4553\n",
      "Epoch 45/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - accuracy: 0.8023 - loss: 0.4249 - val_accuracy: 0.7821 - val_loss: 0.4538\n",
      "Epoch 46/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - accuracy: 0.7880 - loss: 0.4390 - val_accuracy: 0.7757 - val_loss: 0.4545\n",
      "Epoch 47/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - accuracy: 0.7858 - loss: 0.4452 - val_accuracy: 0.7775 - val_loss: 0.4550\n",
      "Epoch 48/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - accuracy: 0.7917 - loss: 0.4383 - val_accuracy: 0.7775 - val_loss: 0.4546\n",
      "Epoch 49/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418us/step - accuracy: 0.7967 - loss: 0.4277 - val_accuracy: 0.7780 - val_loss: 0.4537\n",
      "Epoch 50/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - accuracy: 0.8004 - loss: 0.4292 - val_accuracy: 0.7809 - val_loss: 0.4542\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 5.6964\n",
      "Function value obtained: -0.7780\n",
      "Current minimum: -0.7999\n",
      "Iteration No: 6 started. Evaluating function at random point.\n",
      "Epoch 1/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7223 - loss: 0.5748 - val_accuracy: 0.7700 - val_loss: 0.4723\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 0.7710 - loss: 0.4680 - val_accuracy: 0.7729 - val_loss: 0.4724\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - accuracy: 0.7733 - loss: 0.4716 - val_accuracy: 0.7723 - val_loss: 0.4523\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - accuracy: 0.7793 - loss: 0.4509 - val_accuracy: 0.7740 - val_loss: 0.4580\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - accuracy: 0.7957 - loss: 0.4347 - val_accuracy: 0.7734 - val_loss: 0.4629\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 0.7965 - loss: 0.4478 - val_accuracy: 0.7809 - val_loss: 0.4691\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - accuracy: 0.7914 - loss: 0.4399 - val_accuracy: 0.7769 - val_loss: 0.4438\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - accuracy: 0.7834 - loss: 0.4491 - val_accuracy: 0.7821 - val_loss: 0.4567\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 0.7947 - loss: 0.4337 - val_accuracy: 0.7826 - val_loss: 0.4278\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - accuracy: 0.7908 - loss: 0.4306 - val_accuracy: 0.7780 - val_loss: 0.4420\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7854 - loss: 0.4302 - val_accuracy: 0.7844 - val_loss: 0.4541\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7908 - loss: 0.4429 - val_accuracy: 0.7780 - val_loss: 0.4475\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7876 - loss: 0.4353 - val_accuracy: 0.7752 - val_loss: 0.4653\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7945 - loss: 0.4333 - val_accuracy: 0.7867 - val_loss: 0.4542\n",
      "Epoch 15/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7954 - loss: 0.4266 - val_accuracy: 0.7821 - val_loss: 0.4346\n",
      "Epoch 16/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - accuracy: 0.7981 - loss: 0.4248 - val_accuracy: 0.7821 - val_loss: 0.4655\n",
      "Epoch 17/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - accuracy: 0.7863 - loss: 0.4276 - val_accuracy: 0.7757 - val_loss: 0.4640\n",
      "Epoch 18/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - accuracy: 0.7980 - loss: 0.4373 - val_accuracy: 0.7780 - val_loss: 0.4601\n",
      "Epoch 19/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - accuracy: 0.7958 - loss: 0.4334 - val_accuracy: 0.7918 - val_loss: 0.4277\n",
      "Epoch 20/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7967 - loss: 0.4158 - val_accuracy: 0.7895 - val_loss: 0.4225\n",
      "Epoch 21/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8005 - loss: 0.4167 - val_accuracy: 0.7890 - val_loss: 0.4218\n",
      "Epoch 22/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - accuracy: 0.8010 - loss: 0.4158 - val_accuracy: 0.7901 - val_loss: 0.4233\n",
      "Epoch 23/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - accuracy: 0.7955 - loss: 0.4226 - val_accuracy: 0.7769 - val_loss: 0.4809\n",
      "Epoch 24/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - accuracy: 0.8074 - loss: 0.4121 - val_accuracy: 0.7752 - val_loss: 0.4294\n",
      "Epoch 25/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - accuracy: 0.7988 - loss: 0.4111 - val_accuracy: 0.7890 - val_loss: 0.4225\n",
      "Epoch 26/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - accuracy: 0.7966 - loss: 0.4206 - val_accuracy: 0.7694 - val_loss: 0.4753\n",
      "Epoch 27/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - accuracy: 0.7948 - loss: 0.4257 - val_accuracy: 0.7844 - val_loss: 0.4384\n",
      "Epoch 28/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8056 - loss: 0.4128 - val_accuracy: 0.7861 - val_loss: 0.4216\n",
      "Epoch 29/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - accuracy: 0.7855 - loss: 0.4240 - val_accuracy: 0.7861 - val_loss: 0.4320\n",
      "Epoch 30/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - accuracy: 0.8098 - loss: 0.4155 - val_accuracy: 0.7901 - val_loss: 0.4285\n",
      "Epoch 31/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - accuracy: 0.7952 - loss: 0.4244 - val_accuracy: 0.7809 - val_loss: 0.4408\n",
      "Epoch 32/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - accuracy: 0.7967 - loss: 0.4184 - val_accuracy: 0.7867 - val_loss: 0.4258\n",
      "Epoch 33/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - accuracy: 0.7968 - loss: 0.4184 - val_accuracy: 0.7861 - val_loss: 0.4391\n",
      "Epoch 34/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - accuracy: 0.7984 - loss: 0.4178 - val_accuracy: 0.7918 - val_loss: 0.4263\n",
      "Epoch 35/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - accuracy: 0.7976 - loss: 0.4211 - val_accuracy: 0.7809 - val_loss: 0.4390\n",
      "Epoch 36/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - accuracy: 0.7885 - loss: 0.4301 - val_accuracy: 0.7890 - val_loss: 0.4383\n",
      "Epoch 37/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - accuracy: 0.7863 - loss: 0.4440 - val_accuracy: 0.7924 - val_loss: 0.4199\n",
      "Epoch 38/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - accuracy: 0.8082 - loss: 0.4098 - val_accuracy: 0.7872 - val_loss: 0.4294\n",
      "Epoch 39/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step - accuracy: 0.8044 - loss: 0.4211 - val_accuracy: 0.7798 - val_loss: 0.4363\n",
      "Epoch 40/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - accuracy: 0.7992 - loss: 0.4101 - val_accuracy: 0.7936 - val_loss: 0.4293\n",
      "Epoch 41/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step - accuracy: 0.7964 - loss: 0.4205 - val_accuracy: 0.7930 - val_loss: 0.4281\n",
      "Epoch 42/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - accuracy: 0.7982 - loss: 0.4092 - val_accuracy: 0.7941 - val_loss: 0.4170\n",
      "Epoch 43/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 0.8062 - loss: 0.3967 - val_accuracy: 0.7918 - val_loss: 0.4528\n",
      "Epoch 44/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8027 - loss: 0.4270 - val_accuracy: 0.7941 - val_loss: 0.4323\n",
      "Epoch 45/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - accuracy: 0.7965 - loss: 0.4100 - val_accuracy: 0.7947 - val_loss: 0.4301\n",
      "Epoch 46/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8046 - loss: 0.4098 - val_accuracy: 0.7844 - val_loss: 0.4276\n",
      "Epoch 47/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - accuracy: 0.7998 - loss: 0.4180 - val_accuracy: 0.7970 - val_loss: 0.4204\n",
      "Epoch 48/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - accuracy: 0.8067 - loss: 0.4171 - val_accuracy: 0.7723 - val_loss: 0.4694\n",
      "Epoch 49/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - accuracy: 0.8068 - loss: 0.4194 - val_accuracy: 0.8005 - val_loss: 0.4296\n",
      "Epoch 50/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8050 - loss: 0.4024 - val_accuracy: 0.7855 - val_loss: 0.4276\n",
      "Iteration No: 6 ended. Evaluation done at random point.\n",
      "Time taken: 11.7522\n",
      "Function value obtained: -0.7941\n",
      "Current minimum: -0.7999\n",
      "Iteration No: 7 started. Evaluating function at random point.\n",
      "Epoch 1/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6992 - loss: 0.5607 - val_accuracy: 0.7683 - val_loss: 0.4661\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7851 - loss: 0.4620 - val_accuracy: 0.7775 - val_loss: 0.4410\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7936 - loss: 0.4402 - val_accuracy: 0.7809 - val_loss: 0.4379\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7863 - loss: 0.4479 - val_accuracy: 0.7907 - val_loss: 0.4424\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7916 - loss: 0.4319 - val_accuracy: 0.7861 - val_loss: 0.4331\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8066 - loss: 0.4251 - val_accuracy: 0.7832 - val_loss: 0.4281\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7982 - loss: 0.4220 - val_accuracy: 0.7867 - val_loss: 0.4280\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8062 - loss: 0.4176 - val_accuracy: 0.7855 - val_loss: 0.4284\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8060 - loss: 0.4112 - val_accuracy: 0.7798 - val_loss: 0.4294\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8000 - loss: 0.4133 - val_accuracy: 0.7924 - val_loss: 0.4254\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8093 - loss: 0.4145 - val_accuracy: 0.7821 - val_loss: 0.4218\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8129 - loss: 0.4050 - val_accuracy: 0.7924 - val_loss: 0.4186\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8057 - loss: 0.4087 - val_accuracy: 0.7913 - val_loss: 0.4187\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8004 - loss: 0.4164 - val_accuracy: 0.7838 - val_loss: 0.4232\n",
      "Epoch 15/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8119 - loss: 0.4008 - val_accuracy: 0.7861 - val_loss: 0.4226\n",
      "Epoch 16/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8122 - loss: 0.3958 - val_accuracy: 0.7849 - val_loss: 0.4209\n",
      "Epoch 17/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8103 - loss: 0.4035 - val_accuracy: 0.7872 - val_loss: 0.4184\n",
      "Epoch 18/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8075 - loss: 0.3979 - val_accuracy: 0.7849 - val_loss: 0.4192\n",
      "Epoch 19/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8146 - loss: 0.3904 - val_accuracy: 0.7907 - val_loss: 0.4211\n",
      "Epoch 20/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8178 - loss: 0.3888 - val_accuracy: 0.7964 - val_loss: 0.4194\n",
      "Epoch 21/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8133 - loss: 0.4053 - val_accuracy: 0.7872 - val_loss: 0.4206\n",
      "Epoch 22/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8120 - loss: 0.3947 - val_accuracy: 0.7872 - val_loss: 0.4130\n",
      "Epoch 23/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8195 - loss: 0.3943 - val_accuracy: 0.7878 - val_loss: 0.4169\n",
      "Epoch 24/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8097 - loss: 0.3951 - val_accuracy: 0.7901 - val_loss: 0.4118\n",
      "Epoch 25/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8078 - loss: 0.4002 - val_accuracy: 0.7913 - val_loss: 0.4156\n",
      "Epoch 26/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8143 - loss: 0.3975 - val_accuracy: 0.7901 - val_loss: 0.4188\n",
      "Epoch 27/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8085 - loss: 0.3942 - val_accuracy: 0.7918 - val_loss: 0.4104\n",
      "Epoch 28/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8244 - loss: 0.3783 - val_accuracy: 0.7976 - val_loss: 0.4176\n",
      "Epoch 29/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8160 - loss: 0.3828 - val_accuracy: 0.7936 - val_loss: 0.4134\n",
      "Epoch 30/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8182 - loss: 0.3906 - val_accuracy: 0.7947 - val_loss: 0.4107\n",
      "Epoch 31/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8157 - loss: 0.3829 - val_accuracy: 0.7930 - val_loss: 0.4119\n",
      "Epoch 32/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8100 - loss: 0.4026 - val_accuracy: 0.7890 - val_loss: 0.4139\n",
      "Epoch 33/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8216 - loss: 0.3825 - val_accuracy: 0.7867 - val_loss: 0.4115\n",
      "Epoch 34/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8146 - loss: 0.3896 - val_accuracy: 0.7930 - val_loss: 0.4228\n",
      "Epoch 35/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8220 - loss: 0.3792 - val_accuracy: 0.7907 - val_loss: 0.4136\n",
      "Epoch 36/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8045 - loss: 0.4027 - val_accuracy: 0.7964 - val_loss: 0.4114\n",
      "Epoch 37/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8128 - loss: 0.3800 - val_accuracy: 0.7895 - val_loss: 0.4163\n",
      "Iteration No: 7 ended. Evaluation done at random point.\n",
      "Time taken: 10.5346\n",
      "Function value obtained: -0.7918\n",
      "Current minimum: -0.7999\n",
      "Iteration No: 8 started. Evaluating function at random point.\n",
      "Epoch 1/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648us/step - accuracy: 0.6879 - loss: 0.5709 - val_accuracy: 0.7717 - val_loss: 0.4634\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - accuracy: 0.8009 - loss: 0.4367 - val_accuracy: 0.7803 - val_loss: 0.4474\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - accuracy: 0.7927 - loss: 0.4238 - val_accuracy: 0.7844 - val_loss: 0.4419\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - accuracy: 0.8082 - loss: 0.4141 - val_accuracy: 0.7838 - val_loss: 0.4392\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.8010 - loss: 0.4196 - val_accuracy: 0.7872 - val_loss: 0.4335\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.8049 - loss: 0.4095 - val_accuracy: 0.7746 - val_loss: 0.4336\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.8070 - loss: 0.4135 - val_accuracy: 0.7809 - val_loss: 0.4460\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - accuracy: 0.7962 - loss: 0.4160 - val_accuracy: 0.7798 - val_loss: 0.4397\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - accuracy: 0.8020 - loss: 0.4112 - val_accuracy: 0.7826 - val_loss: 0.4353\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - accuracy: 0.8038 - loss: 0.4119 - val_accuracy: 0.7821 - val_loss: 0.4298\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.8063 - loss: 0.4034 - val_accuracy: 0.7872 - val_loss: 0.4252\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.8129 - loss: 0.3976 - val_accuracy: 0.7803 - val_loss: 0.4324\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - accuracy: 0.8037 - loss: 0.4061 - val_accuracy: 0.7821 - val_loss: 0.4297\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.8030 - loss: 0.4072 - val_accuracy: 0.7849 - val_loss: 0.4261\n",
      "Epoch 15/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - accuracy: 0.8126 - loss: 0.3871 - val_accuracy: 0.7821 - val_loss: 0.4256\n",
      "Epoch 16/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - accuracy: 0.8077 - loss: 0.4049 - val_accuracy: 0.7809 - val_loss: 0.4307\n",
      "Epoch 17/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.8095 - loss: 0.4014 - val_accuracy: 0.7803 - val_loss: 0.4247\n",
      "Epoch 18/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.8003 - loss: 0.4155 - val_accuracy: 0.7826 - val_loss: 0.4317\n",
      "Epoch 19/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.8076 - loss: 0.4029 - val_accuracy: 0.7844 - val_loss: 0.4243\n",
      "Epoch 20/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.8132 - loss: 0.4001 - val_accuracy: 0.7867 - val_loss: 0.4245\n",
      "Epoch 21/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.8066 - loss: 0.4042 - val_accuracy: 0.7838 - val_loss: 0.4284\n",
      "Epoch 22/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.8125 - loss: 0.3902 - val_accuracy: 0.7844 - val_loss: 0.4235\n",
      "Epoch 23/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - accuracy: 0.8096 - loss: 0.3887 - val_accuracy: 0.7826 - val_loss: 0.4247\n",
      "Epoch 24/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - accuracy: 0.8042 - loss: 0.4007 - val_accuracy: 0.7890 - val_loss: 0.4234\n",
      "Epoch 25/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - accuracy: 0.8180 - loss: 0.3841 - val_accuracy: 0.7798 - val_loss: 0.4239\n",
      "Epoch 26/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.8191 - loss: 0.3839 - val_accuracy: 0.7918 - val_loss: 0.4192\n",
      "Epoch 27/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - accuracy: 0.8127 - loss: 0.3874 - val_accuracy: 0.7832 - val_loss: 0.4217\n",
      "Epoch 28/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.8175 - loss: 0.3913 - val_accuracy: 0.7913 - val_loss: 0.4279\n",
      "Epoch 29/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.8066 - loss: 0.3954 - val_accuracy: 0.7861 - val_loss: 0.4233\n",
      "Epoch 30/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.8185 - loss: 0.3847 - val_accuracy: 0.7901 - val_loss: 0.4180\n",
      "Epoch 31/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.8169 - loss: 0.3837 - val_accuracy: 0.7878 - val_loss: 0.4238\n",
      "Epoch 32/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376us/step - accuracy: 0.8119 - loss: 0.3978 - val_accuracy: 0.7872 - val_loss: 0.4199\n",
      "Epoch 33/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - accuracy: 0.8171 - loss: 0.3921 - val_accuracy: 0.7821 - val_loss: 0.4239\n",
      "Epoch 34/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376us/step - accuracy: 0.8153 - loss: 0.3850 - val_accuracy: 0.7924 - val_loss: 0.4198\n",
      "Epoch 35/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - accuracy: 0.8169 - loss: 0.3849 - val_accuracy: 0.7884 - val_loss: 0.4215\n",
      "Epoch 36/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.8175 - loss: 0.3823 - val_accuracy: 0.7867 - val_loss: 0.4182\n",
      "Epoch 37/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.8083 - loss: 0.3827 - val_accuracy: 0.7953 - val_loss: 0.4185\n",
      "Epoch 38/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - accuracy: 0.8165 - loss: 0.3886 - val_accuracy: 0.7861 - val_loss: 0.4237\n",
      "Epoch 39/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375us/step - accuracy: 0.8142 - loss: 0.3949 - val_accuracy: 0.7895 - val_loss: 0.4262\n",
      "Epoch 40/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - accuracy: 0.8212 - loss: 0.3817 - val_accuracy: 0.7918 - val_loss: 0.4216\n",
      "Iteration No: 8 ended. Evaluation done at random point.\n",
      "Time taken: 4.3380\n",
      "Function value obtained: -0.7901\n",
      "Current minimum: -0.7999\n",
      "Iteration No: 9 started. Evaluating function at random point.\n",
      "Epoch 1/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7177 - loss: 0.5589 - val_accuracy: 0.7711 - val_loss: 0.4568\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7844 - loss: 0.4486 - val_accuracy: 0.7832 - val_loss: 0.4476\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7918 - loss: 0.4380 - val_accuracy: 0.7844 - val_loss: 0.4464\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8017 - loss: 0.4154 - val_accuracy: 0.7803 - val_loss: 0.4442\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8042 - loss: 0.4250 - val_accuracy: 0.7792 - val_loss: 0.4358\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7986 - loss: 0.4127 - val_accuracy: 0.7861 - val_loss: 0.4345\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8052 - loss: 0.4077 - val_accuracy: 0.7803 - val_loss: 0.4333\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8043 - loss: 0.4123 - val_accuracy: 0.7838 - val_loss: 0.4284\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8023 - loss: 0.4029 - val_accuracy: 0.7924 - val_loss: 0.4278\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8071 - loss: 0.3989 - val_accuracy: 0.7861 - val_loss: 0.4301\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8066 - loss: 0.3982 - val_accuracy: 0.7844 - val_loss: 0.4243\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8119 - loss: 0.3964 - val_accuracy: 0.7913 - val_loss: 0.4201\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8121 - loss: 0.3902 - val_accuracy: 0.7901 - val_loss: 0.4220\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8049 - loss: 0.4007 - val_accuracy: 0.7849 - val_loss: 0.4250\n",
      "Epoch 15/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8188 - loss: 0.3846 - val_accuracy: 0.7844 - val_loss: 0.4215\n",
      "Epoch 16/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8076 - loss: 0.3930 - val_accuracy: 0.7907 - val_loss: 0.4264\n",
      "Epoch 17/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8123 - loss: 0.3957 - val_accuracy: 0.7890 - val_loss: 0.4185\n",
      "Epoch 18/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8153 - loss: 0.3898 - val_accuracy: 0.7890 - val_loss: 0.4196\n",
      "Epoch 19/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8163 - loss: 0.3809 - val_accuracy: 0.7861 - val_loss: 0.4273\n",
      "Epoch 20/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8096 - loss: 0.3865 - val_accuracy: 0.7826 - val_loss: 0.4227\n",
      "Epoch 21/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8207 - loss: 0.3808 - val_accuracy: 0.7964 - val_loss: 0.4151\n",
      "Epoch 22/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8265 - loss: 0.3703 - val_accuracy: 0.7953 - val_loss: 0.4212\n",
      "Epoch 23/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8205 - loss: 0.3749 - val_accuracy: 0.7907 - val_loss: 0.4169\n",
      "Epoch 24/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8186 - loss: 0.3775 - val_accuracy: 0.7907 - val_loss: 0.4183\n",
      "Epoch 25/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8272 - loss: 0.3680 - val_accuracy: 0.7918 - val_loss: 0.4182\n",
      "Epoch 26/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8191 - loss: 0.3801 - val_accuracy: 0.7901 - val_loss: 0.4185\n",
      "Epoch 27/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8251 - loss: 0.3636 - val_accuracy: 0.7872 - val_loss: 0.4147\n",
      "Epoch 28/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8287 - loss: 0.3715 - val_accuracy: 0.7936 - val_loss: 0.4183\n",
      "Epoch 29/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8209 - loss: 0.3616 - val_accuracy: 0.7907 - val_loss: 0.4195\n",
      "Epoch 30/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8258 - loss: 0.3664 - val_accuracy: 0.7907 - val_loss: 0.4257\n",
      "Epoch 31/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8232 - loss: 0.3750 - val_accuracy: 0.7941 - val_loss: 0.4175\n",
      "Epoch 32/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8179 - loss: 0.3609 - val_accuracy: 0.7901 - val_loss: 0.4185\n",
      "Epoch 33/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8213 - loss: 0.3661 - val_accuracy: 0.7993 - val_loss: 0.4201\n",
      "Epoch 34/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8275 - loss: 0.3655 - val_accuracy: 0.7936 - val_loss: 0.4236\n",
      "Epoch 35/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8275 - loss: 0.3581 - val_accuracy: 0.7953 - val_loss: 0.4149\n",
      "Epoch 36/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8221 - loss: 0.3661 - val_accuracy: 0.7976 - val_loss: 0.4165\n",
      "Epoch 37/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8157 - loss: 0.3653 - val_accuracy: 0.7895 - val_loss: 0.4198\n",
      "Iteration No: 9 ended. Evaluation done at random point.\n",
      "Time taken: 19.0603\n",
      "Function value obtained: -0.7872\n",
      "Current minimum: -0.7999\n",
      "Iteration No: 10 started. Evaluating function at random point.\n",
      "Epoch 1/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6241 - loss: 0.6490 - val_accuracy: 0.7614 - val_loss: 0.4976\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7696 - loss: 0.4912 - val_accuracy: 0.7671 - val_loss: 0.4654\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7822 - loss: 0.4591 - val_accuracy: 0.7763 - val_loss: 0.4591\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7836 - loss: 0.4492 - val_accuracy: 0.7832 - val_loss: 0.4552\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7860 - loss: 0.4446 - val_accuracy: 0.7855 - val_loss: 0.4528\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7879 - loss: 0.4404 - val_accuracy: 0.7826 - val_loss: 0.4517\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7950 - loss: 0.4327 - val_accuracy: 0.7838 - val_loss: 0.4503\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7918 - loss: 0.4460 - val_accuracy: 0.7890 - val_loss: 0.4476\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7910 - loss: 0.4326 - val_accuracy: 0.7849 - val_loss: 0.4447\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7936 - loss: 0.4316 - val_accuracy: 0.7844 - val_loss: 0.4429\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7985 - loss: 0.4251 - val_accuracy: 0.7855 - val_loss: 0.4410\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8040 - loss: 0.4198 - val_accuracy: 0.7855 - val_loss: 0.4412\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7946 - loss: 0.4296 - val_accuracy: 0.7861 - val_loss: 0.4391\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7994 - loss: 0.4205 - val_accuracy: 0.7844 - val_loss: 0.4407\n",
      "Epoch 15/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7981 - loss: 0.4185 - val_accuracy: 0.7826 - val_loss: 0.4361\n",
      "Epoch 16/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8040 - loss: 0.4221 - val_accuracy: 0.7861 - val_loss: 0.4358\n",
      "Epoch 17/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7996 - loss: 0.4211 - val_accuracy: 0.7780 - val_loss: 0.4410\n",
      "Epoch 18/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7944 - loss: 0.4281 - val_accuracy: 0.7844 - val_loss: 0.4338\n",
      "Epoch 19/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7985 - loss: 0.4250 - val_accuracy: 0.7803 - val_loss: 0.4343\n",
      "Epoch 20/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7923 - loss: 0.4285 - val_accuracy: 0.7844 - val_loss: 0.4351\n",
      "Epoch 21/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7984 - loss: 0.4207 - val_accuracy: 0.7815 - val_loss: 0.4317\n",
      "Epoch 22/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8005 - loss: 0.4210 - val_accuracy: 0.7821 - val_loss: 0.4328\n",
      "Epoch 23/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8137 - loss: 0.4136 - val_accuracy: 0.7786 - val_loss: 0.4319\n",
      "Epoch 24/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7991 - loss: 0.4160 - val_accuracy: 0.7786 - val_loss: 0.4328\n",
      "Epoch 25/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8024 - loss: 0.4224 - val_accuracy: 0.7757 - val_loss: 0.4326\n",
      "Epoch 26/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8159 - loss: 0.4040 - val_accuracy: 0.7798 - val_loss: 0.4298\n",
      "Epoch 27/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8022 - loss: 0.4147 - val_accuracy: 0.7798 - val_loss: 0.4354\n",
      "Epoch 28/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7998 - loss: 0.4108 - val_accuracy: 0.7844 - val_loss: 0.4311\n",
      "Epoch 29/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8067 - loss: 0.4000 - val_accuracy: 0.7838 - val_loss: 0.4288\n",
      "Epoch 30/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8072 - loss: 0.4094 - val_accuracy: 0.7861 - val_loss: 0.4281\n",
      "Epoch 31/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8052 - loss: 0.3996 - val_accuracy: 0.7855 - val_loss: 0.4278\n",
      "Epoch 32/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8068 - loss: 0.4052 - val_accuracy: 0.7867 - val_loss: 0.4267\n",
      "Epoch 33/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8058 - loss: 0.4105 - val_accuracy: 0.7844 - val_loss: 0.4268\n",
      "Epoch 34/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8075 - loss: 0.4015 - val_accuracy: 0.7861 - val_loss: 0.4279\n",
      "Epoch 35/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8105 - loss: 0.4002 - val_accuracy: 0.7872 - val_loss: 0.4248\n",
      "Epoch 36/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8051 - loss: 0.4086 - val_accuracy: 0.7895 - val_loss: 0.4248\n",
      "Epoch 37/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7945 - loss: 0.4187 - val_accuracy: 0.7849 - val_loss: 0.4264\n",
      "Epoch 38/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8138 - loss: 0.3893 - val_accuracy: 0.7884 - val_loss: 0.4239\n",
      "Epoch 39/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8113 - loss: 0.3982 - val_accuracy: 0.7890 - val_loss: 0.4233\n",
      "Epoch 40/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8113 - loss: 0.3975 - val_accuracy: 0.7849 - val_loss: 0.4263\n",
      "Epoch 41/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8184 - loss: 0.3912 - val_accuracy: 0.7849 - val_loss: 0.4275\n",
      "Epoch 42/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8092 - loss: 0.4021 - val_accuracy: 0.7861 - val_loss: 0.4247\n",
      "Epoch 43/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8102 - loss: 0.3955 - val_accuracy: 0.7884 - val_loss: 0.4231\n",
      "Epoch 44/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8094 - loss: 0.3962 - val_accuracy: 0.7867 - val_loss: 0.4216\n",
      "Epoch 45/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8055 - loss: 0.4029 - val_accuracy: 0.7878 - val_loss: 0.4235\n",
      "Epoch 46/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8180 - loss: 0.3850 - val_accuracy: 0.7821 - val_loss: 0.4218\n",
      "Epoch 47/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8062 - loss: 0.4083 - val_accuracy: 0.7855 - val_loss: 0.4221\n",
      "Epoch 48/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8093 - loss: 0.4019 - val_accuracy: 0.7838 - val_loss: 0.4259\n",
      "Epoch 49/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8123 - loss: 0.4031 - val_accuracy: 0.7913 - val_loss: 0.4211\n",
      "Epoch 50/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8097 - loss: 0.3915 - val_accuracy: 0.7878 - val_loss: 0.4223\n",
      "Iteration No: 10 ended. Evaluation done at random point.\n",
      "Time taken: 13.1190\n",
      "Function value obtained: -0.7913\n",
      "Current minimum: -0.7999\n",
      "Iteration No: 11 started. Searching for the next optimal point.\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rahulnundlall/anaconda3/envs/ML/lib/python3.12/site-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 597us/step - accuracy: 0.5174 - loss: 0.7565 - val_accuracy: 0.7303 - val_loss: 0.5704\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348us/step - accuracy: 0.6795 - loss: 0.5973 - val_accuracy: 0.7568 - val_loss: 0.5128\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344us/step - accuracy: 0.7352 - loss: 0.5359 - val_accuracy: 0.7596 - val_loss: 0.4886\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341us/step - accuracy: 0.7638 - loss: 0.4947 - val_accuracy: 0.7585 - val_loss: 0.4768\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345us/step - accuracy: 0.7684 - loss: 0.4941 - val_accuracy: 0.7608 - val_loss: 0.4714\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343us/step - accuracy: 0.7615 - loss: 0.4858 - val_accuracy: 0.7648 - val_loss: 0.4678\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347us/step - accuracy: 0.7800 - loss: 0.4742 - val_accuracy: 0.7677 - val_loss: 0.4666\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342us/step - accuracy: 0.7757 - loss: 0.4758 - val_accuracy: 0.7677 - val_loss: 0.4655\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345us/step - accuracy: 0.7723 - loss: 0.4743 - val_accuracy: 0.7706 - val_loss: 0.4643\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345us/step - accuracy: 0.7771 - loss: 0.4616 - val_accuracy: 0.7717 - val_loss: 0.4638\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339us/step - accuracy: 0.7780 - loss: 0.4616 - val_accuracy: 0.7706 - val_loss: 0.4633\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340us/step - accuracy: 0.7852 - loss: 0.4509 - val_accuracy: 0.7706 - val_loss: 0.4628\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348us/step - accuracy: 0.7857 - loss: 0.4514 - val_accuracy: 0.7717 - val_loss: 0.4625\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344us/step - accuracy: 0.7818 - loss: 0.4528 - val_accuracy: 0.7729 - val_loss: 0.4619\n",
      "Epoch 15/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343us/step - accuracy: 0.7767 - loss: 0.4673 - val_accuracy: 0.7706 - val_loss: 0.4625\n",
      "Epoch 16/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337us/step - accuracy: 0.7795 - loss: 0.4624 - val_accuracy: 0.7723 - val_loss: 0.4616\n",
      "Epoch 17/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332us/step - accuracy: 0.7798 - loss: 0.4621 - val_accuracy: 0.7717 - val_loss: 0.4609\n",
      "Epoch 18/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353us/step - accuracy: 0.7870 - loss: 0.4540 - val_accuracy: 0.7740 - val_loss: 0.4609\n",
      "Epoch 19/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375us/step - accuracy: 0.7781 - loss: 0.4497 - val_accuracy: 0.7746 - val_loss: 0.4615\n",
      "Epoch 20/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351us/step - accuracy: 0.7801 - loss: 0.4605 - val_accuracy: 0.7740 - val_loss: 0.4614\n",
      "Epoch 21/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348us/step - accuracy: 0.7885 - loss: 0.4496 - val_accuracy: 0.7746 - val_loss: 0.4610\n",
      "Epoch 22/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344us/step - accuracy: 0.7892 - loss: 0.4458 - val_accuracy: 0.7729 - val_loss: 0.4610\n",
      "Epoch 23/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345us/step - accuracy: 0.7866 - loss: 0.4524 - val_accuracy: 0.7723 - val_loss: 0.4604\n",
      "Epoch 24/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343us/step - accuracy: 0.7876 - loss: 0.4498 - val_accuracy: 0.7746 - val_loss: 0.4605\n",
      "Epoch 25/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353us/step - accuracy: 0.7820 - loss: 0.4579 - val_accuracy: 0.7723 - val_loss: 0.4606\n",
      "Epoch 26/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358us/step - accuracy: 0.7905 - loss: 0.4429 - val_accuracy: 0.7729 - val_loss: 0.4604\n",
      "Epoch 27/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - accuracy: 0.7969 - loss: 0.4397 - val_accuracy: 0.7757 - val_loss: 0.4603\n",
      "Epoch 28/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345us/step - accuracy: 0.7791 - loss: 0.4497 - val_accuracy: 0.7706 - val_loss: 0.4604\n",
      "Epoch 29/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348us/step - accuracy: 0.7894 - loss: 0.4493 - val_accuracy: 0.7729 - val_loss: 0.4600\n",
      "Epoch 30/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step - accuracy: 0.7999 - loss: 0.4317 - val_accuracy: 0.7723 - val_loss: 0.4595\n",
      "Epoch 31/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354us/step - accuracy: 0.7905 - loss: 0.4493 - val_accuracy: 0.7769 - val_loss: 0.4596\n",
      "Epoch 32/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343us/step - accuracy: 0.7928 - loss: 0.4395 - val_accuracy: 0.7734 - val_loss: 0.4602\n",
      "Epoch 33/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336us/step - accuracy: 0.7913 - loss: 0.4504 - val_accuracy: 0.7746 - val_loss: 0.4597\n",
      "Epoch 34/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - accuracy: 0.7929 - loss: 0.4494 - val_accuracy: 0.7769 - val_loss: 0.4593\n",
      "Epoch 35/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344us/step - accuracy: 0.7901 - loss: 0.4433 - val_accuracy: 0.7752 - val_loss: 0.4595\n",
      "Epoch 36/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343us/step - accuracy: 0.7900 - loss: 0.4457 - val_accuracy: 0.7734 - val_loss: 0.4595\n",
      "Epoch 37/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - accuracy: 0.7946 - loss: 0.4435 - val_accuracy: 0.7752 - val_loss: 0.4594\n",
      "Epoch 38/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - accuracy: 0.7916 - loss: 0.4479 - val_accuracy: 0.7752 - val_loss: 0.4594\n",
      "Epoch 39/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336us/step - accuracy: 0.7888 - loss: 0.4480 - val_accuracy: 0.7752 - val_loss: 0.4585\n",
      "Epoch 40/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step - accuracy: 0.7961 - loss: 0.4425 - val_accuracy: 0.7763 - val_loss: 0.4587\n",
      "Epoch 41/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336us/step - accuracy: 0.7902 - loss: 0.4450 - val_accuracy: 0.7757 - val_loss: 0.4585\n",
      "Epoch 42/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336us/step - accuracy: 0.7978 - loss: 0.4339 - val_accuracy: 0.7734 - val_loss: 0.4583\n",
      "Epoch 43/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - accuracy: 0.7929 - loss: 0.4437 - val_accuracy: 0.7757 - val_loss: 0.4586\n",
      "Epoch 44/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336us/step - accuracy: 0.7968 - loss: 0.4318 - val_accuracy: 0.7752 - val_loss: 0.4582\n",
      "Epoch 45/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356us/step - accuracy: 0.7924 - loss: 0.4415 - val_accuracy: 0.7757 - val_loss: 0.4586\n",
      "Epoch 46/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345us/step - accuracy: 0.7952 - loss: 0.4384 - val_accuracy: 0.7757 - val_loss: 0.4585\n",
      "Epoch 47/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344us/step - accuracy: 0.7937 - loss: 0.4429 - val_accuracy: 0.7729 - val_loss: 0.4580\n",
      "Epoch 48/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342us/step - accuracy: 0.7897 - loss: 0.4492 - val_accuracy: 0.7752 - val_loss: 0.4586\n",
      "Epoch 49/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342us/step - accuracy: 0.7881 - loss: 0.4537 - val_accuracy: 0.7757 - val_loss: 0.4585\n",
      "Epoch 50/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346us/step - accuracy: 0.7893 - loss: 0.4510 - val_accuracy: 0.7746 - val_loss: 0.4582\n",
      "Iteration No: 11 ended. Search finished for the next optimal point.\n",
      "Time taken: 5.0567\n",
      "Function value obtained: -0.7729\n",
      "Current minimum: -0.7999\n",
      "Iteration No: 12 started. Searching for the next optimal point.\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rahulnundlall/anaconda3/envs/ML/lib/python3.12/site-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - accuracy: 0.6888 - loss: 0.5863 - val_accuracy: 0.7556 - val_loss: 0.4771\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.7841 - loss: 0.4585 - val_accuracy: 0.7711 - val_loss: 0.4704\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - accuracy: 0.7751 - loss: 0.4595 - val_accuracy: 0.7700 - val_loss: 0.4643\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - accuracy: 0.7910 - loss: 0.4490 - val_accuracy: 0.7688 - val_loss: 0.4626\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step - accuracy: 0.7935 - loss: 0.4354 - val_accuracy: 0.7723 - val_loss: 0.4623\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - accuracy: 0.7852 - loss: 0.4527 - val_accuracy: 0.7711 - val_loss: 0.4618\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step - accuracy: 0.7842 - loss: 0.4493 - val_accuracy: 0.7740 - val_loss: 0.4631\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - accuracy: 0.7853 - loss: 0.4433 - val_accuracy: 0.7694 - val_loss: 0.4632\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - accuracy: 0.7897 - loss: 0.4400 - val_accuracy: 0.7688 - val_loss: 0.4629\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - accuracy: 0.7896 - loss: 0.4390 - val_accuracy: 0.7780 - val_loss: 0.4611\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - accuracy: 0.7959 - loss: 0.4398 - val_accuracy: 0.7746 - val_loss: 0.4609\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - accuracy: 0.7889 - loss: 0.4444 - val_accuracy: 0.7734 - val_loss: 0.4641\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step - accuracy: 0.7847 - loss: 0.4502 - val_accuracy: 0.7752 - val_loss: 0.4623\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - accuracy: 0.7900 - loss: 0.4392 - val_accuracy: 0.7746 - val_loss: 0.4603\n",
      "Epoch 15/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - accuracy: 0.7867 - loss: 0.4476 - val_accuracy: 0.7746 - val_loss: 0.4614\n",
      "Epoch 16/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - accuracy: 0.7830 - loss: 0.4507 - val_accuracy: 0.7769 - val_loss: 0.4604\n",
      "Epoch 17/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.7957 - loss: 0.4427 - val_accuracy: 0.7734 - val_loss: 0.4618\n",
      "Epoch 18/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step - accuracy: 0.7877 - loss: 0.4394 - val_accuracy: 0.7775 - val_loss: 0.4605\n",
      "Epoch 19/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - accuracy: 0.7921 - loss: 0.4427 - val_accuracy: 0.7757 - val_loss: 0.4613\n",
      "Epoch 20/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - accuracy: 0.7868 - loss: 0.4535 - val_accuracy: 0.7746 - val_loss: 0.4616\n",
      "Epoch 21/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.7945 - loss: 0.4426 - val_accuracy: 0.7706 - val_loss: 0.4614\n",
      "Epoch 22/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - accuracy: 0.7879 - loss: 0.4348 - val_accuracy: 0.7757 - val_loss: 0.4600\n",
      "Epoch 23/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - accuracy: 0.7931 - loss: 0.4385 - val_accuracy: 0.7740 - val_loss: 0.4592\n",
      "Epoch 24/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - accuracy: 0.7799 - loss: 0.4453 - val_accuracy: 0.7740 - val_loss: 0.4601\n",
      "Epoch 25/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.7891 - loss: 0.4466 - val_accuracy: 0.7746 - val_loss: 0.4608\n",
      "Epoch 26/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - accuracy: 0.7862 - loss: 0.4453 - val_accuracy: 0.7717 - val_loss: 0.4600\n",
      "Epoch 27/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - accuracy: 0.7895 - loss: 0.4486 - val_accuracy: 0.7740 - val_loss: 0.4592\n",
      "Epoch 28/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.7971 - loss: 0.4355 - val_accuracy: 0.7729 - val_loss: 0.4604\n",
      "Epoch 29/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - accuracy: 0.7930 - loss: 0.4380 - val_accuracy: 0.7734 - val_loss: 0.4603\n",
      "Epoch 30/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - accuracy: 0.7961 - loss: 0.4322 - val_accuracy: 0.7769 - val_loss: 0.4593\n",
      "Epoch 31/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - accuracy: 0.7950 - loss: 0.4375 - val_accuracy: 0.7723 - val_loss: 0.4593\n",
      "Epoch 32/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - accuracy: 0.7935 - loss: 0.4409 - val_accuracy: 0.7723 - val_loss: 0.4592\n",
      "Epoch 33/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - accuracy: 0.7974 - loss: 0.4350 - val_accuracy: 0.7740 - val_loss: 0.4594\n",
      "Epoch 34/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - accuracy: 0.7898 - loss: 0.4430 - val_accuracy: 0.7717 - val_loss: 0.4589\n",
      "Epoch 35/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.7980 - loss: 0.4343 - val_accuracy: 0.7734 - val_loss: 0.4586\n",
      "Epoch 36/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - accuracy: 0.7902 - loss: 0.4426 - val_accuracy: 0.7717 - val_loss: 0.4585\n",
      "Epoch 37/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - accuracy: 0.7844 - loss: 0.4475 - val_accuracy: 0.7729 - val_loss: 0.4610\n",
      "Epoch 38/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.7940 - loss: 0.4356 - val_accuracy: 0.7757 - val_loss: 0.4589\n",
      "Epoch 39/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - accuracy: 0.7928 - loss: 0.4439 - val_accuracy: 0.7757 - val_loss: 0.4596\n",
      "Epoch 40/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - accuracy: 0.8006 - loss: 0.4267 - val_accuracy: 0.7746 - val_loss: 0.4579\n",
      "Epoch 41/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - accuracy: 0.8008 - loss: 0.4239 - val_accuracy: 0.7757 - val_loss: 0.4583\n",
      "Epoch 42/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - accuracy: 0.7862 - loss: 0.4469 - val_accuracy: 0.7780 - val_loss: 0.4585\n",
      "Epoch 43/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.7997 - loss: 0.4339 - val_accuracy: 0.7752 - val_loss: 0.4611\n",
      "Epoch 44/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - accuracy: 0.7915 - loss: 0.4425 - val_accuracy: 0.7763 - val_loss: 0.4593\n",
      "Epoch 45/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - accuracy: 0.7891 - loss: 0.4440 - val_accuracy: 0.7763 - val_loss: 0.4594\n",
      "Epoch 46/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.7923 - loss: 0.4415 - val_accuracy: 0.7763 - val_loss: 0.4584\n",
      "Epoch 47/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - accuracy: 0.7936 - loss: 0.4388 - val_accuracy: 0.7763 - val_loss: 0.4587\n",
      "Epoch 48/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475us/step - accuracy: 0.7904 - loss: 0.4447 - val_accuracy: 0.7746 - val_loss: 0.4601\n",
      "Epoch 49/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - accuracy: 0.7866 - loss: 0.4496 - val_accuracy: 0.7746 - val_loss: 0.4593\n",
      "Epoch 50/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - accuracy: 0.7892 - loss: 0.4525 - val_accuracy: 0.7729 - val_loss: 0.4596\n",
      "Iteration No: 12 ended. Search finished for the next optimal point.\n",
      "Time taken: 6.5339\n",
      "Function value obtained: -0.7746\n",
      "Current minimum: -0.7999\n",
      "Iteration No: 13 started. Searching for the next optimal point.\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rahulnundlall/anaconda3/envs/ML/lib/python3.12/site-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7242 - loss: 0.6294 - val_accuracy: 0.7775 - val_loss: 0.5156\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7508 - loss: 0.5714 - val_accuracy: 0.7338 - val_loss: 0.6498\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7456 - loss: 0.5890 - val_accuracy: 0.7757 - val_loss: 0.4665\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7473 - loss: 0.5934 - val_accuracy: 0.7395 - val_loss: 0.5008\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7395 - loss: 0.5887 - val_accuracy: 0.7746 - val_loss: 0.5960\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7711 - loss: 0.5421 - val_accuracy: 0.7619 - val_loss: 0.4995\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7535 - loss: 0.5582 - val_accuracy: 0.7671 - val_loss: 0.4950\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7668 - loss: 0.5336 - val_accuracy: 0.7729 - val_loss: 0.4881\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7622 - loss: 0.5384 - val_accuracy: 0.7568 - val_loss: 0.5143\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7570 - loss: 0.5470 - val_accuracy: 0.7821 - val_loss: 0.4941\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7698 - loss: 0.5481 - val_accuracy: 0.7671 - val_loss: 0.4860\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7678 - loss: 0.5343 - val_accuracy: 0.7665 - val_loss: 0.4972\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7551 - loss: 0.5628 - val_accuracy: 0.7579 - val_loss: 0.5233\n",
      "Iteration No: 13 ended. Search finished for the next optimal point.\n",
      "Time taken: 6.0279\n",
      "Function value obtained: -0.7757\n",
      "Current minimum: -0.7999\n",
      "Iteration No: 14 started. Searching for the next optimal point.\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rahulnundlall/anaconda3/envs/ML/lib/python3.12/site-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7436 - loss: 0.5163 - val_accuracy: 0.7769 - val_loss: 0.4463\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7820 - loss: 0.4492 - val_accuracy: 0.7815 - val_loss: 0.4437\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7969 - loss: 0.4362 - val_accuracy: 0.7867 - val_loss: 0.4366\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7937 - loss: 0.4283 - val_accuracy: 0.7780 - val_loss: 0.4385\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7893 - loss: 0.4386 - val_accuracy: 0.7740 - val_loss: 0.4377\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8028 - loss: 0.4236 - val_accuracy: 0.7763 - val_loss: 0.4282\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8105 - loss: 0.4046 - val_accuracy: 0.7867 - val_loss: 0.4349\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8030 - loss: 0.4191 - val_accuracy: 0.7775 - val_loss: 0.4304\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8013 - loss: 0.4154 - val_accuracy: 0.7867 - val_loss: 0.4255\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8018 - loss: 0.4137 - val_accuracy: 0.7849 - val_loss: 0.4295\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7959 - loss: 0.4143 - val_accuracy: 0.7907 - val_loss: 0.4240\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8019 - loss: 0.4010 - val_accuracy: 0.7867 - val_loss: 0.4227\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7950 - loss: 0.4199 - val_accuracy: 0.7861 - val_loss: 0.4235\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8091 - loss: 0.4107 - val_accuracy: 0.7953 - val_loss: 0.4314\n",
      "Epoch 15/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8023 - loss: 0.4086 - val_accuracy: 0.7849 - val_loss: 0.4252\n",
      "Epoch 16/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8060 - loss: 0.4071 - val_accuracy: 0.7930 - val_loss: 0.4192\n",
      "Epoch 17/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7992 - loss: 0.4130 - val_accuracy: 0.7941 - val_loss: 0.4213\n",
      "Epoch 18/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7937 - loss: 0.4120 - val_accuracy: 0.7959 - val_loss: 0.4392\n",
      "Epoch 19/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8065 - loss: 0.4058 - val_accuracy: 0.7930 - val_loss: 0.4170\n",
      "Epoch 20/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8062 - loss: 0.3977 - val_accuracy: 0.7895 - val_loss: 0.4213\n",
      "Epoch 21/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8031 - loss: 0.4059 - val_accuracy: 0.7884 - val_loss: 0.4196\n",
      "Epoch 22/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8108 - loss: 0.3985 - val_accuracy: 0.7849 - val_loss: 0.4157\n",
      "Epoch 23/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8199 - loss: 0.3927 - val_accuracy: 0.7901 - val_loss: 0.4155\n",
      "Epoch 24/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8061 - loss: 0.3975 - val_accuracy: 0.7907 - val_loss: 0.4257\n",
      "Epoch 25/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8107 - loss: 0.3951 - val_accuracy: 0.7970 - val_loss: 0.4146\n",
      "Epoch 26/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8161 - loss: 0.3871 - val_accuracy: 0.7947 - val_loss: 0.4128\n",
      "Epoch 27/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8077 - loss: 0.3980 - val_accuracy: 0.7964 - val_loss: 0.4159\n",
      "Epoch 28/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8110 - loss: 0.3904 - val_accuracy: 0.7959 - val_loss: 0.4153\n",
      "Epoch 29/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8186 - loss: 0.3847 - val_accuracy: 0.7913 - val_loss: 0.4285\n",
      "Epoch 30/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8169 - loss: 0.3810 - val_accuracy: 0.7982 - val_loss: 0.4242\n",
      "Epoch 31/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8102 - loss: 0.3926 - val_accuracy: 0.7930 - val_loss: 0.4130\n",
      "Epoch 32/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8169 - loss: 0.3847 - val_accuracy: 0.8033 - val_loss: 0.4214\n",
      "Epoch 33/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8184 - loss: 0.3841 - val_accuracy: 0.7878 - val_loss: 0.4267\n",
      "Epoch 34/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8092 - loss: 0.3840 - val_accuracy: 0.7953 - val_loss: 0.4310\n",
      "Epoch 35/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8063 - loss: 0.3877 - val_accuracy: 0.7907 - val_loss: 0.4278\n",
      "Epoch 36/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8242 - loss: 0.3751 - val_accuracy: 0.7930 - val_loss: 0.4295\n",
      "Iteration No: 14 ended. Search finished for the next optimal point.\n",
      "Time taken: 12.2547\n",
      "Function value obtained: -0.7947\n",
      "Current minimum: -0.7999\n",
      "Iteration No: 15 started. Searching for the next optimal point.\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rahulnundlall/anaconda3/envs/ML/lib/python3.12/site-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 749us/step - accuracy: 0.5614 - loss: 0.6783 - val_accuracy: 0.7568 - val_loss: 0.5261\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - accuracy: 0.7666 - loss: 0.5010 - val_accuracy: 0.7579 - val_loss: 0.4817\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - accuracy: 0.7921 - loss: 0.4558 - val_accuracy: 0.7637 - val_loss: 0.4699\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - accuracy: 0.7820 - loss: 0.4556 - val_accuracy: 0.7671 - val_loss: 0.4672\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - accuracy: 0.7907 - loss: 0.4374 - val_accuracy: 0.7677 - val_loss: 0.4648\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.7813 - loss: 0.4480 - val_accuracy: 0.7677 - val_loss: 0.4635\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - accuracy: 0.7832 - loss: 0.4454 - val_accuracy: 0.7700 - val_loss: 0.4625\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - accuracy: 0.7885 - loss: 0.4457 - val_accuracy: 0.7660 - val_loss: 0.4637\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.7837 - loss: 0.4532 - val_accuracy: 0.7694 - val_loss: 0.4633\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - accuracy: 0.7892 - loss: 0.4437 - val_accuracy: 0.7694 - val_loss: 0.4623\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - accuracy: 0.7932 - loss: 0.4346 - val_accuracy: 0.7723 - val_loss: 0.4615\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - accuracy: 0.7866 - loss: 0.4444 - val_accuracy: 0.7717 - val_loss: 0.4619\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - accuracy: 0.7903 - loss: 0.4418 - val_accuracy: 0.7746 - val_loss: 0.4628\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - accuracy: 0.7878 - loss: 0.4393 - val_accuracy: 0.7734 - val_loss: 0.4608\n",
      "Epoch 15/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - accuracy: 0.7887 - loss: 0.4377 - val_accuracy: 0.7700 - val_loss: 0.4623\n",
      "Epoch 16/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - accuracy: 0.7905 - loss: 0.4456 - val_accuracy: 0.7746 - val_loss: 0.4624\n",
      "Epoch 17/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - accuracy: 0.7876 - loss: 0.4490 - val_accuracy: 0.7711 - val_loss: 0.4631\n",
      "Epoch 18/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - accuracy: 0.7962 - loss: 0.4318 - val_accuracy: 0.7706 - val_loss: 0.4619\n",
      "Epoch 19/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - accuracy: 0.7979 - loss: 0.4275 - val_accuracy: 0.7763 - val_loss: 0.4620\n",
      "Epoch 20/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - accuracy: 0.7896 - loss: 0.4447 - val_accuracy: 0.7734 - val_loss: 0.4614\n",
      "Epoch 21/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - accuracy: 0.7945 - loss: 0.4324 - val_accuracy: 0.7763 - val_loss: 0.4606\n",
      "Epoch 22/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - accuracy: 0.7808 - loss: 0.4551 - val_accuracy: 0.7746 - val_loss: 0.4611\n",
      "Epoch 23/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - accuracy: 0.7953 - loss: 0.4421 - val_accuracy: 0.7746 - val_loss: 0.4617\n",
      "Epoch 24/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474us/step - accuracy: 0.7995 - loss: 0.4335 - val_accuracy: 0.7752 - val_loss: 0.4609\n",
      "Epoch 25/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - accuracy: 0.7912 - loss: 0.4467 - val_accuracy: 0.7711 - val_loss: 0.4616\n",
      "Epoch 26/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - accuracy: 0.7941 - loss: 0.4318 - val_accuracy: 0.7711 - val_loss: 0.4603\n",
      "Epoch 27/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475us/step - accuracy: 0.8001 - loss: 0.4327 - val_accuracy: 0.7711 - val_loss: 0.4595\n",
      "Epoch 28/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - accuracy: 0.7851 - loss: 0.4586 - val_accuracy: 0.7792 - val_loss: 0.4610\n",
      "Epoch 29/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - accuracy: 0.7913 - loss: 0.4402 - val_accuracy: 0.7729 - val_loss: 0.4601\n",
      "Epoch 30/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - accuracy: 0.7891 - loss: 0.4400 - val_accuracy: 0.7752 - val_loss: 0.4601\n",
      "Epoch 31/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - accuracy: 0.7810 - loss: 0.4535 - val_accuracy: 0.7757 - val_loss: 0.4590\n",
      "Epoch 32/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - accuracy: 0.7824 - loss: 0.4479 - val_accuracy: 0.7775 - val_loss: 0.4586\n",
      "Epoch 33/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.7971 - loss: 0.4347 - val_accuracy: 0.7734 - val_loss: 0.4606\n",
      "Epoch 34/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - accuracy: 0.8022 - loss: 0.4271 - val_accuracy: 0.7757 - val_loss: 0.4595\n",
      "Epoch 35/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.7901 - loss: 0.4486 - val_accuracy: 0.7746 - val_loss: 0.4595\n",
      "Epoch 36/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - accuracy: 0.7892 - loss: 0.4451 - val_accuracy: 0.7769 - val_loss: 0.4589\n",
      "Epoch 37/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - accuracy: 0.7901 - loss: 0.4482 - val_accuracy: 0.7757 - val_loss: 0.4597\n",
      "Epoch 38/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - accuracy: 0.7951 - loss: 0.4348 - val_accuracy: 0.7746 - val_loss: 0.4602\n",
      "Epoch 39/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - accuracy: 0.7918 - loss: 0.4428 - val_accuracy: 0.7711 - val_loss: 0.4598\n",
      "Epoch 40/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - accuracy: 0.8005 - loss: 0.4360 - val_accuracy: 0.7729 - val_loss: 0.4601\n",
      "Epoch 41/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - accuracy: 0.7963 - loss: 0.4317 - val_accuracy: 0.7734 - val_loss: 0.4604\n",
      "Epoch 42/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.7945 - loss: 0.4389 - val_accuracy: 0.7734 - val_loss: 0.4595\n",
      "Iteration No: 15 ended. Search finished for the next optimal point.\n",
      "Time taken: 5.8091\n",
      "Function value obtained: -0.7775\n",
      "Current minimum: -0.7999\n",
      "Iteration No: 16 started. Searching for the next optimal point.\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rahulnundlall/anaconda3/envs/ML/lib/python3.12/site-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6619 - loss: 0.6088 - val_accuracy: 0.7660 - val_loss: 0.4821\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7542 - loss: 0.4997 - val_accuracy: 0.7688 - val_loss: 0.4706\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7602 - loss: 0.4912 - val_accuracy: 0.7711 - val_loss: 0.4749\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7630 - loss: 0.4963 - val_accuracy: 0.7740 - val_loss: 0.4694\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7801 - loss: 0.4702 - val_accuracy: 0.7717 - val_loss: 0.4710\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7739 - loss: 0.4809 - val_accuracy: 0.7740 - val_loss: 0.4692\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7699 - loss: 0.4811 - val_accuracy: 0.7740 - val_loss: 0.4785\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7790 - loss: 0.4822 - val_accuracy: 0.7734 - val_loss: 0.4675\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7787 - loss: 0.4630 - val_accuracy: 0.7717 - val_loss: 0.4675\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7852 - loss: 0.4552 - val_accuracy: 0.7752 - val_loss: 0.4677\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7786 - loss: 0.4692 - val_accuracy: 0.7677 - val_loss: 0.4734\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7944 - loss: 0.4525 - val_accuracy: 0.7763 - val_loss: 0.4784\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7788 - loss: 0.4584 - val_accuracy: 0.7717 - val_loss: 0.4749\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7876 - loss: 0.4616 - val_accuracy: 0.7700 - val_loss: 0.4743\n",
      "Epoch 15/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7781 - loss: 0.4592 - val_accuracy: 0.7723 - val_loss: 0.4784\n",
      "Epoch 16/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7741 - loss: 0.4709 - val_accuracy: 0.7752 - val_loss: 0.4618\n",
      "Epoch 17/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7904 - loss: 0.4578 - val_accuracy: 0.7786 - val_loss: 0.4650\n",
      "Epoch 18/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7718 - loss: 0.4738 - val_accuracy: 0.7752 - val_loss: 0.4805\n",
      "Epoch 19/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7853 - loss: 0.4628 - val_accuracy: 0.7740 - val_loss: 0.4740\n",
      "Epoch 20/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7959 - loss: 0.4420 - val_accuracy: 0.7792 - val_loss: 0.4607\n",
      "Epoch 21/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7821 - loss: 0.4635 - val_accuracy: 0.7792 - val_loss: 0.4664\n",
      "Epoch 22/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7846 - loss: 0.4585 - val_accuracy: 0.7798 - val_loss: 0.4762\n",
      "Epoch 23/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7921 - loss: 0.4546 - val_accuracy: 0.7792 - val_loss: 0.4662\n",
      "Epoch 24/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7725 - loss: 0.4697 - val_accuracy: 0.7757 - val_loss: 0.4707\n",
      "Epoch 25/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7831 - loss: 0.4581 - val_accuracy: 0.7803 - val_loss: 0.4723\n",
      "Epoch 26/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7779 - loss: 0.4677 - val_accuracy: 0.7757 - val_loss: 0.4685\n",
      "Epoch 27/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7845 - loss: 0.4568 - val_accuracy: 0.7723 - val_loss: 0.4739\n",
      "Epoch 28/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7954 - loss: 0.4513 - val_accuracy: 0.7786 - val_loss: 0.4711\n",
      "Epoch 29/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7829 - loss: 0.4669 - val_accuracy: 0.7821 - val_loss: 0.4751\n",
      "Epoch 30/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7776 - loss: 0.4647 - val_accuracy: 0.7786 - val_loss: 0.4716\n",
      "Iteration No: 16 ended. Search finished for the next optimal point.\n",
      "Time taken: 25.2743\n",
      "Function value obtained: -0.7792\n",
      "Current minimum: -0.7999\n",
      "Iteration No: 17 started. Searching for the next optimal point.\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rahulnundlall/anaconda3/envs/ML/lib/python3.12/site-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7383 - loss: 0.5242 - val_accuracy: 0.7545 - val_loss: 0.4889\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7771 - loss: 0.4765 - val_accuracy: 0.7757 - val_loss: 0.4786\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7689 - loss: 0.4884 - val_accuracy: 0.7711 - val_loss: 0.4878\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7813 - loss: 0.4702 - val_accuracy: 0.7723 - val_loss: 0.4698\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7876 - loss: 0.4659 - val_accuracy: 0.7752 - val_loss: 0.4748\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7833 - loss: 0.4667 - val_accuracy: 0.7723 - val_loss: 0.4681\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7824 - loss: 0.4557 - val_accuracy: 0.7826 - val_loss: 0.4632\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7800 - loss: 0.4642 - val_accuracy: 0.7832 - val_loss: 0.4734\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8025 - loss: 0.4278 - val_accuracy: 0.7861 - val_loss: 0.4434\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7809 - loss: 0.4571 - val_accuracy: 0.7763 - val_loss: 0.4508\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7943 - loss: 0.4399 - val_accuracy: 0.7786 - val_loss: 0.4509\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7899 - loss: 0.4300 - val_accuracy: 0.7890 - val_loss: 0.4407\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8012 - loss: 0.4257 - val_accuracy: 0.7832 - val_loss: 0.4348\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7921 - loss: 0.4222 - val_accuracy: 0.7872 - val_loss: 0.4287\n",
      "Epoch 15/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7967 - loss: 0.4219 - val_accuracy: 0.7821 - val_loss: 0.4330\n",
      "Epoch 16/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7924 - loss: 0.4192 - val_accuracy: 0.7815 - val_loss: 0.4319\n",
      "Epoch 17/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7967 - loss: 0.4211 - val_accuracy: 0.7809 - val_loss: 0.4272\n",
      "Epoch 18/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8015 - loss: 0.4145 - val_accuracy: 0.7895 - val_loss: 0.4278\n",
      "Epoch 19/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8012 - loss: 0.4099 - val_accuracy: 0.7872 - val_loss: 0.4260\n",
      "Epoch 20/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8052 - loss: 0.4200 - val_accuracy: 0.7815 - val_loss: 0.4409\n",
      "Epoch 21/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8036 - loss: 0.4127 - val_accuracy: 0.7752 - val_loss: 0.4302\n",
      "Epoch 22/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7958 - loss: 0.4166 - val_accuracy: 0.7930 - val_loss: 0.4261\n",
      "Epoch 23/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7947 - loss: 0.4184 - val_accuracy: 0.7907 - val_loss: 0.4279\n",
      "Epoch 24/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8012 - loss: 0.4152 - val_accuracy: 0.7844 - val_loss: 0.4406\n",
      "Epoch 25/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7910 - loss: 0.4189 - val_accuracy: 0.7936 - val_loss: 0.4165\n",
      "Epoch 26/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8033 - loss: 0.4056 - val_accuracy: 0.7953 - val_loss: 0.4209\n",
      "Epoch 27/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7949 - loss: 0.4173 - val_accuracy: 0.7936 - val_loss: 0.4220\n",
      "Epoch 28/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8145 - loss: 0.3961 - val_accuracy: 0.7809 - val_loss: 0.4217\n",
      "Epoch 29/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8115 - loss: 0.3950 - val_accuracy: 0.7884 - val_loss: 0.4279\n",
      "Epoch 30/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7959 - loss: 0.4126 - val_accuracy: 0.7999 - val_loss: 0.4170\n",
      "Epoch 31/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8039 - loss: 0.3975 - val_accuracy: 0.7895 - val_loss: 0.4281\n",
      "Epoch 32/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8066 - loss: 0.3984 - val_accuracy: 0.7878 - val_loss: 0.4151\n",
      "Epoch 33/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8075 - loss: 0.3964 - val_accuracy: 0.7982 - val_loss: 0.4179\n",
      "Epoch 34/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8097 - loss: 0.3953 - val_accuracy: 0.8016 - val_loss: 0.4129\n",
      "Epoch 35/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8031 - loss: 0.4028 - val_accuracy: 0.7913 - val_loss: 0.4199\n",
      "Epoch 36/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8054 - loss: 0.4031 - val_accuracy: 0.7964 - val_loss: 0.4197\n",
      "Epoch 37/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8058 - loss: 0.3944 - val_accuracy: 0.7947 - val_loss: 0.4206\n",
      "Epoch 38/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8111 - loss: 0.3978 - val_accuracy: 0.7953 - val_loss: 0.4225\n",
      "Epoch 39/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8103 - loss: 0.4005 - val_accuracy: 0.7959 - val_loss: 0.4065\n",
      "Epoch 40/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8062 - loss: 0.3971 - val_accuracy: 0.7947 - val_loss: 0.4117\n",
      "Epoch 41/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8122 - loss: 0.3963 - val_accuracy: 0.7941 - val_loss: 0.4201\n",
      "Epoch 42/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8122 - loss: 0.3872 - val_accuracy: 0.7941 - val_loss: 0.4136\n",
      "Epoch 43/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8065 - loss: 0.3994 - val_accuracy: 0.7901 - val_loss: 0.4167\n",
      "Epoch 44/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8135 - loss: 0.3876 - val_accuracy: 0.7953 - val_loss: 0.4136\n",
      "Epoch 45/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8083 - loss: 0.3860 - val_accuracy: 0.7798 - val_loss: 0.4236\n",
      "Epoch 46/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8113 - loss: 0.3948 - val_accuracy: 0.7970 - val_loss: 0.4130\n",
      "Epoch 47/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8165 - loss: 0.3859 - val_accuracy: 0.7941 - val_loss: 0.4124\n",
      "Epoch 48/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8087 - loss: 0.3851 - val_accuracy: 0.7918 - val_loss: 0.4163\n",
      "Epoch 49/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8049 - loss: 0.4096 - val_accuracy: 0.8028 - val_loss: 0.4133\n",
      "Iteration No: 17 ended. Search finished for the next optimal point.\n",
      "Time taken: 45.1168\n",
      "Function value obtained: -0.7959\n",
      "Current minimum: -0.7999\n",
      "Iteration No: 18 started. Searching for the next optimal point.\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rahulnundlall/anaconda3/envs/ML/lib/python3.12/site-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7140 - loss: 0.7850 - val_accuracy: 0.7269 - val_loss: 0.5417\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7447 - loss: 0.5488 - val_accuracy: 0.7148 - val_loss: 0.6008\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7553 - loss: 0.5331 - val_accuracy: 0.7706 - val_loss: 0.4610\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7587 - loss: 0.5311 - val_accuracy: 0.7637 - val_loss: 0.4783\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7560 - loss: 0.5204 - val_accuracy: 0.6774 - val_loss: 0.6868\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7465 - loss: 0.5701 - val_accuracy: 0.7240 - val_loss: 0.5618\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7409 - loss: 0.5537 - val_accuracy: 0.7677 - val_loss: 0.4644\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7648 - loss: 0.5237 - val_accuracy: 0.7706 - val_loss: 0.4907\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7560 - loss: 0.5271 - val_accuracy: 0.7723 - val_loss: 0.5528\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7565 - loss: 0.5381 - val_accuracy: 0.7648 - val_loss: 0.5489\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.5485 - val_accuracy: 0.7539 - val_loss: 0.6052\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7568 - loss: 0.5351 - val_accuracy: 0.7033 - val_loss: 0.6213\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7504 - loss: 0.5538 - val_accuracy: 0.7711 - val_loss: 0.4644\n",
      "Iteration No: 18 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.5824\n",
      "Function value obtained: -0.7706\n",
      "Current minimum: -0.7999\n",
      "Iteration No: 19 started. Searching for the next optimal point.\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rahulnundlall/anaconda3/envs/ML/lib/python3.12/site-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7658 - loss: 0.4887 - val_accuracy: 0.7665 - val_loss: 0.4744\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7823 - loss: 0.4581 - val_accuracy: 0.7665 - val_loss: 0.4627\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7891 - loss: 0.4494 - val_accuracy: 0.7780 - val_loss: 0.4668\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7922 - loss: 0.4450 - val_accuracy: 0.7665 - val_loss: 0.4653\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7960 - loss: 0.4312 - val_accuracy: 0.7711 - val_loss: 0.4817\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7976 - loss: 0.4273 - val_accuracy: 0.7786 - val_loss: 0.4510\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7969 - loss: 0.4291 - val_accuracy: 0.7821 - val_loss: 0.4505\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7863 - loss: 0.4356 - val_accuracy: 0.7884 - val_loss: 0.4440\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7897 - loss: 0.4358 - val_accuracy: 0.7775 - val_loss: 0.4398\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8028 - loss: 0.4140 - val_accuracy: 0.7763 - val_loss: 0.4431\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8020 - loss: 0.4070 - val_accuracy: 0.7769 - val_loss: 0.4302\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8026 - loss: 0.4112 - val_accuracy: 0.7936 - val_loss: 0.4312\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7984 - loss: 0.4142 - val_accuracy: 0.7930 - val_loss: 0.4186\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8019 - loss: 0.4021 - val_accuracy: 0.7844 - val_loss: 0.4287\n",
      "Epoch 15/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8046 - loss: 0.4017 - val_accuracy: 0.7815 - val_loss: 0.4322\n",
      "Epoch 16/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8074 - loss: 0.3997 - val_accuracy: 0.7884 - val_loss: 0.4225\n",
      "Epoch 17/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8141 - loss: 0.3884 - val_accuracy: 0.7861 - val_loss: 0.4307\n",
      "Epoch 18/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8086 - loss: 0.3927 - val_accuracy: 0.7924 - val_loss: 0.4129\n",
      "Epoch 19/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8176 - loss: 0.3883 - val_accuracy: 0.7872 - val_loss: 0.4243\n",
      "Epoch 20/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8118 - loss: 0.3848 - val_accuracy: 0.7878 - val_loss: 0.4147\n",
      "Epoch 21/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8102 - loss: 0.3880 - val_accuracy: 0.7867 - val_loss: 0.4302\n",
      "Epoch 22/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8119 - loss: 0.3957 - val_accuracy: 0.7844 - val_loss: 0.4300\n",
      "Epoch 23/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8159 - loss: 0.3859 - val_accuracy: 0.7798 - val_loss: 0.4303\n",
      "Epoch 24/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8103 - loss: 0.3902 - val_accuracy: 0.7924 - val_loss: 0.4136\n",
      "Epoch 25/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8152 - loss: 0.3845 - val_accuracy: 0.7844 - val_loss: 0.4227\n",
      "Epoch 26/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8152 - loss: 0.3823 - val_accuracy: 0.7924 - val_loss: 0.4157\n",
      "Epoch 27/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8139 - loss: 0.3871 - val_accuracy: 0.7970 - val_loss: 0.4159\n",
      "Epoch 28/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8191 - loss: 0.3734 - val_accuracy: 0.7941 - val_loss: 0.4151\n",
      "Iteration No: 19 ended. Search finished for the next optimal point.\n",
      "Time taken: 16.2662\n",
      "Function value obtained: -0.7924\n",
      "Current minimum: -0.7999\n",
      "Iteration No: 20 started. Searching for the next optimal point.\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rahulnundlall/anaconda3/envs/ML/lib/python3.12/site-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - accuracy: 0.7553 - loss: 0.4942 - val_accuracy: 0.7775 - val_loss: 0.4609\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374us/step - accuracy: 0.7948 - loss: 0.4438 - val_accuracy: 0.7723 - val_loss: 0.4653\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367us/step - accuracy: 0.7966 - loss: 0.4394 - val_accuracy: 0.7763 - val_loss: 0.4618\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370us/step - accuracy: 0.7927 - loss: 0.4393 - val_accuracy: 0.7746 - val_loss: 0.4625\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375us/step - accuracy: 0.7881 - loss: 0.4367 - val_accuracy: 0.7752 - val_loss: 0.4566\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363us/step - accuracy: 0.7890 - loss: 0.4485 - val_accuracy: 0.7786 - val_loss: 0.4555\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368us/step - accuracy: 0.7878 - loss: 0.4360 - val_accuracy: 0.7872 - val_loss: 0.4445\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365us/step - accuracy: 0.7992 - loss: 0.4249 - val_accuracy: 0.7826 - val_loss: 0.4459\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373us/step - accuracy: 0.7947 - loss: 0.4217 - val_accuracy: 0.7786 - val_loss: 0.4503\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373us/step - accuracy: 0.7904 - loss: 0.4290 - val_accuracy: 0.7660 - val_loss: 0.4620\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371us/step - accuracy: 0.7969 - loss: 0.4261 - val_accuracy: 0.7752 - val_loss: 0.4491\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366us/step - accuracy: 0.7958 - loss: 0.4172 - val_accuracy: 0.7792 - val_loss: 0.4386\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364us/step - accuracy: 0.7977 - loss: 0.4289 - val_accuracy: 0.7815 - val_loss: 0.4389\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - accuracy: 0.8001 - loss: 0.4204 - val_accuracy: 0.7832 - val_loss: 0.4377\n",
      "Epoch 15/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365us/step - accuracy: 0.8017 - loss: 0.4136 - val_accuracy: 0.7849 - val_loss: 0.4447\n",
      "Epoch 16/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364us/step - accuracy: 0.8087 - loss: 0.4120 - val_accuracy: 0.7786 - val_loss: 0.4481\n",
      "Epoch 17/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371us/step - accuracy: 0.8067 - loss: 0.4055 - val_accuracy: 0.7815 - val_loss: 0.4373\n",
      "Epoch 18/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - accuracy: 0.8048 - loss: 0.4135 - val_accuracy: 0.7890 - val_loss: 0.4299\n",
      "Epoch 19/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359us/step - accuracy: 0.7944 - loss: 0.4184 - val_accuracy: 0.7815 - val_loss: 0.4290\n",
      "Epoch 20/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364us/step - accuracy: 0.8002 - loss: 0.4063 - val_accuracy: 0.7907 - val_loss: 0.4238\n",
      "Epoch 21/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363us/step - accuracy: 0.7941 - loss: 0.4214 - val_accuracy: 0.7769 - val_loss: 0.4387\n",
      "Epoch 22/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361us/step - accuracy: 0.7982 - loss: 0.4121 - val_accuracy: 0.7861 - val_loss: 0.4286\n",
      "Epoch 23/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - accuracy: 0.8052 - loss: 0.4115 - val_accuracy: 0.7867 - val_loss: 0.4282\n",
      "Epoch 24/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366us/step - accuracy: 0.7964 - loss: 0.4071 - val_accuracy: 0.7855 - val_loss: 0.4336\n",
      "Epoch 25/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369us/step - accuracy: 0.8037 - loss: 0.4091 - val_accuracy: 0.7855 - val_loss: 0.4282\n",
      "Epoch 26/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365us/step - accuracy: 0.8095 - loss: 0.3989 - val_accuracy: 0.7815 - val_loss: 0.4299\n",
      "Epoch 27/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369us/step - accuracy: 0.8089 - loss: 0.4027 - val_accuracy: 0.7884 - val_loss: 0.4279\n",
      "Epoch 28/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - accuracy: 0.8143 - loss: 0.3865 - val_accuracy: 0.7890 - val_loss: 0.4302\n",
      "Epoch 29/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364us/step - accuracy: 0.8066 - loss: 0.3998 - val_accuracy: 0.7993 - val_loss: 0.4213\n",
      "Epoch 30/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361us/step - accuracy: 0.8111 - loss: 0.4016 - val_accuracy: 0.7838 - val_loss: 0.4262\n",
      "Epoch 31/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357us/step - accuracy: 0.8114 - loss: 0.3951 - val_accuracy: 0.7901 - val_loss: 0.4293\n",
      "Epoch 32/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359us/step - accuracy: 0.8005 - loss: 0.4047 - val_accuracy: 0.7821 - val_loss: 0.4329\n",
      "Epoch 33/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - accuracy: 0.8079 - loss: 0.3962 - val_accuracy: 0.7907 - val_loss: 0.4298\n",
      "Epoch 34/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361us/step - accuracy: 0.8021 - loss: 0.4123 - val_accuracy: 0.7890 - val_loss: 0.4251\n",
      "Epoch 35/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368us/step - accuracy: 0.8109 - loss: 0.3935 - val_accuracy: 0.7867 - val_loss: 0.4338\n",
      "Epoch 36/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363us/step - accuracy: 0.8132 - loss: 0.3943 - val_accuracy: 0.7918 - val_loss: 0.4262\n",
      "Epoch 37/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365us/step - accuracy: 0.8184 - loss: 0.3970 - val_accuracy: 0.7826 - val_loss: 0.4290\n",
      "Epoch 38/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371us/step - accuracy: 0.8020 - loss: 0.3961 - val_accuracy: 0.7890 - val_loss: 0.4243\n",
      "Epoch 39/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361us/step - accuracy: 0.8034 - loss: 0.4024 - val_accuracy: 0.7970 - val_loss: 0.4201\n",
      "Epoch 40/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - accuracy: 0.8071 - loss: 0.3941 - val_accuracy: 0.7884 - val_loss: 0.4224\n",
      "Epoch 41/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361us/step - accuracy: 0.8083 - loss: 0.4012 - val_accuracy: 0.7809 - val_loss: 0.4277\n",
      "Epoch 42/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.8147 - loss: 0.3868 - val_accuracy: 0.7941 - val_loss: 0.4200\n",
      "Epoch 43/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371us/step - accuracy: 0.8222 - loss: 0.3886 - val_accuracy: 0.7861 - val_loss: 0.4343\n",
      "Epoch 44/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372us/step - accuracy: 0.7992 - loss: 0.4034 - val_accuracy: 0.7838 - val_loss: 0.4239\n",
      "Epoch 45/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361us/step - accuracy: 0.8107 - loss: 0.3874 - val_accuracy: 0.7849 - val_loss: 0.4189\n",
      "Epoch 46/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362us/step - accuracy: 0.8071 - loss: 0.4009 - val_accuracy: 0.7895 - val_loss: 0.4247\n",
      "Epoch 47/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368us/step - accuracy: 0.8126 - loss: 0.3894 - val_accuracy: 0.7861 - val_loss: 0.4360\n",
      "Epoch 48/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358us/step - accuracy: 0.8128 - loss: 0.3971 - val_accuracy: 0.7884 - val_loss: 0.4252\n",
      "Epoch 49/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361us/step - accuracy: 0.8139 - loss: 0.3846 - val_accuracy: 0.7959 - val_loss: 0.4260\n",
      "Epoch 50/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367us/step - accuracy: 0.8172 - loss: 0.3815 - val_accuracy: 0.7895 - val_loss: 0.4292\n",
      "Iteration No: 20 ended. Search finished for the next optimal point.\n",
      "Time taken: 5.2774\n",
      "Function value obtained: -0.7849\n",
      "Current minimum: -0.7999\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rahulnundlall/anaconda3/envs/ML/lib/python3.12/site-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - accuracy: 0.7552 - loss: 0.4879\n",
      "Epoch 2/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step - accuracy: 0.7830 - loss: 0.4603\n",
      "Epoch 3/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423us/step - accuracy: 0.7850 - loss: 0.4599\n",
      "Epoch 4/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327us/step - accuracy: 0.7780 - loss: 0.4569\n",
      "Epoch 5/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322us/step - accuracy: 0.7853 - loss: 0.4473\n",
      "Epoch 6/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320us/step - accuracy: 0.7885 - loss: 0.4440\n",
      "Epoch 7/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322us/step - accuracy: 0.7942 - loss: 0.4416\n",
      "Epoch 8/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319us/step - accuracy: 0.7945 - loss: 0.4341\n",
      "Epoch 9/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324us/step - accuracy: 0.8019 - loss: 0.4242\n",
      "Epoch 10/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339us/step - accuracy: 0.7877 - loss: 0.4352\n",
      "Epoch 11/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324us/step - accuracy: 0.7923 - loss: 0.4349\n",
      "Epoch 12/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330us/step - accuracy: 0.7929 - loss: 0.4329\n",
      "Epoch 13/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326us/step - accuracy: 0.8057 - loss: 0.4146\n",
      "Epoch 14/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327us/step - accuracy: 0.8037 - loss: 0.4148\n",
      "Epoch 15/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324us/step - accuracy: 0.7992 - loss: 0.4273\n",
      "Epoch 16/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327us/step - accuracy: 0.7987 - loss: 0.4148\n",
      "Epoch 17/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321us/step - accuracy: 0.7924 - loss: 0.4309\n",
      "Epoch 18/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325us/step - accuracy: 0.7997 - loss: 0.4254\n",
      "Epoch 19/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324us/step - accuracy: 0.7961 - loss: 0.4227\n",
      "Epoch 20/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324us/step - accuracy: 0.7939 - loss: 0.4269\n",
      "Epoch 21/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325us/step - accuracy: 0.7920 - loss: 0.4302\n",
      "Epoch 22/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330us/step - accuracy: 0.8023 - loss: 0.4131\n",
      "Epoch 23/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333us/step - accuracy: 0.8071 - loss: 0.4198\n",
      "Epoch 24/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326us/step - accuracy: 0.8128 - loss: 0.4080\n",
      "Epoch 25/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323us/step - accuracy: 0.8040 - loss: 0.4183\n",
      "Epoch 26/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322us/step - accuracy: 0.7911 - loss: 0.4314\n",
      "Epoch 27/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322us/step - accuracy: 0.8003 - loss: 0.4210\n",
      "Epoch 28/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329us/step - accuracy: 0.8051 - loss: 0.4123\n",
      "Epoch 29/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324us/step - accuracy: 0.8091 - loss: 0.4062\n",
      "Epoch 30/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330us/step - accuracy: 0.8062 - loss: 0.4075\n",
      "Epoch 31/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325us/step - accuracy: 0.7975 - loss: 0.4131\n",
      "Epoch 32/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324us/step - accuracy: 0.7992 - loss: 0.4224\n",
      "Epoch 33/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321us/step - accuracy: 0.8060 - loss: 0.4066\n",
      "Epoch 34/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329us/step - accuracy: 0.8101 - loss: 0.4012\n",
      "Epoch 35/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323us/step - accuracy: 0.8058 - loss: 0.4122\n",
      "Epoch 36/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329us/step - accuracy: 0.7950 - loss: 0.4131\n",
      "Epoch 37/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331us/step - accuracy: 0.8018 - loss: 0.4049\n",
      "Epoch 38/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319us/step - accuracy: 0.8125 - loss: 0.4011\n",
      "Epoch 39/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324us/step - accuracy: 0.8025 - loss: 0.4089\n",
      "Epoch 40/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317us/step - accuracy: 0.8034 - loss: 0.4091\n",
      "Epoch 41/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330us/step - accuracy: 0.8132 - loss: 0.3990\n",
      "Epoch 42/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321us/step - accuracy: 0.8128 - loss: 0.4009\n",
      "Epoch 43/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step - accuracy: 0.8073 - loss: 0.4122\n",
      "Epoch 44/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327us/step - accuracy: 0.7957 - loss: 0.4198\n",
      "Epoch 45/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step - accuracy: 0.8025 - loss: 0.4093\n",
      "Epoch 46/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327us/step - accuracy: 0.8087 - loss: 0.4069\n",
      "Epoch 47/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.8065 - loss: 0.4077\n",
      "Epoch 48/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340us/step - accuracy: 0.7981 - loss: 0.4246\n",
      "Epoch 49/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326us/step - accuracy: 0.8002 - loss: 0.4146\n",
      "Epoch 50/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step - accuracy: 0.8128 - loss: 0.4004\n",
      "Epoch 51/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322us/step - accuracy: 0.8052 - loss: 0.4100\n",
      "Epoch 52/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323us/step - accuracy: 0.7961 - loss: 0.4130\n",
      "Epoch 53/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329us/step - accuracy: 0.8101 - loss: 0.4025\n",
      "Epoch 54/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329us/step - accuracy: 0.8080 - loss: 0.4009\n",
      "Epoch 55/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323us/step - accuracy: 0.8049 - loss: 0.4069\n",
      "Epoch 56/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326us/step - accuracy: 0.8084 - loss: 0.4116\n",
      "Epoch 57/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330us/step - accuracy: 0.8002 - loss: 0.4083\n",
      "Epoch 58/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step - accuracy: 0.8130 - loss: 0.3942\n",
      "Epoch 59/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324us/step - accuracy: 0.7998 - loss: 0.4092\n",
      "Epoch 60/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337us/step - accuracy: 0.8093 - loss: 0.3969\n",
      "Epoch 61/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327us/step - accuracy: 0.8069 - loss: 0.4138\n",
      "Epoch 62/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step - accuracy: 0.8039 - loss: 0.4067\n",
      "Epoch 63/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323us/step - accuracy: 0.8074 - loss: 0.3969\n",
      "Epoch 64/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323us/step - accuracy: 0.7984 - loss: 0.4169\n",
      "Epoch 65/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324us/step - accuracy: 0.8086 - loss: 0.4050\n",
      "Epoch 66/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320us/step - accuracy: 0.8152 - loss: 0.3916\n",
      "Epoch 67/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329us/step - accuracy: 0.8118 - loss: 0.4004\n",
      "Epoch 68/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321us/step - accuracy: 0.8084 - loss: 0.4009\n",
      "Epoch 69/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325us/step - accuracy: 0.8053 - loss: 0.4124\n",
      "Epoch 70/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321us/step - accuracy: 0.8091 - loss: 0.3960\n",
      "Epoch 71/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321us/step - accuracy: 0.8060 - loss: 0.4131\n",
      "Epoch 72/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - accuracy: 0.8021 - loss: 0.4063\n",
      "Epoch 73/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324us/step - accuracy: 0.8052 - loss: 0.4115\n",
      "Epoch 74/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322us/step - accuracy: 0.8081 - loss: 0.4027\n",
      "Epoch 75/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321us/step - accuracy: 0.8035 - loss: 0.4053\n",
      "Epoch 76/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321us/step - accuracy: 0.8064 - loss: 0.4048\n",
      "Epoch 77/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324us/step - accuracy: 0.8058 - loss: 0.4075\n",
      "Epoch 78/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326us/step - accuracy: 0.8072 - loss: 0.4076\n",
      "Epoch 79/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429us/step - accuracy: 0.8094 - loss: 0.4042\n",
      "Epoch 80/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330us/step - accuracy: 0.8134 - loss: 0.3981\n",
      "Epoch 81/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321us/step - accuracy: 0.8066 - loss: 0.4103\n",
      "Epoch 82/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327us/step - accuracy: 0.8168 - loss: 0.3839\n",
      "Epoch 83/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step - accuracy: 0.8024 - loss: 0.3965\n",
      "Epoch 84/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322us/step - accuracy: 0.8055 - loss: 0.4079\n",
      "Epoch 85/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step - accuracy: 0.8090 - loss: 0.4075\n",
      "Epoch 86/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step - accuracy: 0.8130 - loss: 0.4011\n",
      "Epoch 87/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320us/step - accuracy: 0.8107 - loss: 0.3932\n",
      "Epoch 88/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step - accuracy: 0.8211 - loss: 0.3978\n",
      "Epoch 89/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322us/step - accuracy: 0.8166 - loss: 0.3884\n",
      "Epoch 90/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step - accuracy: 0.8085 - loss: 0.3973\n",
      "Epoch 91/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330us/step - accuracy: 0.8074 - loss: 0.4067\n",
      "Epoch 92/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342us/step - accuracy: 0.8097 - loss: 0.3978\n",
      "Epoch 93/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351us/step - accuracy: 0.8104 - loss: 0.3982\n",
      "Epoch 94/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342us/step - accuracy: 0.8048 - loss: 0.3983\n",
      "Epoch 95/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372us/step - accuracy: 0.8131 - loss: 0.3948\n",
      "Epoch 96/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347us/step - accuracy: 0.8152 - loss: 0.3964\n",
      "Epoch 97/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348us/step - accuracy: 0.8041 - loss: 0.4027\n",
      "Epoch 98/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - accuracy: 0.8119 - loss: 0.4028\n",
      "Epoch 99/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336us/step - accuracy: 0.8112 - loss: 0.3961\n",
      "Epoch 100/100\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333us/step - accuracy: 0.8147 - loss: 0.3923\n",
      "Best Validation Accuracy: 0.7998849749565125\n",
      "Best Hyperparameters: {'layers': [379], 'activation': 'tanh', 'dropout_rate': 0.10031150633640573, 'learning_rate': 0.009647685075720105}\n"
     ]
    }
   ],
   "source": [
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from skopt.utils import use_named_args\n",
    "\n",
    "train_df = preprocess_data('csv_files/train.csv', is_train=True)\n",
    "test_df = preprocess_data('csv_files/test.csv', is_train=False)\n",
    "\n",
    "# Function to create the model\n",
    "def create_model(input_shape, layers, activation, dropout_rate, learning_rate):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(layers[0], activation=activation, input_shape=(input_shape,)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    for layer_size in layers[1:]:\n",
    "        model.add(Dense(layer_size, activation=activation))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_and_evaluate(model, X_train, y_train, X_val, y_val, batch_size, epochs, class_weight):\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, \n",
    "              validation_data=(X_val, y_val), class_weight=class_weight, \n",
    "              callbacks=[early_stopping])\n",
    "    val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
    "    return val_loss, val_acc\n",
    "\n",
    "# Prepare features and target for the model\n",
    "features = [col for col in train_df.columns if col not in ['PassengerId', 'Name', 'Transported', 'Cabin_Deck', 'HomePlanet_TotalSpending', 'Destination_TotalSpending']]\n",
    "X = train_df[features]\n",
    "y = train_df['Transported']\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Handling class imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train_smote),\n",
    "    y=y_train_smote)\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# Define the hyperparameter search space\n",
    "dim_layers = Integer(low=1, high=4, name='layers')\n",
    "dim_units = Integer(low=32, high=512, name='units')\n",
    "dim_activation = Categorical(categories=['relu', 'tanh'], name='activation')\n",
    "dim_dropout = Real(low=0.1, high=0.5, prior='uniform', name='dropout_rate')\n",
    "dim_learning_rate = Real(low=1e-4, high=1e-2, prior='log-uniform', name='learning_rate')\n",
    "\n",
    "dimensions = [dim_layers, dim_units, dim_activation, dim_dropout, dim_learning_rate]\n",
    "\n",
    "@use_named_args(dimensions=dimensions)\n",
    "def fitness(layers, units, activation, dropout_rate, learning_rate):\n",
    "    layers = [units] * layers\n",
    "    model = create_model(input_shape=X_train_smote.shape[1], layers=layers, \n",
    "                         activation=activation, dropout_rate=dropout_rate, learning_rate=learning_rate)\n",
    "    val_loss, val_acc = train_and_evaluate(model, X_train_smote, y_train_smote, X_val, y_val, \n",
    "                                           batch_size=32, epochs=50, class_weight=class_weight_dict)\n",
    "    return -val_acc  # Minimize the negative of validation accuracy\n",
    "\n",
    "# Perform Bayesian Optimization\n",
    "n_calls = 20\n",
    "best_result = gp_minimize(func=fitness, dimensions=dimensions, n_calls=n_calls, \n",
    "                          random_state=42, verbose=True)\n",
    "\n",
    "# Retrieve the best hyperparameters\n",
    "best_params = {\n",
    "    'layers': [best_result.x[1]] * best_result.x[0],\n",
    "    'activation': best_result.x[2],\n",
    "    'dropout_rate': best_result.x[3],\n",
    "    'learning_rate': best_result.x[4]\n",
    "}\n",
    "best_val_acc = -best_result.fun\n",
    "\n",
    "# Train the final model with the best hyperparameters\n",
    "model_enhanced = create_model(input_shape=X_train_smote.shape[1], **best_params)\n",
    "\n",
    "# Combine the original training and validation sets for final training\n",
    "X_full, y_full = smote.fit_resample(X, y)\n",
    "model_enhanced.fit(X_full, y_full, batch_size=32, epochs=100, class_weight=class_weight_dict)\n",
    "\n",
    "print(f\"Best Validation Accuracy: {best_val_acc}\")\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run 1:\n",
    "Best Validation Accuracy: 0.7998849749565125\n",
    "Best Hyperparameters: {'layers': [379], 'activation': 'tanh', 'dropout_rate': 0.10031150633640573, 'learning_rate': 0.009647685075720105}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "\n",
    "# Preprocess the test data using the same steps as the training data\n",
    "test_df = preprocess_data('csv_files/test.csv', is_train=False)\n",
    "\n",
    "# Load the features used during training\n",
    "train_features = joblib.load('train_features.pkl')\n",
    "\n",
    "# Select the features used by the model, ensuring they are the same as those used in training\n",
    "features = [col for col in train_features if col in test_df.columns]\n",
    "\n",
    "# Ensure that X_test is a DataFrame with the correct numerical types\n",
    "X_test = test_df[features].copy()\n",
    "\n",
    "# Convert X_test to a NumPy array, which is the expected format for TensorFlow models\n",
    "X_test_np = X_test.values\n",
    "\n",
    "# Predict using the enhanced model\n",
    "y_pred_test_proba = model_enhanced.predict(X_test_np)\n",
    "y_pred_test = (y_pred_test_proba > 0.5).astype(int).flatten()\n",
    "\n",
    "# Prepare the submission dataframe\n",
    "submission_df = pd.DataFrame({\n",
    "    'PassengerId': test_df['PassengerId'],\n",
    "    'Transported': y_pred_test\n",
    "})\n",
    "\n",
    "# Convert predictions back to boolean (True/False) if necessary\n",
    "submission_df['Transported'] = submission_df['Transported'].astype(bool)\n",
    "\n",
    "# Save the submission file\n",
    "submission_df.to_csv('neuralnetbaye.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
