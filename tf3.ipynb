{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from scipy.stats import expon, reciprocal\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow import keras\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import keras_tuner as kt\n",
    "import deap\n",
    "import skopt\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.models import save_model\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import joblib\n",
    "\n",
    "def preprocess_data(file_path, is_train=True):\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Convert binary categorical features to 0 and 1\n",
    "    binary_features = ['CryoSleep', 'VIP']\n",
    "    df[binary_features] = df[binary_features].astype(bool).astype(int)\n",
    "    \n",
    "    # Feature Engineering\n",
    "    df['TotalSpending'] = df[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].sum(axis=1)\n",
    "    \n",
    "    # Conditionally set spending-related features to 0 for passengers in cryosleep\n",
    "    spending_features = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "    df.loc[df['CryoSleep'] == 1, spending_features] = 0\n",
    "    \n",
    "    # Create interaction features\n",
    "    df['HomePlanet_TotalSpending'] = df['HomePlanet'].astype(str) + '_' + df['TotalSpending'].astype(str)\n",
    "    df['Destination_TotalSpending'] = df['Destination'].astype(str) + '_' + df['TotalSpending'].astype(str)\n",
    "    \n",
    "    # Extract components from 'Cabin'\n",
    "    if 'Cabin' in df.columns:\n",
    "        df[['Cabin_Deck', 'Cabin_Number', 'Cabin_Side']] = df['Cabin'].str.split('/', expand=True)\n",
    "        df['Cabin_Side'] = df['Cabin_Side'].map({'P': 1, 'S': 0})\n",
    "        df['Cabin_Number'] = pd.to_numeric(df['Cabin_Number'], errors='coerce')\n",
    "        df.drop('Cabin', axis=1, inplace=True)\n",
    "    \n",
    "    # One-hot encode multi-category features\n",
    "    multi_cat_features = ['HomePlanet', 'Destination']\n",
    "    if is_train:\n",
    "        one_hot_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "        encoded_features = one_hot_encoder.fit_transform(df[multi_cat_features])\n",
    "        encoded_feature_names = one_hot_encoder.get_feature_names_out(multi_cat_features)\n",
    "        joblib.dump(one_hot_encoder, 'one_hot_encoder.pkl')\n",
    "    else:\n",
    "        one_hot_encoder = joblib.load('one_hot_encoder.pkl')\n",
    "        encoded_features = one_hot_encoder.transform(df[multi_cat_features])\n",
    "        encoded_feature_names = one_hot_encoder.get_feature_names_out(multi_cat_features)\n",
    "    \n",
    "    encoded_features_df = pd.DataFrame(encoded_features.toarray(), columns=encoded_feature_names)\n",
    "    df = pd.concat([df, encoded_features_df], axis=1)\n",
    "    df.drop(multi_cat_features, axis=1, inplace=True)\n",
    "    \n",
    "    # Imputation and Scaling\n",
    "    numeric_features = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'Cabin_Number', 'Cabin_Side', 'TotalSpending']\n",
    "    if is_train:\n",
    "        imputer = KNNImputer(n_neighbors=5)\n",
    "        scaler = StandardScaler()\n",
    "        df[numeric_features] = imputer.fit_transform(df[numeric_features])\n",
    "        df[numeric_features] = scaler.fit_transform(df[numeric_features])\n",
    "        joblib.dump(imputer, 'imputer.pkl')\n",
    "        joblib.dump(scaler, 'scaler.pkl')\n",
    "    else:\n",
    "        imputer = joblib.load('imputer.pkl')\n",
    "        scaler = joblib.load('scaler.pkl')\n",
    "        df[numeric_features] = imputer.transform(df[numeric_features])\n",
    "        df[numeric_features] = scaler.transform(df[numeric_features])\n",
    "    \n",
    "    if is_train:\n",
    "        # Convert 'Transported' to integer (True=1, False=0) for modeling\n",
    "        df['Transported'] = df['Transported'].astype(int)\n",
    "        \n",
    "        # Save the list of features used for training\n",
    "        train_features = [col for col in df.columns if col not in ['PassengerId', 'Name', 'Transported', 'Cabin_Deck', 'HomePlanet_TotalSpending', 'Destination_TotalSpending']]\n",
    "        joblib.dump(train_features, 'train_features.pkl')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rahulnundlall/anaconda3/envs/ML/lib/python3.12/site-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 601us/step - accuracy: 0.7438 - loss: 0.5113 - val_accuracy: 0.7671 - val_loss: 0.4722 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.7802 - loss: 0.4626 - val_accuracy: 0.7729 - val_loss: 0.4618 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.7850 - loss: 0.4635 - val_accuracy: 0.7752 - val_loss: 0.4745 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.7852 - loss: 0.4461 - val_accuracy: 0.7763 - val_loss: 0.4724 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.7903 - loss: 0.4401 - val_accuracy: 0.7803 - val_loss: 0.4590 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.7854 - loss: 0.4536 - val_accuracy: 0.7769 - val_loss: 0.4628 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.7976 - loss: 0.4394 - val_accuracy: 0.7711 - val_loss: 0.4625 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.7875 - loss: 0.4350 - val_accuracy: 0.7844 - val_loss: 0.4494 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - accuracy: 0.7919 - loss: 0.4333 - val_accuracy: 0.7821 - val_loss: 0.4482 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - accuracy: 0.7922 - loss: 0.4308 - val_accuracy: 0.7711 - val_loss: 0.4507 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - accuracy: 0.7992 - loss: 0.4238 - val_accuracy: 0.7821 - val_loss: 0.4342 - learning_rate: 9.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - accuracy: 0.7918 - loss: 0.4236 - val_accuracy: 0.7872 - val_loss: 0.4284 - learning_rate: 9.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - accuracy: 0.7944 - loss: 0.4240 - val_accuracy: 0.7855 - val_loss: 0.4298 - learning_rate: 9.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - accuracy: 0.8078 - loss: 0.4096 - val_accuracy: 0.7803 - val_loss: 0.4320 - learning_rate: 9.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474us/step - accuracy: 0.7951 - loss: 0.4259 - val_accuracy: 0.7901 - val_loss: 0.4221 - learning_rate: 9.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - accuracy: 0.7989 - loss: 0.4103 - val_accuracy: 0.7890 - val_loss: 0.4224 - learning_rate: 9.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - accuracy: 0.8026 - loss: 0.4108 - val_accuracy: 0.7798 - val_loss: 0.4247 - learning_rate: 9.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - accuracy: 0.7979 - loss: 0.4229 - val_accuracy: 0.7970 - val_loss: 0.4257 - learning_rate: 9.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - accuracy: 0.7997 - loss: 0.4157 - val_accuracy: 0.7803 - val_loss: 0.4330 - learning_rate: 9.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - accuracy: 0.8074 - loss: 0.4084 - val_accuracy: 0.7907 - val_loss: 0.4204 - learning_rate: 9.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step - accuracy: 0.8013 - loss: 0.4098 - val_accuracy: 0.7867 - val_loss: 0.4209 - learning_rate: 8.1000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.8020 - loss: 0.4120 - val_accuracy: 0.7924 - val_loss: 0.4249 - learning_rate: 8.1000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.8116 - loss: 0.4002 - val_accuracy: 0.7970 - val_loss: 0.4169 - learning_rate: 8.1000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - accuracy: 0.7991 - loss: 0.4089 - val_accuracy: 0.7855 - val_loss: 0.4270 - learning_rate: 8.1000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - accuracy: 0.8034 - loss: 0.4096 - val_accuracy: 0.7803 - val_loss: 0.4221 - learning_rate: 8.1000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - accuracy: 0.7939 - loss: 0.4186 - val_accuracy: 0.7913 - val_loss: 0.4181 - learning_rate: 8.1000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - accuracy: 0.8038 - loss: 0.4079 - val_accuracy: 0.7976 - val_loss: 0.4126 - learning_rate: 8.1000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.8060 - loss: 0.4024 - val_accuracy: 0.7878 - val_loss: 0.4198 - learning_rate: 8.1000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.8076 - loss: 0.4105 - val_accuracy: 0.7947 - val_loss: 0.4155 - learning_rate: 8.1000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.8011 - loss: 0.4113 - val_accuracy: 0.7878 - val_loss: 0.4206 - learning_rate: 8.1000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step - accuracy: 0.8141 - loss: 0.4011 - val_accuracy: 0.7936 - val_loss: 0.4189 - learning_rate: 7.2900e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543us/step - accuracy: 0.7997 - loss: 0.4045 - val_accuracy: 0.7976 - val_loss: 0.4135 - learning_rate: 7.2900e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - accuracy: 0.8077 - loss: 0.4074 - val_accuracy: 0.7953 - val_loss: 0.4213 - learning_rate: 7.2900e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.8067 - loss: 0.4019 - val_accuracy: 0.7964 - val_loss: 0.4134 - learning_rate: 7.2900e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.8106 - loss: 0.3987 - val_accuracy: 0.7809 - val_loss: 0.4169 - learning_rate: 7.2900e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - accuracy: 0.8073 - loss: 0.3896 - val_accuracy: 0.7959 - val_loss: 0.4178 - learning_rate: 7.2900e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - accuracy: 0.8034 - loss: 0.3975 - val_accuracy: 0.7884 - val_loss: 0.4161 - learning_rate: 7.2900e-04\n",
      "Iteration 0 using ADAM: Validation Accuracy = 0.7975848317146301\n",
      "New best model found and saved.\n",
      "Epoch 1/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.5143 - loss: 0.7144 - val_accuracy: 0.7044 - val_loss: 0.6289 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - accuracy: 0.6265 - loss: 0.6456 - val_accuracy: 0.7533 - val_loss: 0.5766 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - accuracy: 0.6849 - loss: 0.5964 - val_accuracy: 0.7556 - val_loss: 0.5415 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - accuracy: 0.7100 - loss: 0.5688 - val_accuracy: 0.7579 - val_loss: 0.5189 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - accuracy: 0.7314 - loss: 0.5502 - val_accuracy: 0.7545 - val_loss: 0.5044 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - accuracy: 0.7464 - loss: 0.5261 - val_accuracy: 0.7573 - val_loss: 0.4949 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7621 - loss: 0.5151 - val_accuracy: 0.7573 - val_loss: 0.4889 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7565 - loss: 0.5052 - val_accuracy: 0.7608 - val_loss: 0.4849 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - accuracy: 0.7502 - loss: 0.5201 - val_accuracy: 0.7608 - val_loss: 0.4821 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7625 - loss: 0.4979 - val_accuracy: 0.7631 - val_loss: 0.4801 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7741 - loss: 0.4853 - val_accuracy: 0.7637 - val_loss: 0.4793 - learning_rate: 9.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7628 - loss: 0.4873 - val_accuracy: 0.7619 - val_loss: 0.4783 - learning_rate: 9.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - accuracy: 0.7662 - loss: 0.4910 - val_accuracy: 0.7619 - val_loss: 0.4771 - learning_rate: 9.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.7715 - loss: 0.4860 - val_accuracy: 0.7637 - val_loss: 0.4765 - learning_rate: 9.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - accuracy: 0.7702 - loss: 0.4865 - val_accuracy: 0.7648 - val_loss: 0.4758 - learning_rate: 9.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - accuracy: 0.7677 - loss: 0.4831 - val_accuracy: 0.7654 - val_loss: 0.4756 - learning_rate: 9.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7675 - loss: 0.4875 - val_accuracy: 0.7654 - val_loss: 0.4749 - learning_rate: 9.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.7729 - loss: 0.4746 - val_accuracy: 0.7660 - val_loss: 0.4745 - learning_rate: 9.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.7721 - loss: 0.4756 - val_accuracy: 0.7654 - val_loss: 0.4742 - learning_rate: 9.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - accuracy: 0.7755 - loss: 0.4774 - val_accuracy: 0.7631 - val_loss: 0.4739 - learning_rate: 9.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - accuracy: 0.7805 - loss: 0.4671 - val_accuracy: 0.7665 - val_loss: 0.4735 - learning_rate: 8.1000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - accuracy: 0.7664 - loss: 0.4803 - val_accuracy: 0.7660 - val_loss: 0.4729 - learning_rate: 8.1000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7684 - loss: 0.4826 - val_accuracy: 0.7671 - val_loss: 0.4726 - learning_rate: 8.1000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7739 - loss: 0.4797 - val_accuracy: 0.7700 - val_loss: 0.4722 - learning_rate: 8.1000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7777 - loss: 0.4691 - val_accuracy: 0.7683 - val_loss: 0.4719 - learning_rate: 8.1000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7663 - loss: 0.4728 - val_accuracy: 0.7700 - val_loss: 0.4714 - learning_rate: 8.1000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7720 - loss: 0.4769 - val_accuracy: 0.7694 - val_loss: 0.4711 - learning_rate: 8.1000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - accuracy: 0.7737 - loss: 0.4821 - val_accuracy: 0.7706 - val_loss: 0.4710 - learning_rate: 8.1000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.7655 - loss: 0.4828 - val_accuracy: 0.7717 - val_loss: 0.4711 - learning_rate: 8.1000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - accuracy: 0.7696 - loss: 0.4758 - val_accuracy: 0.7700 - val_loss: 0.4704 - learning_rate: 8.1000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - accuracy: 0.7816 - loss: 0.4609 - val_accuracy: 0.7694 - val_loss: 0.4702 - learning_rate: 7.2900e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376us/step - accuracy: 0.7676 - loss: 0.4675 - val_accuracy: 0.7700 - val_loss: 0.4699 - learning_rate: 7.2900e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7745 - loss: 0.4746 - val_accuracy: 0.7717 - val_loss: 0.4697 - learning_rate: 7.2900e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7687 - loss: 0.4743 - val_accuracy: 0.7711 - val_loss: 0.4694 - learning_rate: 7.2900e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - accuracy: 0.7861 - loss: 0.4535 - val_accuracy: 0.7706 - val_loss: 0.4691 - learning_rate: 7.2900e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.7839 - loss: 0.4603 - val_accuracy: 0.7723 - val_loss: 0.4689 - learning_rate: 7.2900e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7717 - loss: 0.4777 - val_accuracy: 0.7723 - val_loss: 0.4686 - learning_rate: 7.2900e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - accuracy: 0.7815 - loss: 0.4581 - val_accuracy: 0.7694 - val_loss: 0.4684 - learning_rate: 7.2900e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.7779 - loss: 0.4607 - val_accuracy: 0.7711 - val_loss: 0.4682 - learning_rate: 7.2900e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7699 - loss: 0.4730 - val_accuracy: 0.7717 - val_loss: 0.4682 - learning_rate: 7.2900e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.7845 - loss: 0.4660 - val_accuracy: 0.7723 - val_loss: 0.4678 - learning_rate: 6.5610e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.7777 - loss: 0.4633 - val_accuracy: 0.7723 - val_loss: 0.4678 - learning_rate: 6.5610e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - accuracy: 0.7731 - loss: 0.4739 - val_accuracy: 0.7723 - val_loss: 0.4678 - learning_rate: 6.5610e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.7688 - loss: 0.4740 - val_accuracy: 0.7706 - val_loss: 0.4678 - learning_rate: 6.5610e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7777 - loss: 0.4649 - val_accuracy: 0.7717 - val_loss: 0.4675 - learning_rate: 6.5610e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - accuracy: 0.7738 - loss: 0.4855 - val_accuracy: 0.7711 - val_loss: 0.4676 - learning_rate: 6.5610e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.7750 - loss: 0.4747 - val_accuracy: 0.7706 - val_loss: 0.4675 - learning_rate: 6.5610e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - accuracy: 0.7813 - loss: 0.4706 - val_accuracy: 0.7729 - val_loss: 0.4671 - learning_rate: 6.5610e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7766 - loss: 0.4612 - val_accuracy: 0.7734 - val_loss: 0.4670 - learning_rate: 6.5610e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7858 - loss: 0.4573 - val_accuracy: 0.7717 - val_loss: 0.4669 - learning_rate: 6.5610e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7800 - loss: 0.4637 - val_accuracy: 0.7723 - val_loss: 0.4667 - learning_rate: 5.9049e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.7837 - loss: 0.4567 - val_accuracy: 0.7729 - val_loss: 0.4666 - learning_rate: 5.9049e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.7895 - loss: 0.4471 - val_accuracy: 0.7734 - val_loss: 0.4665 - learning_rate: 5.9049e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7786 - loss: 0.4633 - val_accuracy: 0.7734 - val_loss: 0.4665 - learning_rate: 5.9049e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - accuracy: 0.7800 - loss: 0.4605 - val_accuracy: 0.7740 - val_loss: 0.4663 - learning_rate: 5.9049e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.7859 - loss: 0.4566 - val_accuracy: 0.7729 - val_loss: 0.4663 - learning_rate: 5.9049e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - accuracy: 0.7683 - loss: 0.4779 - val_accuracy: 0.7734 - val_loss: 0.4662 - learning_rate: 5.9049e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - accuracy: 0.7815 - loss: 0.4663 - val_accuracy: 0.7740 - val_loss: 0.4663 - learning_rate: 5.9049e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376us/step - accuracy: 0.7840 - loss: 0.4503 - val_accuracy: 0.7729 - val_loss: 0.4664 - learning_rate: 5.9049e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.7766 - loss: 0.4675 - val_accuracy: 0.7740 - val_loss: 0.4663 - learning_rate: 5.9049e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.7803 - loss: 0.4652 - val_accuracy: 0.7746 - val_loss: 0.4661 - learning_rate: 5.3144e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7791 - loss: 0.4645 - val_accuracy: 0.7729 - val_loss: 0.4661 - learning_rate: 5.3144e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - accuracy: 0.7892 - loss: 0.4534 - val_accuracy: 0.7740 - val_loss: 0.4660 - learning_rate: 5.3144e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.7829 - loss: 0.4643 - val_accuracy: 0.7740 - val_loss: 0.4658 - learning_rate: 5.3144e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.7722 - loss: 0.4614 - val_accuracy: 0.7734 - val_loss: 0.4661 - learning_rate: 5.3144e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.7893 - loss: 0.4504 - val_accuracy: 0.7740 - val_loss: 0.4662 - learning_rate: 5.3144e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - accuracy: 0.7967 - loss: 0.4387 - val_accuracy: 0.7740 - val_loss: 0.4660 - learning_rate: 5.3144e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7843 - loss: 0.4693 - val_accuracy: 0.7729 - val_loss: 0.4657 - learning_rate: 5.3144e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.7788 - loss: 0.4597 - val_accuracy: 0.7740 - val_loss: 0.4656 - learning_rate: 5.3144e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.7759 - loss: 0.4732 - val_accuracy: 0.7734 - val_loss: 0.4655 - learning_rate: 5.3144e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - accuracy: 0.7827 - loss: 0.4579 - val_accuracy: 0.7729 - val_loss: 0.4655 - learning_rate: 4.7830e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - accuracy: 0.7870 - loss: 0.4531 - val_accuracy: 0.7734 - val_loss: 0.4654 - learning_rate: 4.7830e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - accuracy: 0.7735 - loss: 0.4679 - val_accuracy: 0.7740 - val_loss: 0.4653 - learning_rate: 4.7830e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - accuracy: 0.7705 - loss: 0.4825 - val_accuracy: 0.7740 - val_loss: 0.4652 - learning_rate: 4.7830e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7837 - loss: 0.4609 - val_accuracy: 0.7734 - val_loss: 0.4652 - learning_rate: 4.7830e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - accuracy: 0.7822 - loss: 0.4649 - val_accuracy: 0.7746 - val_loss: 0.4651 - learning_rate: 4.7830e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.7849 - loss: 0.4651 - val_accuracy: 0.7740 - val_loss: 0.4649 - learning_rate: 4.7830e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.7916 - loss: 0.4524 - val_accuracy: 0.7740 - val_loss: 0.4650 - learning_rate: 4.7830e-04\n",
      "Epoch 79/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7806 - loss: 0.4610 - val_accuracy: 0.7740 - val_loss: 0.4650 - learning_rate: 4.7830e-04\n",
      "Epoch 80/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473us/step - accuracy: 0.7813 - loss: 0.4507 - val_accuracy: 0.7740 - val_loss: 0.4650 - learning_rate: 4.7830e-04\n",
      "Epoch 81/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - accuracy: 0.8002 - loss: 0.4378 - val_accuracy: 0.7752 - val_loss: 0.4651 - learning_rate: 4.3047e-04\n",
      "Epoch 82/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - accuracy: 0.7784 - loss: 0.4624 - val_accuracy: 0.7746 - val_loss: 0.4650 - learning_rate: 4.3047e-04\n",
      "Epoch 83/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - accuracy: 0.7774 - loss: 0.4587 - val_accuracy: 0.7763 - val_loss: 0.4652 - learning_rate: 4.3047e-04\n",
      "Epoch 84/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - accuracy: 0.7815 - loss: 0.4611 - val_accuracy: 0.7752 - val_loss: 0.4649 - learning_rate: 4.3047e-04\n",
      "Epoch 85/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7700 - loss: 0.4727 - val_accuracy: 0.7763 - val_loss: 0.4649 - learning_rate: 4.3047e-04\n",
      "Epoch 86/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7805 - loss: 0.4647 - val_accuracy: 0.7746 - val_loss: 0.4648 - learning_rate: 4.3047e-04\n",
      "Epoch 87/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - accuracy: 0.7884 - loss: 0.4500 - val_accuracy: 0.7757 - val_loss: 0.4648 - learning_rate: 4.3047e-04\n",
      "Epoch 88/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7805 - loss: 0.4645 - val_accuracy: 0.7752 - val_loss: 0.4648 - learning_rate: 4.3047e-04\n",
      "Epoch 89/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.7692 - loss: 0.4645 - val_accuracy: 0.7763 - val_loss: 0.4646 - learning_rate: 4.3047e-04\n",
      "Epoch 90/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7883 - loss: 0.4514 - val_accuracy: 0.7757 - val_loss: 0.4647 - learning_rate: 4.3047e-04\n",
      "Epoch 91/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - accuracy: 0.7775 - loss: 0.4699 - val_accuracy: 0.7757 - val_loss: 0.4647 - learning_rate: 3.8742e-04\n",
      "Epoch 92/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7845 - loss: 0.4594 - val_accuracy: 0.7757 - val_loss: 0.4647 - learning_rate: 3.8742e-04\n",
      "Epoch 93/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7880 - loss: 0.4533 - val_accuracy: 0.7763 - val_loss: 0.4647 - learning_rate: 3.8742e-04\n",
      "Epoch 94/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - accuracy: 0.7892 - loss: 0.4533 - val_accuracy: 0.7763 - val_loss: 0.4647 - learning_rate: 3.8742e-04\n",
      "Epoch 95/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - accuracy: 0.7794 - loss: 0.4584 - val_accuracy: 0.7775 - val_loss: 0.4647 - learning_rate: 3.8742e-04\n",
      "Epoch 96/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7760 - loss: 0.4595 - val_accuracy: 0.7769 - val_loss: 0.4647 - learning_rate: 3.8742e-04\n",
      "Epoch 97/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - accuracy: 0.7875 - loss: 0.4533 - val_accuracy: 0.7757 - val_loss: 0.4647 - learning_rate: 3.8742e-04\n",
      "Epoch 98/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - accuracy: 0.7842 - loss: 0.4603 - val_accuracy: 0.7769 - val_loss: 0.4647 - learning_rate: 3.8742e-04\n",
      "Epoch 99/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.7698 - loss: 0.4744 - val_accuracy: 0.7769 - val_loss: 0.4646 - learning_rate: 3.8742e-04\n",
      "Epoch 100/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7805 - loss: 0.4581 - val_accuracy: 0.7763 - val_loss: 0.4645 - learning_rate: 3.8742e-04\n",
      "Iteration 1 using SGD: Validation Accuracy = 0.7763082385063171\n",
      "Epoch 1/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - accuracy: 0.7344 - loss: 0.5225 - val_accuracy: 0.7688 - val_loss: 0.4669 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - accuracy: 0.7717 - loss: 0.4688 - val_accuracy: 0.7740 - val_loss: 0.4621 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - accuracy: 0.7735 - loss: 0.4638 - val_accuracy: 0.7775 - val_loss: 0.4639 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - accuracy: 0.7865 - loss: 0.4508 - val_accuracy: 0.7729 - val_loss: 0.4579 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - accuracy: 0.7922 - loss: 0.4447 - val_accuracy: 0.7798 - val_loss: 0.4528 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - accuracy: 0.7859 - loss: 0.4500 - val_accuracy: 0.7769 - val_loss: 0.4514 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - accuracy: 0.7939 - loss: 0.4376 - val_accuracy: 0.7752 - val_loss: 0.4547 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step - accuracy: 0.7900 - loss: 0.4416 - val_accuracy: 0.7775 - val_loss: 0.4515 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - accuracy: 0.7862 - loss: 0.4421 - val_accuracy: 0.7757 - val_loss: 0.4521 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - accuracy: 0.7940 - loss: 0.4349 - val_accuracy: 0.7809 - val_loss: 0.4383 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - accuracy: 0.7955 - loss: 0.4270 - val_accuracy: 0.7769 - val_loss: 0.4406 - learning_rate: 9.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473us/step - accuracy: 0.7942 - loss: 0.4285 - val_accuracy: 0.7838 - val_loss: 0.4342 - learning_rate: 9.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - accuracy: 0.7983 - loss: 0.4234 - val_accuracy: 0.7855 - val_loss: 0.4329 - learning_rate: 9.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - accuracy: 0.8036 - loss: 0.4120 - val_accuracy: 0.7826 - val_loss: 0.4253 - learning_rate: 9.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - accuracy: 0.8072 - loss: 0.4101 - val_accuracy: 0.7901 - val_loss: 0.4251 - learning_rate: 9.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473us/step - accuracy: 0.8002 - loss: 0.4247 - val_accuracy: 0.7832 - val_loss: 0.4266 - learning_rate: 9.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - accuracy: 0.7975 - loss: 0.4153 - val_accuracy: 0.7936 - val_loss: 0.4206 - learning_rate: 9.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - accuracy: 0.8131 - loss: 0.3944 - val_accuracy: 0.7821 - val_loss: 0.4259 - learning_rate: 9.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step - accuracy: 0.7921 - loss: 0.4240 - val_accuracy: 0.7815 - val_loss: 0.4280 - learning_rate: 9.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - accuracy: 0.7963 - loss: 0.4122 - val_accuracy: 0.7918 - val_loss: 0.4233 - learning_rate: 9.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step - accuracy: 0.8006 - loss: 0.4156 - val_accuracy: 0.7861 - val_loss: 0.4242 - learning_rate: 8.1000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - accuracy: 0.8088 - loss: 0.4092 - val_accuracy: 0.7936 - val_loss: 0.4197 - learning_rate: 8.1000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - accuracy: 0.8055 - loss: 0.4057 - val_accuracy: 0.7884 - val_loss: 0.4204 - learning_rate: 8.1000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - accuracy: 0.8069 - loss: 0.4160 - val_accuracy: 0.7918 - val_loss: 0.4196 - learning_rate: 8.1000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - accuracy: 0.8030 - loss: 0.4020 - val_accuracy: 0.7884 - val_loss: 0.4190 - learning_rate: 8.1000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - accuracy: 0.8060 - loss: 0.3960 - val_accuracy: 0.7959 - val_loss: 0.4148 - learning_rate: 8.1000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - accuracy: 0.7992 - loss: 0.4130 - val_accuracy: 0.7838 - val_loss: 0.4219 - learning_rate: 8.1000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step - accuracy: 0.8028 - loss: 0.4098 - val_accuracy: 0.7855 - val_loss: 0.4218 - learning_rate: 8.1000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - accuracy: 0.8118 - loss: 0.4002 - val_accuracy: 0.7878 - val_loss: 0.4204 - learning_rate: 8.1000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - accuracy: 0.7970 - loss: 0.4088 - val_accuracy: 0.7930 - val_loss: 0.4183 - learning_rate: 8.1000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - accuracy: 0.8055 - loss: 0.3937 - val_accuracy: 0.7878 - val_loss: 0.4183 - learning_rate: 7.2900e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - accuracy: 0.8102 - loss: 0.3975 - val_accuracy: 0.7890 - val_loss: 0.4144 - learning_rate: 7.2900e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - accuracy: 0.8029 - loss: 0.4029 - val_accuracy: 0.7982 - val_loss: 0.4131 - learning_rate: 7.2900e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - accuracy: 0.8074 - loss: 0.3975 - val_accuracy: 0.7924 - val_loss: 0.4196 - learning_rate: 7.2900e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - accuracy: 0.7959 - loss: 0.4110 - val_accuracy: 0.7930 - val_loss: 0.4170 - learning_rate: 7.2900e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - accuracy: 0.8100 - loss: 0.3969 - val_accuracy: 0.7895 - val_loss: 0.4139 - learning_rate: 7.2900e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - accuracy: 0.8120 - loss: 0.3904 - val_accuracy: 0.7930 - val_loss: 0.4197 - learning_rate: 7.2900e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - accuracy: 0.8148 - loss: 0.3851 - val_accuracy: 0.7993 - val_loss: 0.4164 - learning_rate: 7.2900e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step - accuracy: 0.8089 - loss: 0.3886 - val_accuracy: 0.7872 - val_loss: 0.4145 - learning_rate: 7.2900e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - accuracy: 0.8033 - loss: 0.3985 - val_accuracy: 0.7924 - val_loss: 0.4133 - learning_rate: 7.2900e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545us/step - accuracy: 0.8097 - loss: 0.3894 - val_accuracy: 0.7970 - val_loss: 0.4088 - learning_rate: 6.5610e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - accuracy: 0.7977 - loss: 0.4098 - val_accuracy: 0.7953 - val_loss: 0.4191 - learning_rate: 6.5610e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step - accuracy: 0.8122 - loss: 0.3893 - val_accuracy: 0.7993 - val_loss: 0.4145 - learning_rate: 6.5610e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - accuracy: 0.8094 - loss: 0.3939 - val_accuracy: 0.7982 - val_loss: 0.4117 - learning_rate: 6.5610e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step - accuracy: 0.8042 - loss: 0.3997 - val_accuracy: 0.7907 - val_loss: 0.4170 - learning_rate: 6.5610e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - accuracy: 0.8126 - loss: 0.3933 - val_accuracy: 0.7907 - val_loss: 0.4231 - learning_rate: 6.5610e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - accuracy: 0.8121 - loss: 0.3918 - val_accuracy: 0.7924 - val_loss: 0.4132 - learning_rate: 6.5610e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - accuracy: 0.8183 - loss: 0.3876 - val_accuracy: 0.7987 - val_loss: 0.4107 - learning_rate: 6.5610e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - accuracy: 0.8047 - loss: 0.3947 - val_accuracy: 0.7890 - val_loss: 0.4138 - learning_rate: 6.5610e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - accuracy: 0.8147 - loss: 0.3875 - val_accuracy: 0.7953 - val_loss: 0.4132 - learning_rate: 6.5610e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - accuracy: 0.8072 - loss: 0.3893 - val_accuracy: 0.7976 - val_loss: 0.4098 - learning_rate: 5.9049e-04\n",
      "Iteration 2 using ADAM: Validation Accuracy = 0.7970097661018372\n",
      "Epoch 1/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.4868 - loss: 0.7433 - val_accuracy: 0.6791 - val_loss: 0.6236 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - accuracy: 0.6334 - loss: 0.6344 - val_accuracy: 0.7332 - val_loss: 0.5655 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - accuracy: 0.6864 - loss: 0.5918 - val_accuracy: 0.7412 - val_loss: 0.5339 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - accuracy: 0.7147 - loss: 0.5671 - val_accuracy: 0.7476 - val_loss: 0.5146 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7407 - loss: 0.5352 - val_accuracy: 0.7510 - val_loss: 0.5018 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7615 - loss: 0.5138 - val_accuracy: 0.7510 - val_loss: 0.4930 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7599 - loss: 0.5071 - val_accuracy: 0.7510 - val_loss: 0.4871 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7602 - loss: 0.5013 - val_accuracy: 0.7504 - val_loss: 0.4835 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7577 - loss: 0.5010 - val_accuracy: 0.7522 - val_loss: 0.4809 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7593 - loss: 0.4985 - val_accuracy: 0.7545 - val_loss: 0.4791 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - accuracy: 0.7667 - loss: 0.4882 - val_accuracy: 0.7562 - val_loss: 0.4782 - learning_rate: 9.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7759 - loss: 0.4848 - val_accuracy: 0.7585 - val_loss: 0.4776 - learning_rate: 9.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7722 - loss: 0.4810 - val_accuracy: 0.7596 - val_loss: 0.4770 - learning_rate: 9.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7704 - loss: 0.4844 - val_accuracy: 0.7619 - val_loss: 0.4763 - learning_rate: 9.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.7699 - loss: 0.4918 - val_accuracy: 0.7619 - val_loss: 0.4754 - learning_rate: 9.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - accuracy: 0.7713 - loss: 0.4845 - val_accuracy: 0.7637 - val_loss: 0.4749 - learning_rate: 9.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - accuracy: 0.7772 - loss: 0.4777 - val_accuracy: 0.7642 - val_loss: 0.4744 - learning_rate: 9.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7689 - loss: 0.4875 - val_accuracy: 0.7648 - val_loss: 0.4739 - learning_rate: 9.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - accuracy: 0.7755 - loss: 0.4800 - val_accuracy: 0.7642 - val_loss: 0.4739 - learning_rate: 9.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7546 - loss: 0.4963 - val_accuracy: 0.7648 - val_loss: 0.4735 - learning_rate: 9.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - accuracy: 0.7738 - loss: 0.4832 - val_accuracy: 0.7660 - val_loss: 0.4729 - learning_rate: 8.1000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - accuracy: 0.7765 - loss: 0.4690 - val_accuracy: 0.7660 - val_loss: 0.4725 - learning_rate: 8.1000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7690 - loss: 0.4754 - val_accuracy: 0.7654 - val_loss: 0.4721 - learning_rate: 8.1000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7680 - loss: 0.4809 - val_accuracy: 0.7665 - val_loss: 0.4717 - learning_rate: 8.1000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7815 - loss: 0.4615 - val_accuracy: 0.7665 - val_loss: 0.4716 - learning_rate: 8.1000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - accuracy: 0.7806 - loss: 0.4751 - val_accuracy: 0.7671 - val_loss: 0.4711 - learning_rate: 8.1000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - accuracy: 0.7750 - loss: 0.4679 - val_accuracy: 0.7665 - val_loss: 0.4711 - learning_rate: 8.1000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - accuracy: 0.7694 - loss: 0.4790 - val_accuracy: 0.7665 - val_loss: 0.4710 - learning_rate: 8.1000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7814 - loss: 0.4666 - val_accuracy: 0.7671 - val_loss: 0.4704 - learning_rate: 8.1000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7758 - loss: 0.4890 - val_accuracy: 0.7660 - val_loss: 0.4701 - learning_rate: 8.1000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7796 - loss: 0.4695 - val_accuracy: 0.7677 - val_loss: 0.4697 - learning_rate: 7.2900e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - accuracy: 0.7663 - loss: 0.4789 - val_accuracy: 0.7665 - val_loss: 0.4697 - learning_rate: 7.2900e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7694 - loss: 0.4860 - val_accuracy: 0.7677 - val_loss: 0.4696 - learning_rate: 7.2900e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - accuracy: 0.7799 - loss: 0.4678 - val_accuracy: 0.7683 - val_loss: 0.4697 - learning_rate: 7.2900e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7795 - loss: 0.4720 - val_accuracy: 0.7665 - val_loss: 0.4695 - learning_rate: 7.2900e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7749 - loss: 0.4721 - val_accuracy: 0.7677 - val_loss: 0.4696 - learning_rate: 7.2900e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7756 - loss: 0.4692 - val_accuracy: 0.7677 - val_loss: 0.4694 - learning_rate: 7.2900e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7740 - loss: 0.4749 - val_accuracy: 0.7677 - val_loss: 0.4690 - learning_rate: 7.2900e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - accuracy: 0.7771 - loss: 0.4662 - val_accuracy: 0.7671 - val_loss: 0.4689 - learning_rate: 7.2900e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7891 - loss: 0.4612 - val_accuracy: 0.7665 - val_loss: 0.4684 - learning_rate: 7.2900e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7766 - loss: 0.4716 - val_accuracy: 0.7677 - val_loss: 0.4687 - learning_rate: 6.5610e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - accuracy: 0.7862 - loss: 0.4592 - val_accuracy: 0.7683 - val_loss: 0.4684 - learning_rate: 6.5610e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - accuracy: 0.7806 - loss: 0.4641 - val_accuracy: 0.7683 - val_loss: 0.4682 - learning_rate: 6.5610e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7678 - loss: 0.4714 - val_accuracy: 0.7688 - val_loss: 0.4681 - learning_rate: 6.5610e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7801 - loss: 0.4662 - val_accuracy: 0.7677 - val_loss: 0.4679 - learning_rate: 6.5610e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.7769 - loss: 0.4639 - val_accuracy: 0.7671 - val_loss: 0.4678 - learning_rate: 6.5610e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7831 - loss: 0.4550 - val_accuracy: 0.7665 - val_loss: 0.4677 - learning_rate: 6.5610e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7759 - loss: 0.4651 - val_accuracy: 0.7688 - val_loss: 0.4678 - learning_rate: 6.5610e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - accuracy: 0.7685 - loss: 0.4797 - val_accuracy: 0.7683 - val_loss: 0.4676 - learning_rate: 6.5610e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.7874 - loss: 0.4713 - val_accuracy: 0.7688 - val_loss: 0.4674 - learning_rate: 6.5610e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7799 - loss: 0.4618 - val_accuracy: 0.7700 - val_loss: 0.4672 - learning_rate: 5.9049e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.7922 - loss: 0.4540 - val_accuracy: 0.7706 - val_loss: 0.4673 - learning_rate: 5.9049e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473us/step - accuracy: 0.7746 - loss: 0.4648 - val_accuracy: 0.7688 - val_loss: 0.4675 - learning_rate: 5.9049e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - accuracy: 0.7849 - loss: 0.4592 - val_accuracy: 0.7700 - val_loss: 0.4672 - learning_rate: 5.9049e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - accuracy: 0.7793 - loss: 0.4649 - val_accuracy: 0.7717 - val_loss: 0.4670 - learning_rate: 5.9049e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7718 - loss: 0.4862 - val_accuracy: 0.7711 - val_loss: 0.4670 - learning_rate: 5.9049e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - accuracy: 0.7825 - loss: 0.4602 - val_accuracy: 0.7723 - val_loss: 0.4668 - learning_rate: 5.9049e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7798 - loss: 0.4685 - val_accuracy: 0.7723 - val_loss: 0.4667 - learning_rate: 5.9049e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7883 - loss: 0.4561 - val_accuracy: 0.7700 - val_loss: 0.4667 - learning_rate: 5.9049e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7764 - loss: 0.4715 - val_accuracy: 0.7677 - val_loss: 0.4666 - learning_rate: 5.9049e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7785 - loss: 0.4683 - val_accuracy: 0.7694 - val_loss: 0.4666 - learning_rate: 5.3144e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - accuracy: 0.7799 - loss: 0.4579 - val_accuracy: 0.7694 - val_loss: 0.4666 - learning_rate: 5.3144e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7764 - loss: 0.4719 - val_accuracy: 0.7711 - val_loss: 0.4667 - learning_rate: 5.3144e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - accuracy: 0.7749 - loss: 0.4641 - val_accuracy: 0.7717 - val_loss: 0.4665 - learning_rate: 5.3144e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.7781 - loss: 0.4637 - val_accuracy: 0.7706 - val_loss: 0.4666 - learning_rate: 5.3144e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7710 - loss: 0.4762 - val_accuracy: 0.7706 - val_loss: 0.4665 - learning_rate: 5.3144e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7849 - loss: 0.4600 - val_accuracy: 0.7700 - val_loss: 0.4664 - learning_rate: 5.3144e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7749 - loss: 0.4730 - val_accuracy: 0.7711 - val_loss: 0.4663 - learning_rate: 5.3144e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7876 - loss: 0.4610 - val_accuracy: 0.7706 - val_loss: 0.4664 - learning_rate: 5.3144e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7787 - loss: 0.4551 - val_accuracy: 0.7711 - val_loss: 0.4663 - learning_rate: 5.3144e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - accuracy: 0.7752 - loss: 0.4606 - val_accuracy: 0.7706 - val_loss: 0.4664 - learning_rate: 4.7830e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.7789 - loss: 0.4599 - val_accuracy: 0.7711 - val_loss: 0.4663 - learning_rate: 4.7830e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475us/step - accuracy: 0.7657 - loss: 0.4781 - val_accuracy: 0.7706 - val_loss: 0.4662 - learning_rate: 4.7830e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.7907 - loss: 0.4554 - val_accuracy: 0.7717 - val_loss: 0.4661 - learning_rate: 4.7830e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7825 - loss: 0.4580 - val_accuracy: 0.7717 - val_loss: 0.4660 - learning_rate: 4.7830e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7779 - loss: 0.4623 - val_accuracy: 0.7711 - val_loss: 0.4659 - learning_rate: 4.7830e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7760 - loss: 0.4670 - val_accuracy: 0.7717 - val_loss: 0.4660 - learning_rate: 4.7830e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - accuracy: 0.7913 - loss: 0.4510 - val_accuracy: 0.7711 - val_loss: 0.4659 - learning_rate: 4.7830e-04\n",
      "Epoch 79/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - accuracy: 0.7676 - loss: 0.4676 - val_accuracy: 0.7717 - val_loss: 0.4658 - learning_rate: 4.7830e-04\n",
      "Epoch 80/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7917 - loss: 0.4532 - val_accuracy: 0.7729 - val_loss: 0.4658 - learning_rate: 4.7830e-04\n",
      "Epoch 81/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.7772 - loss: 0.4678 - val_accuracy: 0.7723 - val_loss: 0.4657 - learning_rate: 4.3047e-04\n",
      "Epoch 82/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step - accuracy: 0.7775 - loss: 0.4627 - val_accuracy: 0.7729 - val_loss: 0.4657 - learning_rate: 4.3047e-04\n",
      "Epoch 83/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7888 - loss: 0.4490 - val_accuracy: 0.7729 - val_loss: 0.4658 - learning_rate: 4.3047e-04\n",
      "Epoch 84/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.7777 - loss: 0.4567 - val_accuracy: 0.7723 - val_loss: 0.4656 - learning_rate: 4.3047e-04\n",
      "Epoch 85/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7757 - loss: 0.4668 - val_accuracy: 0.7717 - val_loss: 0.4657 - learning_rate: 4.3047e-04\n",
      "Epoch 86/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7734 - loss: 0.4708 - val_accuracy: 0.7711 - val_loss: 0.4654 - learning_rate: 4.3047e-04\n",
      "Epoch 87/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.7865 - loss: 0.4605 - val_accuracy: 0.7734 - val_loss: 0.4652 - learning_rate: 4.3047e-04\n",
      "Epoch 88/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7784 - loss: 0.4582 - val_accuracy: 0.7746 - val_loss: 0.4652 - learning_rate: 4.3047e-04\n",
      "Epoch 89/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7807 - loss: 0.4615 - val_accuracy: 0.7734 - val_loss: 0.4654 - learning_rate: 4.3047e-04\n",
      "Epoch 90/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - accuracy: 0.7773 - loss: 0.4655 - val_accuracy: 0.7740 - val_loss: 0.4654 - learning_rate: 4.3047e-04\n",
      "Epoch 91/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - accuracy: 0.7830 - loss: 0.4573 - val_accuracy: 0.7729 - val_loss: 0.4655 - learning_rate: 3.8742e-04\n",
      "Epoch 92/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7890 - loss: 0.4493 - val_accuracy: 0.7729 - val_loss: 0.4654 - learning_rate: 3.8742e-04\n",
      "Epoch 93/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7718 - loss: 0.4712 - val_accuracy: 0.7734 - val_loss: 0.4654 - learning_rate: 3.8742e-04\n",
      "Epoch 94/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.7849 - loss: 0.4536 - val_accuracy: 0.7740 - val_loss: 0.4653 - learning_rate: 3.8742e-04\n",
      "Epoch 95/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7877 - loss: 0.4557 - val_accuracy: 0.7734 - val_loss: 0.4653 - learning_rate: 3.8742e-04\n",
      "Epoch 96/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - accuracy: 0.7842 - loss: 0.4529 - val_accuracy: 0.7746 - val_loss: 0.4652 - learning_rate: 3.8742e-04\n",
      "Epoch 97/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7887 - loss: 0.4559 - val_accuracy: 0.7752 - val_loss: 0.4652 - learning_rate: 3.8742e-04\n",
      "Epoch 98/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7824 - loss: 0.4603 - val_accuracy: 0.7746 - val_loss: 0.4652 - learning_rate: 3.8742e-04\n",
      "Epoch 99/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7878 - loss: 0.4572 - val_accuracy: 0.7746 - val_loss: 0.4651 - learning_rate: 3.8742e-04\n",
      "Epoch 100/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - accuracy: 0.7807 - loss: 0.4569 - val_accuracy: 0.7740 - val_loss: 0.4651 - learning_rate: 3.8742e-04\n",
      "Iteration 3 using SGD: Validation Accuracy = 0.77400803565979\n",
      "Epoch 1/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 611us/step - accuracy: 0.7284 - loss: 0.5287 - val_accuracy: 0.7752 - val_loss: 0.4755 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - accuracy: 0.7776 - loss: 0.4691 - val_accuracy: 0.7723 - val_loss: 0.4736 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - accuracy: 0.7867 - loss: 0.4545 - val_accuracy: 0.7752 - val_loss: 0.4619 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.7721 - loss: 0.4714 - val_accuracy: 0.7677 - val_loss: 0.4629 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - accuracy: 0.7918 - loss: 0.4459 - val_accuracy: 0.7757 - val_loss: 0.4496 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - accuracy: 0.7884 - loss: 0.4456 - val_accuracy: 0.7809 - val_loss: 0.4480 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - accuracy: 0.7899 - loss: 0.4432 - val_accuracy: 0.7729 - val_loss: 0.4546 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - accuracy: 0.7950 - loss: 0.4264 - val_accuracy: 0.7809 - val_loss: 0.4451 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step - accuracy: 0.7925 - loss: 0.4221 - val_accuracy: 0.7775 - val_loss: 0.4446 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475us/step - accuracy: 0.7979 - loss: 0.4343 - val_accuracy: 0.7821 - val_loss: 0.4339 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.8114 - loss: 0.4089 - val_accuracy: 0.7757 - val_loss: 0.4334 - learning_rate: 9.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - accuracy: 0.7962 - loss: 0.4248 - val_accuracy: 0.7895 - val_loss: 0.4282 - learning_rate: 9.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - accuracy: 0.7922 - loss: 0.4193 - val_accuracy: 0.7878 - val_loss: 0.4293 - learning_rate: 9.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step - accuracy: 0.7947 - loss: 0.4258 - val_accuracy: 0.7901 - val_loss: 0.4394 - learning_rate: 9.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - accuracy: 0.8001 - loss: 0.4189 - val_accuracy: 0.7941 - val_loss: 0.4233 - learning_rate: 9.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.8002 - loss: 0.4136 - val_accuracy: 0.7803 - val_loss: 0.4313 - learning_rate: 9.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - accuracy: 0.8014 - loss: 0.4058 - val_accuracy: 0.7861 - val_loss: 0.4242 - learning_rate: 9.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - accuracy: 0.8051 - loss: 0.4117 - val_accuracy: 0.7884 - val_loss: 0.4242 - learning_rate: 9.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - accuracy: 0.8022 - loss: 0.4125 - val_accuracy: 0.7878 - val_loss: 0.4252 - learning_rate: 9.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574us/step - accuracy: 0.8037 - loss: 0.4119 - val_accuracy: 0.7884 - val_loss: 0.4280 - learning_rate: 9.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.8047 - loss: 0.4144 - val_accuracy: 0.7861 - val_loss: 0.4235 - learning_rate: 8.1000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.7984 - loss: 0.4104 - val_accuracy: 0.7832 - val_loss: 0.4226 - learning_rate: 8.1000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - accuracy: 0.8009 - loss: 0.4135 - val_accuracy: 0.7895 - val_loss: 0.4203 - learning_rate: 8.1000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - accuracy: 0.8104 - loss: 0.4009 - val_accuracy: 0.7964 - val_loss: 0.4248 - learning_rate: 8.1000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - accuracy: 0.8042 - loss: 0.4134 - val_accuracy: 0.7924 - val_loss: 0.4193 - learning_rate: 8.1000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - accuracy: 0.8086 - loss: 0.3948 - val_accuracy: 0.7803 - val_loss: 0.4275 - learning_rate: 8.1000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - accuracy: 0.8049 - loss: 0.4000 - val_accuracy: 0.7913 - val_loss: 0.4209 - learning_rate: 8.1000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - accuracy: 0.7964 - loss: 0.4170 - val_accuracy: 0.7924 - val_loss: 0.4201 - learning_rate: 8.1000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - accuracy: 0.8066 - loss: 0.4084 - val_accuracy: 0.7924 - val_loss: 0.4211 - learning_rate: 8.1000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574us/step - accuracy: 0.7997 - loss: 0.4023 - val_accuracy: 0.7936 - val_loss: 0.4163 - learning_rate: 8.1000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.8125 - loss: 0.3822 - val_accuracy: 0.7982 - val_loss: 0.4163 - learning_rate: 7.2900e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.7985 - loss: 0.4070 - val_accuracy: 0.7907 - val_loss: 0.4206 - learning_rate: 7.2900e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.8046 - loss: 0.4076 - val_accuracy: 0.7964 - val_loss: 0.4134 - learning_rate: 7.2900e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - accuracy: 0.8061 - loss: 0.3990 - val_accuracy: 0.7918 - val_loss: 0.4139 - learning_rate: 7.2900e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.8178 - loss: 0.3881 - val_accuracy: 0.7895 - val_loss: 0.4180 - learning_rate: 7.2900e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - accuracy: 0.8068 - loss: 0.3972 - val_accuracy: 0.7895 - val_loss: 0.4131 - learning_rate: 7.2900e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.8000 - loss: 0.3999 - val_accuracy: 0.7895 - val_loss: 0.4176 - learning_rate: 7.2900e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473us/step - accuracy: 0.8085 - loss: 0.4013 - val_accuracy: 0.7941 - val_loss: 0.4121 - learning_rate: 7.2900e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.8075 - loss: 0.3985 - val_accuracy: 0.7913 - val_loss: 0.4135 - learning_rate: 7.2900e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.8052 - loss: 0.3929 - val_accuracy: 0.7964 - val_loss: 0.4136 - learning_rate: 7.2900e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.8158 - loss: 0.3863 - val_accuracy: 0.7941 - val_loss: 0.4116 - learning_rate: 6.5610e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - accuracy: 0.8156 - loss: 0.3853 - val_accuracy: 0.7970 - val_loss: 0.4122 - learning_rate: 6.5610e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.8020 - loss: 0.4087 - val_accuracy: 0.7999 - val_loss: 0.4186 - learning_rate: 6.5610e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.8213 - loss: 0.3859 - val_accuracy: 0.8028 - val_loss: 0.4079 - learning_rate: 6.5610e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.8122 - loss: 0.3987 - val_accuracy: 0.7976 - val_loss: 0.4113 - learning_rate: 6.5610e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - accuracy: 0.8120 - loss: 0.3987 - val_accuracy: 0.7959 - val_loss: 0.4085 - learning_rate: 6.5610e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.8066 - loss: 0.3962 - val_accuracy: 0.7976 - val_loss: 0.4114 - learning_rate: 6.5610e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547us/step - accuracy: 0.8141 - loss: 0.4035 - val_accuracy: 0.7976 - val_loss: 0.4088 - learning_rate: 6.5610e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - accuracy: 0.8121 - loss: 0.3903 - val_accuracy: 0.7953 - val_loss: 0.4100 - learning_rate: 6.5610e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 0.8132 - loss: 0.3974 - val_accuracy: 0.8010 - val_loss: 0.4084 - learning_rate: 6.5610e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - accuracy: 0.8176 - loss: 0.3822 - val_accuracy: 0.7930 - val_loss: 0.4107 - learning_rate: 5.9049e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.8141 - loss: 0.3831 - val_accuracy: 0.7970 - val_loss: 0.4078 - learning_rate: 5.9049e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545us/step - accuracy: 0.8154 - loss: 0.3919 - val_accuracy: 0.7970 - val_loss: 0.4102 - learning_rate: 5.9049e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.8149 - loss: 0.3852 - val_accuracy: 0.7964 - val_loss: 0.4080 - learning_rate: 5.9049e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.8119 - loss: 0.3918 - val_accuracy: 0.7987 - val_loss: 0.4132 - learning_rate: 5.9049e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.8163 - loss: 0.3902 - val_accuracy: 0.7982 - val_loss: 0.4096 - learning_rate: 5.9049e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.8173 - loss: 0.3861 - val_accuracy: 0.7999 - val_loss: 0.4165 - learning_rate: 5.9049e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.8135 - loss: 0.3948 - val_accuracy: 0.7976 - val_loss: 0.4098 - learning_rate: 5.9049e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - accuracy: 0.8144 - loss: 0.3889 - val_accuracy: 0.7987 - val_loss: 0.4123 - learning_rate: 5.9049e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.8090 - loss: 0.3884 - val_accuracy: 0.7970 - val_loss: 0.4122 - learning_rate: 5.9049e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - accuracy: 0.8150 - loss: 0.3848 - val_accuracy: 0.7987 - val_loss: 0.4160 - learning_rate: 5.3144e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.8131 - loss: 0.3913 - val_accuracy: 0.7987 - val_loss: 0.4083 - learning_rate: 5.3144e-04\n",
      "Iteration 4 using ADAM: Validation Accuracy = 0.7970097661018372\n",
      "Target accuracy not reached after maximum iterations.\n",
      "Final Model Validation Accuracy: 0.7975848317146301\n",
      "Epoch 1/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431us/step - accuracy: 0.7959 - loss: 0.4135\n",
      "Epoch 2/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - accuracy: 0.7975 - loss: 0.4122\n",
      "Epoch 3/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475us/step - accuracy: 0.7972 - loss: 0.4142\n",
      "Epoch 4/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - accuracy: 0.8004 - loss: 0.4025\n",
      "Epoch 5/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.8041 - loss: 0.4085\n",
      "Epoch 6/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - accuracy: 0.8044 - loss: 0.4025\n",
      "Epoch 7/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - accuracy: 0.7972 - loss: 0.4158\n",
      "Epoch 8/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - accuracy: 0.8058 - loss: 0.4033\n",
      "Epoch 9/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - accuracy: 0.7986 - loss: 0.4092\n",
      "Epoch 10/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - accuracy: 0.8058 - loss: 0.4060\n",
      "Epoch 11/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - accuracy: 0.7971 - loss: 0.4114\n",
      "Epoch 12/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - accuracy: 0.8199 - loss: 0.3926\n",
      "Epoch 13/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - accuracy: 0.7973 - loss: 0.4094\n",
      "Epoch 14/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - accuracy: 0.7990 - loss: 0.4014\n",
      "Epoch 15/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - accuracy: 0.8109 - loss: 0.3968\n",
      "Epoch 16/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - accuracy: 0.8020 - loss: 0.3993\n",
      "Epoch 17/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - accuracy: 0.8103 - loss: 0.4000\n",
      "Epoch 18/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - accuracy: 0.8046 - loss: 0.4012\n",
      "Epoch 19/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - accuracy: 0.8068 - loss: 0.4023\n",
      "Epoch 20/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - accuracy: 0.8124 - loss: 0.3927\n",
      "Epoch 21/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - accuracy: 0.8051 - loss: 0.4012\n",
      "Epoch 22/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.8077 - loss: 0.3933\n",
      "Epoch 23/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - accuracy: 0.8135 - loss: 0.3941\n",
      "Epoch 24/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - accuracy: 0.8023 - loss: 0.3992\n",
      "Epoch 25/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - accuracy: 0.8057 - loss: 0.3957\n",
      "Epoch 26/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - accuracy: 0.8021 - loss: 0.3970\n",
      "Epoch 27/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - accuracy: 0.8157 - loss: 0.3908\n",
      "Epoch 28/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - accuracy: 0.8059 - loss: 0.3964\n",
      "Epoch 29/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.8074 - loss: 0.3944\n",
      "Epoch 30/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - accuracy: 0.8140 - loss: 0.3900\n",
      "Epoch 31/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - accuracy: 0.8093 - loss: 0.3983\n",
      "Epoch 32/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.8029 - loss: 0.3936\n",
      "Epoch 33/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - accuracy: 0.8059 - loss: 0.3980\n",
      "Epoch 34/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - accuracy: 0.8199 - loss: 0.3882\n",
      "Epoch 35/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - accuracy: 0.8119 - loss: 0.3887\n",
      "Epoch 36/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - accuracy: 0.8083 - loss: 0.3910\n",
      "Epoch 37/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435us/step - accuracy: 0.8080 - loss: 0.3969\n",
      "Epoch 38/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417us/step - accuracy: 0.8180 - loss: 0.3786\n",
      "Epoch 39/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - accuracy: 0.8058 - loss: 0.3927\n",
      "Epoch 40/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.8170 - loss: 0.3804\n",
      "Epoch 41/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - accuracy: 0.8142 - loss: 0.3873\n",
      "Epoch 42/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - accuracy: 0.8136 - loss: 0.3830\n",
      "Epoch 43/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - accuracy: 0.8130 - loss: 0.3815\n",
      "Epoch 44/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - accuracy: 0.8080 - loss: 0.3930\n",
      "Epoch 45/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - accuracy: 0.8157 - loss: 0.3890\n",
      "Epoch 46/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - accuracy: 0.8156 - loss: 0.3967\n",
      "Epoch 47/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - accuracy: 0.8172 - loss: 0.3905\n",
      "Epoch 48/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.8096 - loss: 0.3928\n",
      "Epoch 49/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - accuracy: 0.8152 - loss: 0.3926\n",
      "Epoch 50/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - accuracy: 0.8144 - loss: 0.3887\n",
      "Epoch 51/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - accuracy: 0.8082 - loss: 0.3947\n",
      "Epoch 52/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - accuracy: 0.8155 - loss: 0.3912\n",
      "Epoch 53/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - accuracy: 0.8182 - loss: 0.3800\n",
      "Epoch 54/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - accuracy: 0.8120 - loss: 0.3921\n",
      "Epoch 55/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474us/step - accuracy: 0.8216 - loss: 0.3702\n",
      "Epoch 56/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - accuracy: 0.8154 - loss: 0.3847\n",
      "Epoch 57/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - accuracy: 0.8147 - loss: 0.3917\n",
      "Epoch 58/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.8089 - loss: 0.3940\n",
      "Epoch 59/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - accuracy: 0.8103 - loss: 0.3878\n",
      "Epoch 60/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420us/step - accuracy: 0.8122 - loss: 0.3902\n",
      "Epoch 61/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - accuracy: 0.8169 - loss: 0.3811\n",
      "Epoch 62/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - accuracy: 0.8174 - loss: 0.3852\n",
      "Epoch 63/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - accuracy: 0.8163 - loss: 0.3777\n",
      "Epoch 64/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - accuracy: 0.8125 - loss: 0.3897\n",
      "Epoch 65/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.8192 - loss: 0.3895\n",
      "Epoch 66/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - accuracy: 0.8144 - loss: 0.3854\n",
      "Epoch 67/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - accuracy: 0.8178 - loss: 0.3825\n",
      "Epoch 68/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - accuracy: 0.8188 - loss: 0.3849\n",
      "Epoch 69/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - accuracy: 0.8233 - loss: 0.3741\n",
      "Epoch 70/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - accuracy: 0.8233 - loss: 0.3772\n",
      "Epoch 71/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.8164 - loss: 0.3796\n",
      "Epoch 72/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - accuracy: 0.8170 - loss: 0.3729\n",
      "Epoch 73/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - accuracy: 0.8190 - loss: 0.3784\n",
      "Epoch 74/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - accuracy: 0.8130 - loss: 0.3916\n",
      "Epoch 75/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - accuracy: 0.8222 - loss: 0.3757\n",
      "Epoch 76/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417us/step - accuracy: 0.8147 - loss: 0.3774\n",
      "Epoch 77/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - accuracy: 0.8176 - loss: 0.3789\n",
      "Epoch 78/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - accuracy: 0.8107 - loss: 0.3805\n",
      "Epoch 79/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.8206 - loss: 0.3782\n",
      "Epoch 80/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - accuracy: 0.8176 - loss: 0.3754\n",
      "Epoch 81/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - accuracy: 0.8193 - loss: 0.3789\n",
      "Epoch 82/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - accuracy: 0.8067 - loss: 0.3907\n",
      "Epoch 83/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - accuracy: 0.8173 - loss: 0.3807\n",
      "Epoch 84/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.8130 - loss: 0.3865\n",
      "Epoch 85/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - accuracy: 0.8254 - loss: 0.3761\n",
      "Epoch 86/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414us/step - accuracy: 0.8201 - loss: 0.3752\n",
      "Epoch 87/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434us/step - accuracy: 0.8160 - loss: 0.3760\n",
      "Epoch 88/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - accuracy: 0.8228 - loss: 0.3714\n",
      "Epoch 89/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - accuracy: 0.8267 - loss: 0.3618\n",
      "Epoch 90/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - accuracy: 0.8218 - loss: 0.3734\n",
      "Epoch 91/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - accuracy: 0.8188 - loss: 0.3795\n",
      "Epoch 92/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414us/step - accuracy: 0.8195 - loss: 0.3808\n",
      "Epoch 93/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - accuracy: 0.8190 - loss: 0.3739\n",
      "Epoch 94/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - accuracy: 0.8132 - loss: 0.3858\n",
      "Epoch 95/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - accuracy: 0.8171 - loss: 0.3814\n",
      "Epoch 96/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - accuracy: 0.8169 - loss: 0.3752\n",
      "Epoch 97/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - accuracy: 0.8202 - loss: 0.3757\n",
      "Epoch 98/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - accuracy: 0.8251 - loss: 0.3737\n",
      "Epoch 99/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.8265 - loss: 0.3706\n",
      "Epoch 100/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441us/step - accuracy: 0.8259 - loss: 0.3638\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2ae68fb90>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = preprocess_data('csv_files/train.csv', is_train=True)\n",
    "test_df = preprocess_data('csv_files/test.csv', is_train=False)\n",
    "\n",
    "# Function to create the model, now with an optimizer parameter\n",
    "def create_model(input_shape, layers, activation, dropout_rate, learning_rate, optimizer_type='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(layers[0], activation=activation, input_shape=(input_shape,)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    for layer_size in layers[1:]:\n",
    "        model.add(Dense(layer_size, activation=activation))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Choose the optimizer\n",
    "    if optimizer_type == 'sgd':\n",
    "        optimizer = SGD(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Define a schedule function\n",
    "def lr_schedule(epoch, lr):\n",
    "    if epoch > 0 and epoch % 10 == 0:\n",
    "        return lr * 0.9\n",
    "    return lr\n",
    "\n",
    "def train_and_evaluate(model, X_train, y_train, X_val, y_val, batch_size, epochs, class_weight):\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    learning_rate_scheduler = LearningRateScheduler(lr_schedule)\n",
    "    model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, \n",
    "              validation_data=(X_val, y_val), class_weight=class_weight, \n",
    "              callbacks=[early_stopping, learning_rate_scheduler])\n",
    "    val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
    "    return val_loss, val_acc\n",
    "\n",
    "# Prepare features and target for the model\n",
    "features = [col for col in train_df.columns if col not in ['PassengerId', 'Name', 'Transported', 'Cabin_Deck', 'HomePlanet_TotalSpending', 'Destination_TotalSpending']]\n",
    "X = train_df[features]\n",
    "y = train_df['Transported']\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Handling class imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train_smote),\n",
    "    y=y_train_smote)\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# Optimization loop\n",
    "target_accuracy = 0.85\n",
    "max_iterations = 5\n",
    "current_iteration = 0\n",
    "best_val_acc = 0\n",
    "best_params = {'layers': [128, 128, 64], 'activation': 'tanh', 'dropout_rate': 0.3, 'learning_rate': 0.001}\n",
    "# Initialization outside the loop\n",
    "best_model = None\n",
    "\n",
    "while current_iteration < max_iterations:\n",
    "    # Use best parameters from previous iterations\n",
    "    layers = best_params['layers']\n",
    "    activation = best_params['activation']\n",
    "    dropout_rate = best_params['dropout_rate']\n",
    "    learning_rate = best_params['learning_rate']\n",
    "    \n",
    "    # Here you can decide to use SGD or Adam based on some condition, e.g., alternate between them\n",
    "    if current_iteration % 2 == 0:\n",
    "        optimizer_type = 'adam'\n",
    "    else:\n",
    "        optimizer_type = 'sgd'\n",
    "    \n",
    "    # Create and train the model\n",
    "    model = create_model(input_shape=X_train_smote.shape[1], \n",
    "                         layers=layers, \n",
    "                         activation=activation, \n",
    "                         dropout_rate=dropout_rate, \n",
    "                         learning_rate=learning_rate,\n",
    "                         optimizer_type=optimizer_type)\n",
    "\n",
    "    val_loss, val_acc = train_and_evaluate(model, X_train_smote, y_train_smote, X_val, y_val, \n",
    "                                           batch_size=16, epochs=100, class_weight=class_weight_dict)\n",
    "\n",
    "    print(f'Iteration {current_iteration} using {optimizer_type.upper()}: Validation Accuracy = {val_acc}')\n",
    "\n",
    "    # Update best parameters if current model is better\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_params = {'layers': layers, 'activation': activation, 'dropout_rate': dropout_rate, 'learning_rate': learning_rate, 'optimizer_type': optimizer_type}\n",
    "        best_model = model  \n",
    "        print(\"New best model found and saved.\")\n",
    "\n",
    "    # Adjust model complexity based on performance\n",
    "    if val_acc < best_val_acc - 0.05:  # significant drop in performance\n",
    "        layers = [max(l // 2, 32) for l in layers]  # reduce complexity\n",
    "    elif val_acc > best_val_acc:\n",
    "        layers = [min(l * 2, 512) for l in layers]  # increase complexity if showing improvement\n",
    "\n",
    "    # Try different activation functions\n",
    "    if current_iteration % 2 == 0:\n",
    "        activation = 'relu'\n",
    "    else:\n",
    "        activation = 'tanh'\n",
    "\n",
    "    # Adjust dropout rate based on overfitting/underfitting\n",
    "    if val_acc < best_val_acc - 0.03:  # underfitting\n",
    "        dropout_rate = max(dropout_rate - 0.1, 0)\n",
    "    elif val_acc > best_val_acc + 0.03:  # overfitting\n",
    "        dropout_rate = min(dropout_rate + 0.1, 0.5)\n",
    "\n",
    "    # Adjust learning rate based on performance\n",
    "    if val_acc < best_val_acc - 0.02:\n",
    "        learning_rate *= 0.5  # reduce learning rate if performance drops\n",
    "    elif val_acc > best_val_acc + 0.02:\n",
    "        learning_rate *= 1.2  # increase learning rate if performance improves\n",
    "\n",
    "    if best_val_acc >= target_accuracy:\n",
    "        print(\"Target accuracy reached.\")\n",
    "        break\n",
    "\n",
    "    current_iteration += 1\n",
    "\n",
    "# Final evaluation\n",
    "if best_val_acc < target_accuracy:\n",
    "    print(\"Target accuracy not reached after maximum iterations.\")\n",
    "    print(f\"Final Model Validation Accuracy: {best_val_acc}\")\n",
    "else:\n",
    "    print(f\"Final Model Validation Accuracy: {best_val_acc}\")\n",
    "\n",
    "model_enhanced = best_model\n",
    "# Combine the original training and validation sets for final training\n",
    "X_full, y_full = smote.fit_resample(X, y)\n",
    "model_enhanced.fit(X_full, y_full, batch_size=16, epochs=100, class_weight=class_weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_1127\" is incompatible with the layer: expected axis -1 of input shape to have value 16, but received input with shape (32, 19)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(32, 19), dtype=float32)\n  • training=False\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m X_test_np \u001b[38;5;241m=\u001b[39m X_test\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Predict using the enhanced model\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m y_pred_test_proba \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_enhanced\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_np\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m y_pred_test \u001b[38;5;241m=\u001b[39m (y_pred_test_proba \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Prepare the submission dataframe\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ML/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:123\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/ML/lib/python3.12/site-packages/keras/src/layers/input_spec.py:227\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis, value \u001b[38;5;129;01min\u001b[39;00m spec\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape[axis] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[1;32m    224\u001b[0m             value,\n\u001b[1;32m    225\u001b[0m             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    226\u001b[0m         }:\n\u001b[0;32m--> 227\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    228\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    229\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: expected axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    230\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof input shape to have value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    231\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut received input with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    232\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    233\u001b[0m             )\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m# Check shape.\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_1127\" is incompatible with the layer: expected axis -1 of input shape to have value 16, but received input with shape (32, 19)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(32, 19), dtype=float32)\n  • training=False\n  • mask=None"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# Load the best model\n",
    "model_enhanced = load_model('model_enhanced.keras')\n",
    "\n",
    "# Preprocess the test data using the same steps as the training data\n",
    "test_df = preprocess_data('csv_files/test.csv', is_train=False)\n",
    "\n",
    "# Load the features used during training\n",
    "train_features = joblib.load('train_features.pkl')\n",
    "\n",
    "# Select the features used by the model, ensuring they are the same as those used in training\n",
    "features = [col for col in train_features if col in test_df.columns]\n",
    "\n",
    "# Ensure that X_test is a DataFrame with the correct numerical types\n",
    "X_test = test_df[features].copy()\n",
    "\n",
    "# Convert X_test to a NumPy array, which is the expected format for TensorFlow models\n",
    "X_test_np = X_test.values\n",
    "\n",
    "# Predict using the enhanced model\n",
    "y_pred_test_proba = model_enhanced.predict(X_test_np)\n",
    "y_pred_test = (y_pred_test_proba > 0.5).astype(int).flatten()\n",
    "\n",
    "# Prepare the submission dataframe\n",
    "submission_df = pd.DataFrame({\n",
    "    'PassengerId': test_df['PassengerId'],\n",
    "    'Transported': y_pred_test\n",
    "})\n",
    "\n",
    "# Convert predictions back to boolean (True/False) if necessary\n",
    "submission_df['Transported'] = submission_df['Transported'].astype(bool)\n",
    "\n",
    "# Save the submission file\n",
    "submission_df.to_csv('enhanced_model_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rahulnundlall/anaconda3/envs/ML/lib/python3.12/site-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7383 - loss: 0.5151 - val_accuracy: 0.7792 - val_loss: 0.4555\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7841 - loss: 0.4496 - val_accuracy: 0.7815 - val_loss: 0.4501\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - accuracy: 0.7928 - loss: 0.4447 - val_accuracy: 0.7809 - val_loss: 0.4328\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - accuracy: 0.7981 - loss: 0.4403 - val_accuracy: 0.7826 - val_loss: 0.4323\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - accuracy: 0.7954 - loss: 0.4219 - val_accuracy: 0.7849 - val_loss: 0.4416\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - accuracy: 0.8035 - loss: 0.4206 - val_accuracy: 0.7821 - val_loss: 0.4439\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - accuracy: 0.7999 - loss: 0.4246 - val_accuracy: 0.7821 - val_loss: 0.4326\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - accuracy: 0.7995 - loss: 0.4182 - val_accuracy: 0.7844 - val_loss: 0.4252\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - accuracy: 0.7931 - loss: 0.4329 - val_accuracy: 0.7780 - val_loss: 0.4301\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - accuracy: 0.7981 - loss: 0.4287 - val_accuracy: 0.7855 - val_loss: 0.4401\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step - accuracy: 0.8047 - loss: 0.4209 - val_accuracy: 0.7746 - val_loss: 0.4468\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - accuracy: 0.7995 - loss: 0.4194 - val_accuracy: 0.7924 - val_loss: 0.4210\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - accuracy: 0.8046 - loss: 0.4161 - val_accuracy: 0.7849 - val_loss: 0.4151\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - accuracy: 0.8062 - loss: 0.4051 - val_accuracy: 0.7861 - val_loss: 0.4236\n",
      "Epoch 15/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8014 - loss: 0.4139 - val_accuracy: 0.7861 - val_loss: 0.4203\n",
      "Epoch 16/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - accuracy: 0.8105 - loss: 0.4055 - val_accuracy: 0.7815 - val_loss: 0.4221\n",
      "Epoch 17/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - accuracy: 0.8020 - loss: 0.4101 - val_accuracy: 0.7849 - val_loss: 0.4225\n",
      "Epoch 18/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8072 - loss: 0.4080 - val_accuracy: 0.7815 - val_loss: 0.4331\n",
      "Epoch 19/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8183 - loss: 0.3865 - val_accuracy: 0.7872 - val_loss: 0.4201\n",
      "Epoch 20/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - accuracy: 0.8110 - loss: 0.4071 - val_accuracy: 0.7959 - val_loss: 0.4146\n",
      "Epoch 21/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - accuracy: 0.8053 - loss: 0.4079 - val_accuracy: 0.7809 - val_loss: 0.4207\n",
      "Epoch 22/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - accuracy: 0.8172 - loss: 0.3904 - val_accuracy: 0.7872 - val_loss: 0.4272\n",
      "Epoch 23/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - accuracy: 0.7996 - loss: 0.4086 - val_accuracy: 0.7855 - val_loss: 0.4176\n",
      "Epoch 24/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - accuracy: 0.8186 - loss: 0.3944 - val_accuracy: 0.7918 - val_loss: 0.4208\n",
      "Epoch 25/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - accuracy: 0.8019 - loss: 0.4018 - val_accuracy: 0.7878 - val_loss: 0.4254\n",
      "Epoch 26/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step - accuracy: 0.8086 - loss: 0.3917 - val_accuracy: 0.7936 - val_loss: 0.4179\n",
      "Epoch 27/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - accuracy: 0.8115 - loss: 0.3962 - val_accuracy: 0.7964 - val_loss: 0.4152\n",
      "Epoch 28/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - accuracy: 0.8020 - loss: 0.3905 - val_accuracy: 0.7890 - val_loss: 0.4228\n",
      "Epoch 29/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - accuracy: 0.8097 - loss: 0.3914 - val_accuracy: 0.7907 - val_loss: 0.4351\n",
      "Epoch 30/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 990us/step - accuracy: 0.8023 - loss: 0.3956 - val_accuracy: 0.7844 - val_loss: 0.4283\n",
      "Epoch 1/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7407 - loss: 0.5294 - val_accuracy: 0.7723 - val_loss: 0.4591\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7894 - loss: 0.4368 - val_accuracy: 0.7775 - val_loss: 0.4515\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7966 - loss: 0.4259 - val_accuracy: 0.7890 - val_loss: 0.4381\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7998 - loss: 0.4230 - val_accuracy: 0.7763 - val_loss: 0.4389\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8081 - loss: 0.4100 - val_accuracy: 0.7867 - val_loss: 0.4324\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8045 - loss: 0.4137 - val_accuracy: 0.7821 - val_loss: 0.4393\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7969 - loss: 0.4184 - val_accuracy: 0.7844 - val_loss: 0.4292\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8019 - loss: 0.4128 - val_accuracy: 0.7809 - val_loss: 0.4313\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8097 - loss: 0.3995 - val_accuracy: 0.7849 - val_loss: 0.4250\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8147 - loss: 0.3971 - val_accuracy: 0.7844 - val_loss: 0.4358\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7970 - loss: 0.4113 - val_accuracy: 0.7872 - val_loss: 0.4273\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8198 - loss: 0.3798 - val_accuracy: 0.7867 - val_loss: 0.4232\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8003 - loss: 0.4060 - val_accuracy: 0.7959 - val_loss: 0.4290\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8190 - loss: 0.3843 - val_accuracy: 0.7798 - val_loss: 0.4263\n",
      "Epoch 15/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8133 - loss: 0.3969 - val_accuracy: 0.7803 - val_loss: 0.4241\n",
      "Epoch 16/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8192 - loss: 0.3763 - val_accuracy: 0.7924 - val_loss: 0.4199\n",
      "Epoch 17/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8202 - loss: 0.3831 - val_accuracy: 0.7867 - val_loss: 0.4261\n",
      "Epoch 18/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8219 - loss: 0.3854 - val_accuracy: 0.7907 - val_loss: 0.4219\n",
      "Epoch 19/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8206 - loss: 0.3815 - val_accuracy: 0.7803 - val_loss: 0.4225\n",
      "Epoch 20/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8078 - loss: 0.3842 - val_accuracy: 0.7861 - val_loss: 0.4255\n",
      "Epoch 21/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8174 - loss: 0.3757 - val_accuracy: 0.7849 - val_loss: 0.4260\n",
      "Epoch 22/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8223 - loss: 0.3704 - val_accuracy: 0.7855 - val_loss: 0.4265\n",
      "Epoch 23/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8183 - loss: 0.3752 - val_accuracy: 0.7964 - val_loss: 0.4198\n",
      "Epoch 24/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8116 - loss: 0.3849 - val_accuracy: 0.7913 - val_loss: 0.4257\n",
      "Epoch 25/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8114 - loss: 0.3811 - val_accuracy: 0.7867 - val_loss: 0.4274\n",
      "Epoch 26/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8230 - loss: 0.3693 - val_accuracy: 0.7895 - val_loss: 0.4192\n",
      "Epoch 27/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8218 - loss: 0.3657 - val_accuracy: 0.7918 - val_loss: 0.4299\n",
      "Epoch 28/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8323 - loss: 0.3603 - val_accuracy: 0.7878 - val_loss: 0.4284\n",
      "Epoch 29/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8223 - loss: 0.3634 - val_accuracy: 0.7838 - val_loss: 0.4269\n",
      "Epoch 30/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8274 - loss: 0.3653 - val_accuracy: 0.7844 - val_loss: 0.4288\n",
      "Epoch 31/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8244 - loss: 0.3673 - val_accuracy: 0.7849 - val_loss: 0.4197\n",
      "Epoch 32/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8189 - loss: 0.3684 - val_accuracy: 0.7855 - val_loss: 0.4235\n",
      "Epoch 33/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8322 - loss: 0.3577 - val_accuracy: 0.7884 - val_loss: 0.4281\n",
      "Epoch 34/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8314 - loss: 0.3570 - val_accuracy: 0.7959 - val_loss: 0.4209\n",
      "Epoch 35/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8262 - loss: 0.3566 - val_accuracy: 0.7861 - val_loss: 0.4188\n",
      "Epoch 36/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8262 - loss: 0.3573 - val_accuracy: 0.7901 - val_loss: 0.4164\n",
      "Epoch 37/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8215 - loss: 0.3660 - val_accuracy: 0.7924 - val_loss: 0.4260\n",
      "Epoch 38/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8336 - loss: 0.3550 - val_accuracy: 0.7884 - val_loss: 0.4296\n",
      "Epoch 39/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8399 - loss: 0.3510 - val_accuracy: 0.7930 - val_loss: 0.4182\n",
      "Epoch 40/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8263 - loss: 0.3566 - val_accuracy: 0.7913 - val_loss: 0.4229\n",
      "Epoch 41/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8358 - loss: 0.3459 - val_accuracy: 0.7890 - val_loss: 0.4182\n",
      "Epoch 42/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8359 - loss: 0.3465 - val_accuracy: 0.7844 - val_loss: 0.4287\n",
      "Epoch 43/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8336 - loss: 0.3511 - val_accuracy: 0.7849 - val_loss: 0.4266\n",
      "Epoch 44/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8349 - loss: 0.3446 - val_accuracy: 0.7890 - val_loss: 0.4214\n",
      "Epoch 45/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8321 - loss: 0.3463 - val_accuracy: 0.7930 - val_loss: 0.4359\n",
      "Epoch 46/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8376 - loss: 0.3355 - val_accuracy: 0.7867 - val_loss: 0.4251\n",
      "Epoch 1/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 816us/step - accuracy: 0.7311 - loss: 0.5697 - val_accuracy: 0.7677 - val_loss: 0.4633\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - accuracy: 0.7972 - loss: 0.4370 - val_accuracy: 0.7809 - val_loss: 0.4528\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - accuracy: 0.7972 - loss: 0.4202 - val_accuracy: 0.7884 - val_loss: 0.4505\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step - accuracy: 0.8041 - loss: 0.4187 - val_accuracy: 0.7786 - val_loss: 0.4476\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - accuracy: 0.8053 - loss: 0.4073 - val_accuracy: 0.7878 - val_loss: 0.4386\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.8102 - loss: 0.4040 - val_accuracy: 0.7786 - val_loss: 0.4415\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - accuracy: 0.8115 - loss: 0.4023 - val_accuracy: 0.7798 - val_loss: 0.4378\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - accuracy: 0.8123 - loss: 0.3982 - val_accuracy: 0.7786 - val_loss: 0.4429\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.8040 - loss: 0.4115 - val_accuracy: 0.7752 - val_loss: 0.4345\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - accuracy: 0.8117 - loss: 0.3915 - val_accuracy: 0.7815 - val_loss: 0.4345\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.8008 - loss: 0.4101 - val_accuracy: 0.7798 - val_loss: 0.4325\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - accuracy: 0.8055 - loss: 0.4067 - val_accuracy: 0.7763 - val_loss: 0.4357\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - accuracy: 0.8105 - loss: 0.3995 - val_accuracy: 0.7826 - val_loss: 0.4378\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - accuracy: 0.8033 - loss: 0.3982 - val_accuracy: 0.7757 - val_loss: 0.4387\n",
      "Epoch 15/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - accuracy: 0.8136 - loss: 0.3906 - val_accuracy: 0.7786 - val_loss: 0.4370\n",
      "Epoch 16/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - accuracy: 0.8149 - loss: 0.3812 - val_accuracy: 0.7792 - val_loss: 0.4341\n",
      "Epoch 17/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - accuracy: 0.8176 - loss: 0.3842 - val_accuracy: 0.7855 - val_loss: 0.4278\n",
      "Epoch 18/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - accuracy: 0.8192 - loss: 0.3871 - val_accuracy: 0.7861 - val_loss: 0.4283\n",
      "Epoch 19/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - accuracy: 0.8070 - loss: 0.4050 - val_accuracy: 0.7855 - val_loss: 0.4267\n",
      "Epoch 20/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.8175 - loss: 0.3799 - val_accuracy: 0.7867 - val_loss: 0.4280\n",
      "Epoch 21/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - accuracy: 0.8190 - loss: 0.3798 - val_accuracy: 0.7798 - val_loss: 0.4277\n",
      "Epoch 22/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.8203 - loss: 0.3754 - val_accuracy: 0.7815 - val_loss: 0.4298\n",
      "Epoch 23/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - accuracy: 0.8237 - loss: 0.3734 - val_accuracy: 0.7941 - val_loss: 0.4244\n",
      "Epoch 24/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.8223 - loss: 0.3690 - val_accuracy: 0.7717 - val_loss: 0.4339\n",
      "Epoch 25/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - accuracy: 0.8187 - loss: 0.3792 - val_accuracy: 0.7855 - val_loss: 0.4340\n",
      "Epoch 26/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - accuracy: 0.8225 - loss: 0.3737 - val_accuracy: 0.7872 - val_loss: 0.4265\n",
      "Epoch 27/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.8256 - loss: 0.3688 - val_accuracy: 0.7964 - val_loss: 0.4257\n",
      "Epoch 28/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - accuracy: 0.8229 - loss: 0.3734 - val_accuracy: 0.7918 - val_loss: 0.4306\n",
      "Epoch 29/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - accuracy: 0.8221 - loss: 0.3774 - val_accuracy: 0.7821 - val_loss: 0.4336\n",
      "Epoch 30/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step - accuracy: 0.8190 - loss: 0.3746 - val_accuracy: 0.7803 - val_loss: 0.4299\n",
      "Epoch 31/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.8213 - loss: 0.3754 - val_accuracy: 0.7809 - val_loss: 0.4268\n",
      "Epoch 32/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574us/step - accuracy: 0.8357 - loss: 0.3549 - val_accuracy: 0.7855 - val_loss: 0.4273\n",
      "Epoch 33/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - accuracy: 0.8138 - loss: 0.3775 - val_accuracy: 0.7867 - val_loss: 0.4259\n",
      "Epoch 1/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7208 - loss: 0.5431 - val_accuracy: 0.7769 - val_loss: 0.4580\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - accuracy: 0.7794 - loss: 0.4561 - val_accuracy: 0.7780 - val_loss: 0.4529\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - accuracy: 0.7978 - loss: 0.4352 - val_accuracy: 0.7844 - val_loss: 0.4404\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - accuracy: 0.7963 - loss: 0.4298 - val_accuracy: 0.7792 - val_loss: 0.4378\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - accuracy: 0.7970 - loss: 0.4200 - val_accuracy: 0.7734 - val_loss: 0.4395\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - accuracy: 0.8043 - loss: 0.4122 - val_accuracy: 0.7826 - val_loss: 0.4303\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - accuracy: 0.7971 - loss: 0.4184 - val_accuracy: 0.7821 - val_loss: 0.4391\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - accuracy: 0.8060 - loss: 0.4118 - val_accuracy: 0.7815 - val_loss: 0.4299\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - accuracy: 0.8125 - loss: 0.4034 - val_accuracy: 0.7826 - val_loss: 0.4305\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - accuracy: 0.7930 - loss: 0.4248 - val_accuracy: 0.7809 - val_loss: 0.4300\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - accuracy: 0.8046 - loss: 0.4024 - val_accuracy: 0.7798 - val_loss: 0.4281\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8131 - loss: 0.3990 - val_accuracy: 0.7895 - val_loss: 0.4244\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - accuracy: 0.8193 - loss: 0.3973 - val_accuracy: 0.7832 - val_loss: 0.4240\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - accuracy: 0.8111 - loss: 0.3939 - val_accuracy: 0.7855 - val_loss: 0.4213\n",
      "Epoch 15/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - accuracy: 0.8130 - loss: 0.3967 - val_accuracy: 0.7872 - val_loss: 0.4361\n",
      "Epoch 16/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - accuracy: 0.8054 - loss: 0.3944 - val_accuracy: 0.7849 - val_loss: 0.4228\n",
      "Epoch 17/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - accuracy: 0.8126 - loss: 0.3937 - val_accuracy: 0.7826 - val_loss: 0.4257\n",
      "Epoch 18/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - accuracy: 0.8047 - loss: 0.4006 - val_accuracy: 0.7878 - val_loss: 0.4224\n",
      "Epoch 19/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step - accuracy: 0.8069 - loss: 0.3983 - val_accuracy: 0.7826 - val_loss: 0.4214\n",
      "Epoch 20/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - accuracy: 0.8120 - loss: 0.3940 - val_accuracy: 0.7913 - val_loss: 0.4172\n",
      "Epoch 21/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - accuracy: 0.8166 - loss: 0.3902 - val_accuracy: 0.7901 - val_loss: 0.4196\n",
      "Epoch 22/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - accuracy: 0.8083 - loss: 0.3899 - val_accuracy: 0.7930 - val_loss: 0.4193\n",
      "Epoch 23/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - accuracy: 0.8120 - loss: 0.4003 - val_accuracy: 0.7901 - val_loss: 0.4169\n",
      "Epoch 24/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - accuracy: 0.8030 - loss: 0.3990 - val_accuracy: 0.7884 - val_loss: 0.4207\n",
      "Epoch 25/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - accuracy: 0.8105 - loss: 0.3863 - val_accuracy: 0.7815 - val_loss: 0.4176\n",
      "Epoch 26/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - accuracy: 0.8129 - loss: 0.3837 - val_accuracy: 0.7907 - val_loss: 0.4209\n",
      "Epoch 27/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - accuracy: 0.8272 - loss: 0.3762 - val_accuracy: 0.7872 - val_loss: 0.4141\n",
      "Epoch 28/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - accuracy: 0.8184 - loss: 0.3760 - val_accuracy: 0.7959 - val_loss: 0.4153\n",
      "Epoch 29/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step - accuracy: 0.8238 - loss: 0.3772 - val_accuracy: 0.7849 - val_loss: 0.4171\n",
      "Epoch 30/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - accuracy: 0.8186 - loss: 0.3804 - val_accuracy: 0.7959 - val_loss: 0.4120\n",
      "Epoch 31/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780us/step - accuracy: 0.8195 - loss: 0.3795 - val_accuracy: 0.7890 - val_loss: 0.4178\n",
      "Epoch 32/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780us/step - accuracy: 0.8229 - loss: 0.3654 - val_accuracy: 0.7890 - val_loss: 0.4150\n",
      "Epoch 33/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step - accuracy: 0.8179 - loss: 0.3779 - val_accuracy: 0.7913 - val_loss: 0.4107\n",
      "Epoch 34/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - accuracy: 0.8239 - loss: 0.3766 - val_accuracy: 0.7901 - val_loss: 0.4148\n",
      "Epoch 35/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - accuracy: 0.8217 - loss: 0.3688 - val_accuracy: 0.7907 - val_loss: 0.4151\n",
      "Epoch 36/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - accuracy: 0.8144 - loss: 0.3868 - val_accuracy: 0.7930 - val_loss: 0.4178\n",
      "Epoch 37/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780us/step - accuracy: 0.8165 - loss: 0.3757 - val_accuracy: 0.7918 - val_loss: 0.4161\n",
      "Epoch 38/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - accuracy: 0.8184 - loss: 0.3780 - val_accuracy: 0.7936 - val_loss: 0.4149\n",
      "Epoch 39/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - accuracy: 0.8207 - loss: 0.3664 - val_accuracy: 0.7872 - val_loss: 0.4200\n",
      "Epoch 40/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - accuracy: 0.8146 - loss: 0.3785 - val_accuracy: 0.7867 - val_loss: 0.4197\n",
      "Epoch 41/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - accuracy: 0.8272 - loss: 0.3611 - val_accuracy: 0.7913 - val_loss: 0.4107\n",
      "Epoch 42/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - accuracy: 0.8254 - loss: 0.3592 - val_accuracy: 0.7901 - val_loss: 0.4175\n",
      "Epoch 43/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - accuracy: 0.8177 - loss: 0.3692 - val_accuracy: 0.7982 - val_loss: 0.4198\n",
      "Epoch 44/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - accuracy: 0.8221 - loss: 0.3696 - val_accuracy: 0.7884 - val_loss: 0.4199\n",
      "Epoch 45/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - accuracy: 0.8196 - loss: 0.3738 - val_accuracy: 0.7947 - val_loss: 0.4174\n",
      "Epoch 46/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - accuracy: 0.8275 - loss: 0.3564 - val_accuracy: 0.7953 - val_loss: 0.4148\n",
      "Epoch 47/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - accuracy: 0.8240 - loss: 0.3579 - val_accuracy: 0.7959 - val_loss: 0.4163\n",
      "Epoch 48/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - accuracy: 0.8270 - loss: 0.3629 - val_accuracy: 0.7947 - val_loss: 0.4147\n",
      "Epoch 49/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - accuracy: 0.8153 - loss: 0.3656 - val_accuracy: 0.7867 - val_loss: 0.4133\n",
      "Epoch 50/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step - accuracy: 0.8346 - loss: 0.3465 - val_accuracy: 0.7878 - val_loss: 0.4146\n",
      "Epoch 1/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 934us/step - accuracy: 0.6891 - loss: 0.5859 - val_accuracy: 0.7734 - val_loss: 0.4657\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - accuracy: 0.7878 - loss: 0.4507 - val_accuracy: 0.7711 - val_loss: 0.4564\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678us/step - accuracy: 0.7879 - loss: 0.4484 - val_accuracy: 0.7723 - val_loss: 0.4523\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - accuracy: 0.7929 - loss: 0.4327 - val_accuracy: 0.7809 - val_loss: 0.4464\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658us/step - accuracy: 0.8063 - loss: 0.4191 - val_accuracy: 0.7924 - val_loss: 0.4405\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - accuracy: 0.7934 - loss: 0.4283 - val_accuracy: 0.7826 - val_loss: 0.4413\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - accuracy: 0.7859 - loss: 0.4439 - val_accuracy: 0.7815 - val_loss: 0.4392\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.7987 - loss: 0.4302 - val_accuracy: 0.7826 - val_loss: 0.4385\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.8080 - loss: 0.4115 - val_accuracy: 0.7821 - val_loss: 0.4369\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - accuracy: 0.8019 - loss: 0.4185 - val_accuracy: 0.7832 - val_loss: 0.4344\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656us/step - accuracy: 0.7921 - loss: 0.4233 - val_accuracy: 0.7826 - val_loss: 0.4334\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - accuracy: 0.8027 - loss: 0.4213 - val_accuracy: 0.7780 - val_loss: 0.4352\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - accuracy: 0.8031 - loss: 0.4167 - val_accuracy: 0.7832 - val_loss: 0.4323\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 0.8018 - loss: 0.4151 - val_accuracy: 0.7844 - val_loss: 0.4327\n",
      "Epoch 15/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.8012 - loss: 0.4181 - val_accuracy: 0.7878 - val_loss: 0.4282\n",
      "Epoch 16/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662us/step - accuracy: 0.8060 - loss: 0.4071 - val_accuracy: 0.7809 - val_loss: 0.4312\n",
      "Epoch 17/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.8041 - loss: 0.4112 - val_accuracy: 0.7838 - val_loss: 0.4265\n",
      "Epoch 18/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658us/step - accuracy: 0.7983 - loss: 0.4168 - val_accuracy: 0.7872 - val_loss: 0.4261\n",
      "Epoch 19/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - accuracy: 0.8037 - loss: 0.4046 - val_accuracy: 0.7895 - val_loss: 0.4264\n",
      "Epoch 20/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658us/step - accuracy: 0.8133 - loss: 0.3907 - val_accuracy: 0.7821 - val_loss: 0.4244\n",
      "Epoch 21/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.8009 - loss: 0.4081 - val_accuracy: 0.7878 - val_loss: 0.4264\n",
      "Epoch 22/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step - accuracy: 0.8098 - loss: 0.3922 - val_accuracy: 0.7907 - val_loss: 0.4210\n",
      "Epoch 23/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - accuracy: 0.8100 - loss: 0.4006 - val_accuracy: 0.7872 - val_loss: 0.4241\n",
      "Epoch 24/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.8184 - loss: 0.3950 - val_accuracy: 0.7855 - val_loss: 0.4205\n",
      "Epoch 25/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - accuracy: 0.8118 - loss: 0.3981 - val_accuracy: 0.7849 - val_loss: 0.4212\n",
      "Epoch 26/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.8069 - loss: 0.4050 - val_accuracy: 0.7872 - val_loss: 0.4216\n",
      "Epoch 27/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.8164 - loss: 0.3920 - val_accuracy: 0.7895 - val_loss: 0.4203\n",
      "Epoch 28/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.8126 - loss: 0.3968 - val_accuracy: 0.7849 - val_loss: 0.4193\n",
      "Epoch 29/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.8141 - loss: 0.3912 - val_accuracy: 0.7890 - val_loss: 0.4186\n",
      "Epoch 30/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.8124 - loss: 0.3862 - val_accuracy: 0.7838 - val_loss: 0.4196\n",
      "Epoch 31/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.8022 - loss: 0.4023 - val_accuracy: 0.7867 - val_loss: 0.4176\n",
      "Epoch 32/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step - accuracy: 0.8205 - loss: 0.3826 - val_accuracy: 0.7838 - val_loss: 0.4173\n",
      "Epoch 33/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - accuracy: 0.8125 - loss: 0.3873 - val_accuracy: 0.7890 - val_loss: 0.4150\n",
      "Epoch 34/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.8155 - loss: 0.3864 - val_accuracy: 0.7878 - val_loss: 0.4182\n",
      "Epoch 35/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656us/step - accuracy: 0.8106 - loss: 0.3855 - val_accuracy: 0.7872 - val_loss: 0.4191\n",
      "Epoch 36/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.8026 - loss: 0.4020 - val_accuracy: 0.7872 - val_loss: 0.4158\n",
      "Epoch 37/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - accuracy: 0.8214 - loss: 0.3798 - val_accuracy: 0.7913 - val_loss: 0.4160\n",
      "Epoch 38/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - accuracy: 0.8268 - loss: 0.3860 - val_accuracy: 0.7832 - val_loss: 0.4164\n",
      "Epoch 39/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.8167 - loss: 0.3749 - val_accuracy: 0.7918 - val_loss: 0.4207\n",
      "Epoch 40/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.8164 - loss: 0.3852 - val_accuracy: 0.7890 - val_loss: 0.4139\n",
      "Epoch 41/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - accuracy: 0.8233 - loss: 0.3796 - val_accuracy: 0.7890 - val_loss: 0.4165\n",
      "Epoch 42/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 0.8113 - loss: 0.3929 - val_accuracy: 0.7918 - val_loss: 0.4197\n",
      "Epoch 43/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - accuracy: 0.8134 - loss: 0.3860 - val_accuracy: 0.7907 - val_loss: 0.4155\n",
      "Epoch 44/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.8145 - loss: 0.3812 - val_accuracy: 0.7867 - val_loss: 0.4114\n",
      "Epoch 45/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - accuracy: 0.8168 - loss: 0.3836 - val_accuracy: 0.7884 - val_loss: 0.4159\n",
      "Epoch 46/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.8105 - loss: 0.3896 - val_accuracy: 0.7872 - val_loss: 0.4156\n",
      "Epoch 47/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.8204 - loss: 0.3840 - val_accuracy: 0.7872 - val_loss: 0.4117\n",
      "Epoch 48/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - accuracy: 0.8194 - loss: 0.3698 - val_accuracy: 0.7901 - val_loss: 0.4142\n",
      "Epoch 49/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8225 - loss: 0.3750 - val_accuracy: 0.7867 - val_loss: 0.4142\n",
      "Epoch 50/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.8188 - loss: 0.3708 - val_accuracy: 0.7855 - val_loss: 0.4129\n",
      "Epoch 1/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7587 - loss: 0.5160 - val_accuracy: 0.7786 - val_loss: 0.4609\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7941 - loss: 0.4499 - val_accuracy: 0.7706 - val_loss: 0.4674\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7978 - loss: 0.4369 - val_accuracy: 0.7844 - val_loss: 0.4436\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7927 - loss: 0.4248 - val_accuracy: 0.7993 - val_loss: 0.4385\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7976 - loss: 0.4203 - val_accuracy: 0.7849 - val_loss: 0.4455\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7895 - loss: 0.4209 - val_accuracy: 0.7878 - val_loss: 0.4446\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7955 - loss: 0.4215 - val_accuracy: 0.7907 - val_loss: 0.4325\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7987 - loss: 0.4150 - val_accuracy: 0.7861 - val_loss: 0.4615\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7964 - loss: 0.4206 - val_accuracy: 0.7821 - val_loss: 0.4250\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8106 - loss: 0.4052 - val_accuracy: 0.7895 - val_loss: 0.4200\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8066 - loss: 0.4041 - val_accuracy: 0.7844 - val_loss: 0.4232\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8078 - loss: 0.3994 - val_accuracy: 0.7907 - val_loss: 0.4245\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8088 - loss: 0.3941 - val_accuracy: 0.7947 - val_loss: 0.4248\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8029 - loss: 0.3958 - val_accuracy: 0.7970 - val_loss: 0.4212\n",
      "Epoch 15/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8185 - loss: 0.3881 - val_accuracy: 0.7913 - val_loss: 0.4209\n",
      "Epoch 16/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8074 - loss: 0.3970 - val_accuracy: 0.7907 - val_loss: 0.4254\n",
      "Epoch 17/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8051 - loss: 0.3982 - val_accuracy: 0.7987 - val_loss: 0.4175\n",
      "Epoch 18/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8122 - loss: 0.3857 - val_accuracy: 0.7924 - val_loss: 0.4306\n",
      "Epoch 19/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8152 - loss: 0.3826 - val_accuracy: 0.7913 - val_loss: 0.4209\n",
      "Epoch 20/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8157 - loss: 0.3796 - val_accuracy: 0.7890 - val_loss: 0.4163\n",
      "Epoch 21/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8149 - loss: 0.3795 - val_accuracy: 0.7884 - val_loss: 0.4170\n",
      "Epoch 22/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8142 - loss: 0.3811 - val_accuracy: 0.7964 - val_loss: 0.4425\n",
      "Epoch 23/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8081 - loss: 0.3882 - val_accuracy: 0.7867 - val_loss: 0.4311\n",
      "Epoch 24/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8149 - loss: 0.3730 - val_accuracy: 0.7867 - val_loss: 0.4218\n",
      "Epoch 25/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8155 - loss: 0.3721 - val_accuracy: 0.7947 - val_loss: 0.4277\n",
      "Epoch 26/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8089 - loss: 0.3769 - val_accuracy: 0.7930 - val_loss: 0.4447\n",
      "Epoch 27/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8195 - loss: 0.3670 - val_accuracy: 0.7913 - val_loss: 0.4315\n",
      "Epoch 28/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8188 - loss: 0.3804 - val_accuracy: 0.7878 - val_loss: 0.4389\n",
      "Epoch 29/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8255 - loss: 0.3640 - val_accuracy: 0.7855 - val_loss: 0.4495\n",
      "Epoch 30/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8034 - loss: 0.3789 - val_accuracy: 0.7947 - val_loss: 0.4380\n",
      "Epoch 1/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 687us/step - accuracy: 0.6315 - loss: 0.6239 - val_accuracy: 0.7729 - val_loss: 0.4687\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.7735 - loss: 0.4841 - val_accuracy: 0.7803 - val_loss: 0.4522\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - accuracy: 0.7834 - loss: 0.4636 - val_accuracy: 0.7849 - val_loss: 0.4478\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - accuracy: 0.8003 - loss: 0.4439 - val_accuracy: 0.7815 - val_loss: 0.4501\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - accuracy: 0.7968 - loss: 0.4359 - val_accuracy: 0.7775 - val_loss: 0.4447\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432us/step - accuracy: 0.7929 - loss: 0.4400 - val_accuracy: 0.7821 - val_loss: 0.4418\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441us/step - accuracy: 0.7933 - loss: 0.4328 - val_accuracy: 0.7867 - val_loss: 0.4337\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429us/step - accuracy: 0.8022 - loss: 0.4251 - val_accuracy: 0.7884 - val_loss: 0.4311\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - accuracy: 0.7915 - loss: 0.4283 - val_accuracy: 0.7861 - val_loss: 0.4344\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - accuracy: 0.7984 - loss: 0.4181 - val_accuracy: 0.7878 - val_loss: 0.4309\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step - accuracy: 0.8029 - loss: 0.4191 - val_accuracy: 0.7832 - val_loss: 0.4288\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - accuracy: 0.8095 - loss: 0.4156 - val_accuracy: 0.7844 - val_loss: 0.4310\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430us/step - accuracy: 0.8022 - loss: 0.4213 - val_accuracy: 0.7872 - val_loss: 0.4276\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433us/step - accuracy: 0.8048 - loss: 0.4173 - val_accuracy: 0.7901 - val_loss: 0.4257\n",
      "Epoch 15/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439us/step - accuracy: 0.8033 - loss: 0.4164 - val_accuracy: 0.7924 - val_loss: 0.4260\n",
      "Epoch 16/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - accuracy: 0.8039 - loss: 0.4165 - val_accuracy: 0.7930 - val_loss: 0.4243\n",
      "Epoch 17/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433us/step - accuracy: 0.8086 - loss: 0.4059 - val_accuracy: 0.7872 - val_loss: 0.4266\n",
      "Epoch 18/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - accuracy: 0.7994 - loss: 0.4057 - val_accuracy: 0.7849 - val_loss: 0.4247\n",
      "Epoch 19/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - accuracy: 0.7940 - loss: 0.4230 - val_accuracy: 0.7867 - val_loss: 0.4233\n",
      "Epoch 20/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - accuracy: 0.7975 - loss: 0.4081 - val_accuracy: 0.7878 - val_loss: 0.4206\n",
      "Epoch 21/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - accuracy: 0.8027 - loss: 0.4192 - val_accuracy: 0.7924 - val_loss: 0.4193\n",
      "Epoch 22/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - accuracy: 0.8078 - loss: 0.4037 - val_accuracy: 0.7855 - val_loss: 0.4210\n",
      "Epoch 23/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605us/step - accuracy: 0.8089 - loss: 0.3982 - val_accuracy: 0.7844 - val_loss: 0.4230\n",
      "Epoch 24/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - accuracy: 0.8132 - loss: 0.3941 - val_accuracy: 0.7832 - val_loss: 0.4195\n",
      "Epoch 25/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431us/step - accuracy: 0.8030 - loss: 0.4101 - val_accuracy: 0.7890 - val_loss: 0.4209\n",
      "Epoch 26/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439us/step - accuracy: 0.8048 - loss: 0.4047 - val_accuracy: 0.7901 - val_loss: 0.4160\n",
      "Epoch 27/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439us/step - accuracy: 0.8103 - loss: 0.3996 - val_accuracy: 0.7867 - val_loss: 0.4181\n",
      "Epoch 28/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - accuracy: 0.7997 - loss: 0.4121 - val_accuracy: 0.7872 - val_loss: 0.4195\n",
      "Epoch 29/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439us/step - accuracy: 0.8065 - loss: 0.4068 - val_accuracy: 0.7890 - val_loss: 0.4166\n",
      "Epoch 30/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.8078 - loss: 0.3989 - val_accuracy: 0.7930 - val_loss: 0.4168\n",
      "Epoch 31/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431us/step - accuracy: 0.8006 - loss: 0.4165 - val_accuracy: 0.7867 - val_loss: 0.4170\n",
      "Epoch 32/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - accuracy: 0.8026 - loss: 0.4051 - val_accuracy: 0.7878 - val_loss: 0.4147\n",
      "Epoch 33/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439us/step - accuracy: 0.8137 - loss: 0.3940 - val_accuracy: 0.7849 - val_loss: 0.4136\n",
      "Epoch 34/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - accuracy: 0.8113 - loss: 0.3987 - val_accuracy: 0.7861 - val_loss: 0.4133\n",
      "Epoch 35/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - accuracy: 0.8071 - loss: 0.3969 - val_accuracy: 0.7844 - val_loss: 0.4130\n",
      "Epoch 36/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - accuracy: 0.8078 - loss: 0.4042 - val_accuracy: 0.7913 - val_loss: 0.4134\n",
      "Epoch 37/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - accuracy: 0.8080 - loss: 0.3998 - val_accuracy: 0.7901 - val_loss: 0.4141\n",
      "Epoch 38/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430us/step - accuracy: 0.8136 - loss: 0.3935 - val_accuracy: 0.7907 - val_loss: 0.4121\n",
      "Epoch 39/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - accuracy: 0.8182 - loss: 0.3910 - val_accuracy: 0.7821 - val_loss: 0.4144\n",
      "Epoch 40/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - accuracy: 0.8098 - loss: 0.3913 - val_accuracy: 0.7890 - val_loss: 0.4115\n",
      "Epoch 41/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436us/step - accuracy: 0.8135 - loss: 0.3906 - val_accuracy: 0.7907 - val_loss: 0.4116\n",
      "Epoch 42/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - accuracy: 0.8110 - loss: 0.3982 - val_accuracy: 0.7936 - val_loss: 0.4115\n",
      "Epoch 43/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441us/step - accuracy: 0.8101 - loss: 0.3909 - val_accuracy: 0.7907 - val_loss: 0.4122\n",
      "Epoch 44/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429us/step - accuracy: 0.8135 - loss: 0.3959 - val_accuracy: 0.7924 - val_loss: 0.4092\n",
      "Epoch 45/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439us/step - accuracy: 0.8204 - loss: 0.3827 - val_accuracy: 0.7890 - val_loss: 0.4116\n",
      "Epoch 46/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436us/step - accuracy: 0.8081 - loss: 0.3959 - val_accuracy: 0.7964 - val_loss: 0.4078\n",
      "Epoch 47/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430us/step - accuracy: 0.8081 - loss: 0.3913 - val_accuracy: 0.7930 - val_loss: 0.4124\n",
      "Epoch 48/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670us/step - accuracy: 0.8103 - loss: 0.3922 - val_accuracy: 0.7924 - val_loss: 0.4089\n",
      "Epoch 49/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436us/step - accuracy: 0.8096 - loss: 0.3941 - val_accuracy: 0.7884 - val_loss: 0.4091\n",
      "Epoch 50/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429us/step - accuracy: 0.8083 - loss: 0.3987 - val_accuracy: 0.7970 - val_loss: 0.4111\n",
      "Epoch 1/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7379 - loss: 0.5042 - val_accuracy: 0.7826 - val_loss: 0.4436\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7831 - loss: 0.4390 - val_accuracy: 0.7855 - val_loss: 0.4396\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7978 - loss: 0.4154 - val_accuracy: 0.7700 - val_loss: 0.4464\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8094 - loss: 0.4141 - val_accuracy: 0.7821 - val_loss: 0.4278\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8082 - loss: 0.3937 - val_accuracy: 0.7844 - val_loss: 0.4343\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8025 - loss: 0.4142 - val_accuracy: 0.7907 - val_loss: 0.4247\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8062 - loss: 0.4005 - val_accuracy: 0.7895 - val_loss: 0.4257\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8150 - loss: 0.3893 - val_accuracy: 0.7947 - val_loss: 0.4178\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8115 - loss: 0.3963 - val_accuracy: 0.7838 - val_loss: 0.4271\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8070 - loss: 0.3951 - val_accuracy: 0.7861 - val_loss: 0.4236\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8115 - loss: 0.3952 - val_accuracy: 0.7947 - val_loss: 0.4194\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8084 - loss: 0.3930 - val_accuracy: 0.7826 - val_loss: 0.4401\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8074 - loss: 0.3942 - val_accuracy: 0.7890 - val_loss: 0.4256\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8015 - loss: 0.3972 - val_accuracy: 0.7924 - val_loss: 0.4178\n",
      "Epoch 15/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8085 - loss: 0.3829 - val_accuracy: 0.7878 - val_loss: 0.4166\n",
      "Epoch 16/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8186 - loss: 0.3805 - val_accuracy: 0.7890 - val_loss: 0.4232\n",
      "Epoch 17/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8236 - loss: 0.3672 - val_accuracy: 0.7930 - val_loss: 0.4183\n",
      "Epoch 18/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8193 - loss: 0.3764 - val_accuracy: 0.7947 - val_loss: 0.4225\n",
      "Epoch 19/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8194 - loss: 0.3683 - val_accuracy: 0.7861 - val_loss: 0.4266\n",
      "Epoch 20/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8193 - loss: 0.3748 - val_accuracy: 0.7964 - val_loss: 0.4235\n",
      "Epoch 21/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8202 - loss: 0.3763 - val_accuracy: 0.7855 - val_loss: 0.4296\n",
      "Epoch 22/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8288 - loss: 0.3579 - val_accuracy: 0.7987 - val_loss: 0.4332\n",
      "Epoch 23/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8275 - loss: 0.3575 - val_accuracy: 0.7895 - val_loss: 0.4278\n",
      "Epoch 24/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8306 - loss: 0.3550 - val_accuracy: 0.7878 - val_loss: 0.4180\n",
      "Epoch 25/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8242 - loss: 0.3588 - val_accuracy: 0.8016 - val_loss: 0.4323\n",
      "Epoch 1/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7490 - loss: 0.5052 - val_accuracy: 0.7671 - val_loss: 0.4531\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7944 - loss: 0.4296 - val_accuracy: 0.7861 - val_loss: 0.4445\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8009 - loss: 0.4239 - val_accuracy: 0.7832 - val_loss: 0.4355\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8001 - loss: 0.4138 - val_accuracy: 0.7826 - val_loss: 0.4431\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8002 - loss: 0.4099 - val_accuracy: 0.7855 - val_loss: 0.4360\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8115 - loss: 0.4041 - val_accuracy: 0.7867 - val_loss: 0.4317\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8105 - loss: 0.3925 - val_accuracy: 0.7855 - val_loss: 0.4244\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7985 - loss: 0.4101 - val_accuracy: 0.7769 - val_loss: 0.4516\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8106 - loss: 0.4042 - val_accuracy: 0.7867 - val_loss: 0.4255\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8048 - loss: 0.3944 - val_accuracy: 0.7821 - val_loss: 0.4248\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8003 - loss: 0.4047 - val_accuracy: 0.7861 - val_loss: 0.4179\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8163 - loss: 0.3846 - val_accuracy: 0.7815 - val_loss: 0.4249\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8155 - loss: 0.3880 - val_accuracy: 0.7844 - val_loss: 0.4242\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8088 - loss: 0.3858 - val_accuracy: 0.7924 - val_loss: 0.4142\n",
      "Epoch 15/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8167 - loss: 0.3835 - val_accuracy: 0.7855 - val_loss: 0.4193\n",
      "Epoch 16/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8100 - loss: 0.3882 - val_accuracy: 0.7901 - val_loss: 0.4187\n",
      "Epoch 17/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8140 - loss: 0.3882 - val_accuracy: 0.7821 - val_loss: 0.4229\n",
      "Epoch 18/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8134 - loss: 0.3847 - val_accuracy: 0.7918 - val_loss: 0.4159\n",
      "Epoch 19/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8208 - loss: 0.3667 - val_accuracy: 0.7918 - val_loss: 0.4163\n",
      "Epoch 20/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8158 - loss: 0.3783 - val_accuracy: 0.7821 - val_loss: 0.4171\n",
      "Epoch 21/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8184 - loss: 0.3740 - val_accuracy: 0.7884 - val_loss: 0.4225\n",
      "Epoch 22/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8153 - loss: 0.3807 - val_accuracy: 0.7964 - val_loss: 0.4181\n",
      "Epoch 23/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8275 - loss: 0.3716 - val_accuracy: 0.7844 - val_loss: 0.4147\n",
      "Epoch 24/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8253 - loss: 0.3605 - val_accuracy: 0.7844 - val_loss: 0.4366\n",
      "Epoch 1/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7530 - loss: 0.5056 - val_accuracy: 0.7832 - val_loss: 0.4553\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8051 - loss: 0.4196 - val_accuracy: 0.7815 - val_loss: 0.4437\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7987 - loss: 0.4134 - val_accuracy: 0.7861 - val_loss: 0.4303\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7993 - loss: 0.4128 - val_accuracy: 0.7769 - val_loss: 0.4343\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8045 - loss: 0.4059 - val_accuracy: 0.7878 - val_loss: 0.4309\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8039 - loss: 0.4002 - val_accuracy: 0.7798 - val_loss: 0.4430\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8116 - loss: 0.3937 - val_accuracy: 0.7872 - val_loss: 0.4246\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8161 - loss: 0.3871 - val_accuracy: 0.7861 - val_loss: 0.4397\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8123 - loss: 0.3909 - val_accuracy: 0.7861 - val_loss: 0.4310\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8175 - loss: 0.3830 - val_accuracy: 0.7867 - val_loss: 0.4198\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8121 - loss: 0.3850 - val_accuracy: 0.7809 - val_loss: 0.4305\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8196 - loss: 0.3754 - val_accuracy: 0.7913 - val_loss: 0.4225\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8251 - loss: 0.3706 - val_accuracy: 0.7838 - val_loss: 0.4336\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8238 - loss: 0.3673 - val_accuracy: 0.7987 - val_loss: 0.4248\n",
      "Epoch 15/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8198 - loss: 0.3687 - val_accuracy: 0.7780 - val_loss: 0.4425\n",
      "Epoch 16/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8288 - loss: 0.3565 - val_accuracy: 0.7855 - val_loss: 0.4251\n",
      "Epoch 17/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8267 - loss: 0.3602 - val_accuracy: 0.7901 - val_loss: 0.4285\n",
      "Epoch 18/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8323 - loss: 0.3600 - val_accuracy: 0.7872 - val_loss: 0.4206\n",
      "Epoch 19/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8260 - loss: 0.3560 - val_accuracy: 0.7901 - val_loss: 0.4402\n",
      "Epoch 20/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8302 - loss: 0.3509 - val_accuracy: 0.7890 - val_loss: 0.4254\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rahulnundlall/anaconda3/envs/ML/lib/python3.12/site-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657us/step - accuracy: 0.6116 - loss: 0.6551 - val_accuracy: 0.7556 - val_loss: 0.5238\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.7415 - loss: 0.5324 - val_accuracy: 0.7665 - val_loss: 0.4774\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - accuracy: 0.7674 - loss: 0.4920 - val_accuracy: 0.7729 - val_loss: 0.4641\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - accuracy: 0.7806 - loss: 0.4744 - val_accuracy: 0.7740 - val_loss: 0.4592\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - accuracy: 0.7732 - loss: 0.4679 - val_accuracy: 0.7786 - val_loss: 0.4569\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - accuracy: 0.7893 - loss: 0.4508 - val_accuracy: 0.7803 - val_loss: 0.4541\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - accuracy: 0.7816 - loss: 0.4648 - val_accuracy: 0.7798 - val_loss: 0.4494\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - accuracy: 0.7940 - loss: 0.4409 - val_accuracy: 0.7832 - val_loss: 0.4478\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - accuracy: 0.8010 - loss: 0.4375 - val_accuracy: 0.7821 - val_loss: 0.4469\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - accuracy: 0.7921 - loss: 0.4473 - val_accuracy: 0.7838 - val_loss: 0.4469\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.7912 - loss: 0.4387 - val_accuracy: 0.7838 - val_loss: 0.4434\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - accuracy: 0.7892 - loss: 0.4419 - val_accuracy: 0.7838 - val_loss: 0.4435\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - accuracy: 0.7960 - loss: 0.4414 - val_accuracy: 0.7821 - val_loss: 0.4438\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.7939 - loss: 0.4392 - val_accuracy: 0.7849 - val_loss: 0.4415\n",
      "Epoch 15/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - accuracy: 0.7913 - loss: 0.4421 - val_accuracy: 0.7849 - val_loss: 0.4417\n",
      "Epoch 16/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.7915 - loss: 0.4383 - val_accuracy: 0.7884 - val_loss: 0.4388\n",
      "Epoch 17/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.7918 - loss: 0.4372 - val_accuracy: 0.7907 - val_loss: 0.4385\n",
      "Epoch 18/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - accuracy: 0.7995 - loss: 0.4227 - val_accuracy: 0.7867 - val_loss: 0.4356\n",
      "Epoch 19/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.7822 - loss: 0.4363 - val_accuracy: 0.7913 - val_loss: 0.4358\n",
      "Epoch 20/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - accuracy: 0.8001 - loss: 0.4264 - val_accuracy: 0.7930 - val_loss: 0.4351\n",
      "Epoch 21/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - accuracy: 0.8083 - loss: 0.4177 - val_accuracy: 0.7884 - val_loss: 0.4350\n",
      "Epoch 22/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - accuracy: 0.8002 - loss: 0.4202 - val_accuracy: 0.7907 - val_loss: 0.4330\n",
      "Epoch 23/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - accuracy: 0.8052 - loss: 0.4169 - val_accuracy: 0.7913 - val_loss: 0.4334\n",
      "Epoch 24/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - accuracy: 0.8046 - loss: 0.4205 - val_accuracy: 0.7878 - val_loss: 0.4324\n",
      "Epoch 25/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - accuracy: 0.8102 - loss: 0.4238 - val_accuracy: 0.7901 - val_loss: 0.4315\n",
      "Epoch 26/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - accuracy: 0.7914 - loss: 0.4365 - val_accuracy: 0.7901 - val_loss: 0.4318\n",
      "Epoch 27/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.8067 - loss: 0.4177 - val_accuracy: 0.7884 - val_loss: 0.4321\n",
      "Epoch 28/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - accuracy: 0.8038 - loss: 0.4210 - val_accuracy: 0.7844 - val_loss: 0.4298\n",
      "Epoch 29/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.8015 - loss: 0.4216 - val_accuracy: 0.7872 - val_loss: 0.4278\n",
      "Epoch 30/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - accuracy: 0.7995 - loss: 0.4211 - val_accuracy: 0.7855 - val_loss: 0.4285\n",
      "Epoch 31/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.8056 - loss: 0.4144 - val_accuracy: 0.7861 - val_loss: 0.4287\n",
      "Epoch 32/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - accuracy: 0.8048 - loss: 0.4197 - val_accuracy: 0.7849 - val_loss: 0.4273\n",
      "Epoch 33/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.7989 - loss: 0.4183 - val_accuracy: 0.7895 - val_loss: 0.4285\n",
      "Epoch 34/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - accuracy: 0.8087 - loss: 0.4132 - val_accuracy: 0.7855 - val_loss: 0.4274\n",
      "Epoch 35/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - accuracy: 0.7988 - loss: 0.4136 - val_accuracy: 0.7867 - val_loss: 0.4272\n",
      "Epoch 36/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.8055 - loss: 0.4106 - val_accuracy: 0.7901 - val_loss: 0.4251\n",
      "Epoch 37/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - accuracy: 0.8034 - loss: 0.4115 - val_accuracy: 0.7907 - val_loss: 0.4255\n",
      "Epoch 38/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - accuracy: 0.8122 - loss: 0.4043 - val_accuracy: 0.7907 - val_loss: 0.4250\n",
      "Epoch 39/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.8035 - loss: 0.4087 - val_accuracy: 0.7878 - val_loss: 0.4246\n",
      "Epoch 40/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - accuracy: 0.8034 - loss: 0.4132 - val_accuracy: 0.7884 - val_loss: 0.4250\n",
      "Epoch 41/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.8086 - loss: 0.4157 - val_accuracy: 0.7867 - val_loss: 0.4250\n",
      "Epoch 42/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - accuracy: 0.7990 - loss: 0.4123 - val_accuracy: 0.7901 - val_loss: 0.4245\n",
      "Epoch 43/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - accuracy: 0.8040 - loss: 0.4109 - val_accuracy: 0.7855 - val_loss: 0.4247\n",
      "Epoch 44/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418us/step - accuracy: 0.8129 - loss: 0.4058 - val_accuracy: 0.7901 - val_loss: 0.4225\n",
      "Epoch 45/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417us/step - accuracy: 0.8053 - loss: 0.4121 - val_accuracy: 0.7890 - val_loss: 0.4233\n",
      "Epoch 46/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - accuracy: 0.8123 - loss: 0.4049 - val_accuracy: 0.7901 - val_loss: 0.4208\n",
      "Epoch 47/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.8111 - loss: 0.4023 - val_accuracy: 0.7890 - val_loss: 0.4214\n",
      "Epoch 48/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - accuracy: 0.8202 - loss: 0.3939 - val_accuracy: 0.7872 - val_loss: 0.4207\n",
      "Epoch 49/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - accuracy: 0.8030 - loss: 0.4033 - val_accuracy: 0.7930 - val_loss: 0.4225\n",
      "Epoch 50/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.8007 - loss: 0.4084 - val_accuracy: 0.7918 - val_loss: 0.4219\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rahulnundlall/anaconda3/envs/ML/lib/python3.12/site-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 833us/step - accuracy: 0.6132 - loss: 0.6493 - val_accuracy: 0.7694 - val_loss: 0.4899\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - accuracy: 0.7594 - loss: 0.5065 - val_accuracy: 0.7752 - val_loss: 0.4631\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.7757 - loss: 0.4768 - val_accuracy: 0.7803 - val_loss: 0.4602\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - accuracy: 0.7834 - loss: 0.4631 - val_accuracy: 0.7821 - val_loss: 0.4523\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - accuracy: 0.7830 - loss: 0.4567 - val_accuracy: 0.7763 - val_loss: 0.4510\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718us/step - accuracy: 0.7859 - loss: 0.4527 - val_accuracy: 0.7832 - val_loss: 0.4488\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - accuracy: 0.7884 - loss: 0.4518 - val_accuracy: 0.7780 - val_loss: 0.4484\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435us/step - accuracy: 0.7955 - loss: 0.4412 - val_accuracy: 0.7838 - val_loss: 0.4442\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430us/step - accuracy: 0.7835 - loss: 0.4564 - val_accuracy: 0.7821 - val_loss: 0.4434\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.7942 - loss: 0.4456 - val_accuracy: 0.7872 - val_loss: 0.4415\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428us/step - accuracy: 0.7917 - loss: 0.4417 - val_accuracy: 0.7809 - val_loss: 0.4394\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8003 - loss: 0.4342 - val_accuracy: 0.7832 - val_loss: 0.4390\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430us/step - accuracy: 0.7871 - loss: 0.4408 - val_accuracy: 0.7815 - val_loss: 0.4387\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.7996 - loss: 0.4301 - val_accuracy: 0.7844 - val_loss: 0.4359\n",
      "Epoch 15/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - accuracy: 0.7924 - loss: 0.4274 - val_accuracy: 0.7786 - val_loss: 0.4349\n",
      "Epoch 16/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.7991 - loss: 0.4269 - val_accuracy: 0.7792 - val_loss: 0.4341\n",
      "Epoch 17/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - accuracy: 0.7962 - loss: 0.4291 - val_accuracy: 0.7855 - val_loss: 0.4333\n",
      "Epoch 18/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.8013 - loss: 0.4286 - val_accuracy: 0.7861 - val_loss: 0.4320\n",
      "Epoch 19/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.7988 - loss: 0.4169 - val_accuracy: 0.7872 - val_loss: 0.4317\n",
      "Epoch 20/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - accuracy: 0.8009 - loss: 0.4164 - val_accuracy: 0.7838 - val_loss: 0.4301\n",
      "Epoch 21/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - accuracy: 0.7972 - loss: 0.4240 - val_accuracy: 0.7849 - val_loss: 0.4316\n",
      "Epoch 22/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.8041 - loss: 0.4221 - val_accuracy: 0.7844 - val_loss: 0.4294\n",
      "Epoch 23/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.8054 - loss: 0.4187 - val_accuracy: 0.7775 - val_loss: 0.4293\n",
      "Epoch 24/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - accuracy: 0.7870 - loss: 0.4259 - val_accuracy: 0.7803 - val_loss: 0.4304\n",
      "Epoch 25/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.8075 - loss: 0.4103 - val_accuracy: 0.7844 - val_loss: 0.4284\n",
      "Epoch 26/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430us/step - accuracy: 0.7989 - loss: 0.4244 - val_accuracy: 0.7855 - val_loss: 0.4273\n",
      "Epoch 27/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - accuracy: 0.7964 - loss: 0.4203 - val_accuracy: 0.7780 - val_loss: 0.4293\n",
      "Epoch 28/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - accuracy: 0.7997 - loss: 0.4181 - val_accuracy: 0.7872 - val_loss: 0.4271\n",
      "Epoch 29/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - accuracy: 0.8035 - loss: 0.4102 - val_accuracy: 0.7803 - val_loss: 0.4293\n",
      "Epoch 30/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.8182 - loss: 0.4062 - val_accuracy: 0.7832 - val_loss: 0.4251\n",
      "Epoch 31/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.8108 - loss: 0.4030 - val_accuracy: 0.7855 - val_loss: 0.4256\n",
      "Epoch 32/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - accuracy: 0.8037 - loss: 0.4195 - val_accuracy: 0.7844 - val_loss: 0.4256\n",
      "Epoch 33/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - accuracy: 0.8107 - loss: 0.4029 - val_accuracy: 0.7838 - val_loss: 0.4256\n",
      "Epoch 34/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - accuracy: 0.8108 - loss: 0.4031 - val_accuracy: 0.7826 - val_loss: 0.4263\n",
      "Epoch 35/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - accuracy: 0.8031 - loss: 0.4138 - val_accuracy: 0.7867 - val_loss: 0.4242\n",
      "Epoch 36/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - accuracy: 0.8086 - loss: 0.4134 - val_accuracy: 0.7844 - val_loss: 0.4239\n",
      "Epoch 37/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.8047 - loss: 0.4076 - val_accuracy: 0.7895 - val_loss: 0.4240\n",
      "Epoch 38/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417us/step - accuracy: 0.8108 - loss: 0.4038 - val_accuracy: 0.7878 - val_loss: 0.4235\n",
      "Epoch 39/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.8039 - loss: 0.4061 - val_accuracy: 0.7901 - val_loss: 0.4245\n",
      "Epoch 40/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431us/step - accuracy: 0.8071 - loss: 0.4123 - val_accuracy: 0.7867 - val_loss: 0.4231\n",
      "Epoch 41/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.7980 - loss: 0.4119 - val_accuracy: 0.7861 - val_loss: 0.4226\n",
      "Epoch 42/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - accuracy: 0.8070 - loss: 0.4088 - val_accuracy: 0.7826 - val_loss: 0.4236\n",
      "Epoch 43/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.8060 - loss: 0.4089 - val_accuracy: 0.7867 - val_loss: 0.4235\n",
      "Epoch 44/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - accuracy: 0.7942 - loss: 0.4169 - val_accuracy: 0.7895 - val_loss: 0.4225\n",
      "Epoch 45/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - accuracy: 0.8112 - loss: 0.3993 - val_accuracy: 0.7878 - val_loss: 0.4230\n",
      "Epoch 46/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - accuracy: 0.7980 - loss: 0.4138 - val_accuracy: 0.7884 - val_loss: 0.4202\n",
      "Epoch 47/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - accuracy: 0.8035 - loss: 0.4075 - val_accuracy: 0.7872 - val_loss: 0.4218\n",
      "Epoch 48/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.8153 - loss: 0.3951 - val_accuracy: 0.7855 - val_loss: 0.4246\n",
      "Epoch 49/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - accuracy: 0.8063 - loss: 0.4009 - val_accuracy: 0.7878 - val_loss: 0.4211\n",
      "Epoch 50/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - accuracy: 0.8096 - loss: 0.4074 - val_accuracy: 0.7844 - val_loss: 0.4203\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rahulnundlall/anaconda3/envs/ML/lib/python3.12/site-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - accuracy: 0.5753 - loss: 0.6701 - val_accuracy: 0.7619 - val_loss: 0.5193\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - accuracy: 0.7389 - loss: 0.5369 - val_accuracy: 0.7734 - val_loss: 0.4710\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.7564 - loss: 0.5008 - val_accuracy: 0.7826 - val_loss: 0.4619\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.7808 - loss: 0.4724 - val_accuracy: 0.7803 - val_loss: 0.4550\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423us/step - accuracy: 0.7755 - loss: 0.4703 - val_accuracy: 0.7803 - val_loss: 0.4546\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428us/step - accuracy: 0.7851 - loss: 0.4681 - val_accuracy: 0.7844 - val_loss: 0.4477\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427us/step - accuracy: 0.7856 - loss: 0.4528 - val_accuracy: 0.7838 - val_loss: 0.4453\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - accuracy: 0.8006 - loss: 0.4519 - val_accuracy: 0.7844 - val_loss: 0.4421\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - accuracy: 0.7867 - loss: 0.4444 - val_accuracy: 0.7844 - val_loss: 0.4414\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418us/step - accuracy: 0.7933 - loss: 0.4448 - val_accuracy: 0.7821 - val_loss: 0.4401\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423us/step - accuracy: 0.7975 - loss: 0.4383 - val_accuracy: 0.7809 - val_loss: 0.4411\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426us/step - accuracy: 0.7984 - loss: 0.4409 - val_accuracy: 0.7838 - val_loss: 0.4375\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423us/step - accuracy: 0.8108 - loss: 0.4223 - val_accuracy: 0.7798 - val_loss: 0.4387\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415us/step - accuracy: 0.7980 - loss: 0.4333 - val_accuracy: 0.7872 - val_loss: 0.4349\n",
      "Epoch 15/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419us/step - accuracy: 0.8018 - loss: 0.4315 - val_accuracy: 0.7867 - val_loss: 0.4329\n",
      "Epoch 16/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427us/step - accuracy: 0.8037 - loss: 0.4184 - val_accuracy: 0.7872 - val_loss: 0.4351\n",
      "Epoch 17/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.8013 - loss: 0.4301 - val_accuracy: 0.7872 - val_loss: 0.4331\n",
      "Epoch 18/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - accuracy: 0.8020 - loss: 0.4257 - val_accuracy: 0.7838 - val_loss: 0.4310\n",
      "Epoch 19/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.8030 - loss: 0.4211 - val_accuracy: 0.7821 - val_loss: 0.4310\n",
      "Epoch 20/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - accuracy: 0.7993 - loss: 0.4180 - val_accuracy: 0.7867 - val_loss: 0.4283\n",
      "Epoch 21/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - accuracy: 0.8176 - loss: 0.4036 - val_accuracy: 0.7884 - val_loss: 0.4281\n",
      "Epoch 22/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.8027 - loss: 0.4194 - val_accuracy: 0.7918 - val_loss: 0.4264\n",
      "Epoch 23/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - accuracy: 0.8029 - loss: 0.4146 - val_accuracy: 0.7855 - val_loss: 0.4262\n",
      "Epoch 24/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - accuracy: 0.8022 - loss: 0.4216 - val_accuracy: 0.7930 - val_loss: 0.4256\n",
      "Epoch 25/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.8073 - loss: 0.4136 - val_accuracy: 0.7844 - val_loss: 0.4269\n",
      "Epoch 26/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - accuracy: 0.7956 - loss: 0.4280 - val_accuracy: 0.7849 - val_loss: 0.4295\n",
      "Epoch 27/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.8063 - loss: 0.4149 - val_accuracy: 0.7872 - val_loss: 0.4276\n",
      "Epoch 28/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.7983 - loss: 0.4231 - val_accuracy: 0.7918 - val_loss: 0.4282\n",
      "Epoch 29/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.8007 - loss: 0.4181 - val_accuracy: 0.7913 - val_loss: 0.4268\n",
      "Epoch 30/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.8052 - loss: 0.4100 - val_accuracy: 0.7913 - val_loss: 0.4245\n",
      "Epoch 31/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - accuracy: 0.8026 - loss: 0.4128 - val_accuracy: 0.7890 - val_loss: 0.4251\n",
      "Epoch 32/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376us/step - accuracy: 0.8041 - loss: 0.4145 - val_accuracy: 0.7895 - val_loss: 0.4237\n",
      "Epoch 33/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.8108 - loss: 0.4139 - val_accuracy: 0.7832 - val_loss: 0.4239\n",
      "Epoch 34/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.8129 - loss: 0.4073 - val_accuracy: 0.7895 - val_loss: 0.4239\n",
      "Epoch 35/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.8086 - loss: 0.4075 - val_accuracy: 0.7890 - val_loss: 0.4237\n",
      "Epoch 36/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373us/step - accuracy: 0.8012 - loss: 0.4170 - val_accuracy: 0.7884 - val_loss: 0.4236\n",
      "Epoch 37/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.8060 - loss: 0.4222 - val_accuracy: 0.7907 - val_loss: 0.4230\n",
      "Epoch 38/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - accuracy: 0.8196 - loss: 0.4045 - val_accuracy: 0.7884 - val_loss: 0.4208\n",
      "Epoch 39/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.8025 - loss: 0.4055 - val_accuracy: 0.7867 - val_loss: 0.4227\n",
      "Epoch 40/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.8115 - loss: 0.4112 - val_accuracy: 0.7867 - val_loss: 0.4214\n",
      "Epoch 41/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374us/step - accuracy: 0.8100 - loss: 0.4096 - val_accuracy: 0.7855 - val_loss: 0.4219\n",
      "Epoch 42/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.8034 - loss: 0.4052 - val_accuracy: 0.7855 - val_loss: 0.4199\n",
      "Epoch 43/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376us/step - accuracy: 0.8051 - loss: 0.4142 - val_accuracy: 0.7913 - val_loss: 0.4216\n",
      "Epoch 44/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374us/step - accuracy: 0.8056 - loss: 0.4113 - val_accuracy: 0.7838 - val_loss: 0.4222\n",
      "Epoch 45/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374us/step - accuracy: 0.8128 - loss: 0.4023 - val_accuracy: 0.7884 - val_loss: 0.4218\n",
      "Epoch 46/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376us/step - accuracy: 0.8094 - loss: 0.4099 - val_accuracy: 0.7849 - val_loss: 0.4227\n",
      "Epoch 47/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375us/step - accuracy: 0.8044 - loss: 0.4207 - val_accuracy: 0.7872 - val_loss: 0.4231\n",
      "Epoch 48/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376us/step - accuracy: 0.8072 - loss: 0.4107 - val_accuracy: 0.7855 - val_loss: 0.4229\n",
      "Epoch 49/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375us/step - accuracy: 0.8106 - loss: 0.4068 - val_accuracy: 0.7913 - val_loss: 0.4207\n",
      "Epoch 50/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376us/step - accuracy: 0.7958 - loss: 0.4239 - val_accuracy: 0.7895 - val_loss: 0.4206\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rahulnundlall/anaconda3/envs/ML/lib/python3.12/site-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 715us/step - accuracy: 0.6845 - loss: 0.5707 - val_accuracy: 0.7838 - val_loss: 0.4556\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - accuracy: 0.7883 - loss: 0.4560 - val_accuracy: 0.7654 - val_loss: 0.4612\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - accuracy: 0.7924 - loss: 0.4394 - val_accuracy: 0.7757 - val_loss: 0.4459\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - accuracy: 0.7931 - loss: 0.4389 - val_accuracy: 0.7780 - val_loss: 0.4380\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.7995 - loss: 0.4288 - val_accuracy: 0.7861 - val_loss: 0.4340\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.7900 - loss: 0.4210 - val_accuracy: 0.7821 - val_loss: 0.4333\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.7999 - loss: 0.4248 - val_accuracy: 0.7809 - val_loss: 0.4316\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.8050 - loss: 0.4181 - val_accuracy: 0.7987 - val_loss: 0.4301\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - accuracy: 0.7970 - loss: 0.4182 - val_accuracy: 0.7832 - val_loss: 0.4295\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.7982 - loss: 0.4190 - val_accuracy: 0.7844 - val_loss: 0.4286\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.8061 - loss: 0.4142 - val_accuracy: 0.7826 - val_loss: 0.4349\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.8045 - loss: 0.4060 - val_accuracy: 0.7826 - val_loss: 0.4224\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.8077 - loss: 0.3982 - val_accuracy: 0.7844 - val_loss: 0.4249\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.8109 - loss: 0.3979 - val_accuracy: 0.7872 - val_loss: 0.4212\n",
      "Epoch 15/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - accuracy: 0.8054 - loss: 0.4064 - val_accuracy: 0.7809 - val_loss: 0.4216\n",
      "Epoch 16/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.8118 - loss: 0.3955 - val_accuracy: 0.7826 - val_loss: 0.4202\n",
      "Epoch 17/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.8008 - loss: 0.4052 - val_accuracy: 0.7844 - val_loss: 0.4187\n",
      "Epoch 18/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.8090 - loss: 0.4041 - val_accuracy: 0.7878 - val_loss: 0.4189\n",
      "Epoch 19/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.8104 - loss: 0.3991 - val_accuracy: 0.7832 - val_loss: 0.4216\n",
      "Epoch 20/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step - accuracy: 0.8022 - loss: 0.4072 - val_accuracy: 0.7798 - val_loss: 0.4224\n",
      "Epoch 21/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - accuracy: 0.8180 - loss: 0.3857 - val_accuracy: 0.7867 - val_loss: 0.4222\n",
      "Epoch 22/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.8133 - loss: 0.4029 - val_accuracy: 0.7855 - val_loss: 0.4183\n",
      "Epoch 23/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.8071 - loss: 0.3972 - val_accuracy: 0.7815 - val_loss: 0.4176\n",
      "Epoch 24/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.8139 - loss: 0.3844 - val_accuracy: 0.7878 - val_loss: 0.4157\n",
      "Epoch 25/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - accuracy: 0.8219 - loss: 0.3870 - val_accuracy: 0.7855 - val_loss: 0.4141\n",
      "Epoch 26/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.8187 - loss: 0.3911 - val_accuracy: 0.7844 - val_loss: 0.4173\n",
      "Epoch 27/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.8045 - loss: 0.3916 - val_accuracy: 0.7913 - val_loss: 0.4143\n",
      "Epoch 28/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.8195 - loss: 0.3873 - val_accuracy: 0.7821 - val_loss: 0.4115\n",
      "Epoch 29/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - accuracy: 0.8123 - loss: 0.3876 - val_accuracy: 0.7867 - val_loss: 0.4164\n",
      "Epoch 30/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - accuracy: 0.8187 - loss: 0.3801 - val_accuracy: 0.7855 - val_loss: 0.4141\n",
      "Epoch 31/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - accuracy: 0.8184 - loss: 0.3788 - val_accuracy: 0.7838 - val_loss: 0.4173\n",
      "Epoch 32/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - accuracy: 0.8208 - loss: 0.3828 - val_accuracy: 0.7855 - val_loss: 0.4115\n",
      "Epoch 33/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - accuracy: 0.8125 - loss: 0.3862 - val_accuracy: 0.7867 - val_loss: 0.4137\n",
      "Epoch 34/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - accuracy: 0.8121 - loss: 0.3863 - val_accuracy: 0.7844 - val_loss: 0.4144\n",
      "Epoch 35/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473us/step - accuracy: 0.8156 - loss: 0.3813 - val_accuracy: 0.7849 - val_loss: 0.4142\n",
      "Epoch 36/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - accuracy: 0.8027 - loss: 0.3875 - val_accuracy: 0.7821 - val_loss: 0.4122\n",
      "Epoch 37/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - accuracy: 0.8308 - loss: 0.3748 - val_accuracy: 0.7844 - val_loss: 0.4116\n",
      "Epoch 38/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - accuracy: 0.8152 - loss: 0.3862 - val_accuracy: 0.7861 - val_loss: 0.4157\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rahulnundlall/anaconda3/envs/ML/lib/python3.12/site-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 684us/step - accuracy: 0.6969 - loss: 0.5763 - val_accuracy: 0.7688 - val_loss: 0.4778\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428us/step - accuracy: 0.7822 - loss: 0.4614 - val_accuracy: 0.7763 - val_loss: 0.4579\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418us/step - accuracy: 0.7864 - loss: 0.4566 - val_accuracy: 0.7757 - val_loss: 0.4544\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414us/step - accuracy: 0.7909 - loss: 0.4369 - val_accuracy: 0.7901 - val_loss: 0.4425\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - accuracy: 0.7973 - loss: 0.4329 - val_accuracy: 0.7815 - val_loss: 0.4431\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - accuracy: 0.7936 - loss: 0.4288 - val_accuracy: 0.7838 - val_loss: 0.4402\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418us/step - accuracy: 0.8075 - loss: 0.4155 - val_accuracy: 0.7867 - val_loss: 0.4340\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414us/step - accuracy: 0.7944 - loss: 0.4283 - val_accuracy: 0.7861 - val_loss: 0.4374\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423us/step - accuracy: 0.8006 - loss: 0.4276 - val_accuracy: 0.7895 - val_loss: 0.4350\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416us/step - accuracy: 0.8100 - loss: 0.4122 - val_accuracy: 0.7872 - val_loss: 0.4350\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - accuracy: 0.8040 - loss: 0.4170 - val_accuracy: 0.7890 - val_loss: 0.4333\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - accuracy: 0.8080 - loss: 0.4051 - val_accuracy: 0.7832 - val_loss: 0.4321\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419us/step - accuracy: 0.8087 - loss: 0.4113 - val_accuracy: 0.7878 - val_loss: 0.4351\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423us/step - accuracy: 0.7927 - loss: 0.4275 - val_accuracy: 0.7884 - val_loss: 0.4256\n",
      "Epoch 15/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418us/step - accuracy: 0.8116 - loss: 0.4066 - val_accuracy: 0.7872 - val_loss: 0.4295\n",
      "Epoch 16/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418us/step - accuracy: 0.8060 - loss: 0.4120 - val_accuracy: 0.7884 - val_loss: 0.4238\n",
      "Epoch 17/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - accuracy: 0.8176 - loss: 0.3997 - val_accuracy: 0.7844 - val_loss: 0.4262\n",
      "Epoch 18/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step - accuracy: 0.8037 - loss: 0.4112 - val_accuracy: 0.7878 - val_loss: 0.4219\n",
      "Epoch 19/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - accuracy: 0.8126 - loss: 0.3956 - val_accuracy: 0.7849 - val_loss: 0.4241\n",
      "Epoch 20/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415us/step - accuracy: 0.8026 - loss: 0.4084 - val_accuracy: 0.7901 - val_loss: 0.4204\n",
      "Epoch 21/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.8141 - loss: 0.4015 - val_accuracy: 0.7890 - val_loss: 0.4222\n",
      "Epoch 22/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415us/step - accuracy: 0.8013 - loss: 0.4043 - val_accuracy: 0.7890 - val_loss: 0.4209\n",
      "Epoch 23/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.8036 - loss: 0.4054 - val_accuracy: 0.7890 - val_loss: 0.4225\n",
      "Epoch 24/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - accuracy: 0.8008 - loss: 0.3993 - val_accuracy: 0.7918 - val_loss: 0.4195\n",
      "Epoch 25/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413us/step - accuracy: 0.8134 - loss: 0.4029 - val_accuracy: 0.7901 - val_loss: 0.4206\n",
      "Epoch 26/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.8058 - loss: 0.4051 - val_accuracy: 0.7907 - val_loss: 0.4199\n",
      "Epoch 27/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.8096 - loss: 0.3880 - val_accuracy: 0.7878 - val_loss: 0.4207\n",
      "Epoch 28/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - accuracy: 0.8088 - loss: 0.3934 - val_accuracy: 0.7901 - val_loss: 0.4219\n",
      "Epoch 29/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420us/step - accuracy: 0.7982 - loss: 0.4072 - val_accuracy: 0.7907 - val_loss: 0.4172\n",
      "Epoch 30/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414us/step - accuracy: 0.8101 - loss: 0.3993 - val_accuracy: 0.7924 - val_loss: 0.4162\n",
      "Epoch 31/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step - accuracy: 0.8089 - loss: 0.3959 - val_accuracy: 0.7890 - val_loss: 0.4180\n",
      "Epoch 32/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step - accuracy: 0.8195 - loss: 0.3892 - val_accuracy: 0.7959 - val_loss: 0.4133\n",
      "Epoch 33/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421us/step - accuracy: 0.8178 - loss: 0.3933 - val_accuracy: 0.7953 - val_loss: 0.4153\n",
      "Epoch 34/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605us/step - accuracy: 0.8190 - loss: 0.3835 - val_accuracy: 0.7901 - val_loss: 0.4131\n",
      "Epoch 35/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - accuracy: 0.8165 - loss: 0.3919 - val_accuracy: 0.7953 - val_loss: 0.4131\n",
      "Epoch 36/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419us/step - accuracy: 0.8187 - loss: 0.3835 - val_accuracy: 0.7936 - val_loss: 0.4155\n",
      "Epoch 37/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.8072 - loss: 0.3927 - val_accuracy: 0.7947 - val_loss: 0.4112\n",
      "Epoch 38/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413us/step - accuracy: 0.8175 - loss: 0.3895 - val_accuracy: 0.7878 - val_loss: 0.4169\n",
      "Epoch 39/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416us/step - accuracy: 0.8050 - loss: 0.3974 - val_accuracy: 0.7895 - val_loss: 0.4197\n",
      "Epoch 40/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step - accuracy: 0.8109 - loss: 0.3878 - val_accuracy: 0.7913 - val_loss: 0.4165\n",
      "Epoch 41/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417us/step - accuracy: 0.8124 - loss: 0.3889 - val_accuracy: 0.7959 - val_loss: 0.4136\n",
      "Epoch 42/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413us/step - accuracy: 0.8134 - loss: 0.3873 - val_accuracy: 0.7884 - val_loss: 0.4150\n",
      "Epoch 43/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417us/step - accuracy: 0.8181 - loss: 0.3782 - val_accuracy: 0.7918 - val_loss: 0.4132\n",
      "Epoch 44/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417us/step - accuracy: 0.8205 - loss: 0.3807 - val_accuracy: 0.7993 - val_loss: 0.4117\n",
      "Epoch 45/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419us/step - accuracy: 0.8111 - loss: 0.3892 - val_accuracy: 0.7941 - val_loss: 0.4126\n",
      "Epoch 46/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - accuracy: 0.8110 - loss: 0.3847 - val_accuracy: 0.7890 - val_loss: 0.4201\n",
      "Epoch 47/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417us/step - accuracy: 0.8225 - loss: 0.3763 - val_accuracy: 0.7936 - val_loss: 0.4149\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rahulnundlall/anaconda3/envs/ML/lib/python3.12/site-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6962 - loss: 0.6087 - val_accuracy: 0.7665 - val_loss: 0.4833\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - accuracy: 0.7863 - loss: 0.4575 - val_accuracy: 0.7763 - val_loss: 0.4574\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - accuracy: 0.7962 - loss: 0.4342 - val_accuracy: 0.7775 - val_loss: 0.4559\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 0.8005 - loss: 0.4290 - val_accuracy: 0.7844 - val_loss: 0.4496\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 0.7994 - loss: 0.4181 - val_accuracy: 0.7815 - val_loss: 0.4458\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 0.7955 - loss: 0.4254 - val_accuracy: 0.7832 - val_loss: 0.4451\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 0.8012 - loss: 0.4053 - val_accuracy: 0.7867 - val_loss: 0.4403\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - accuracy: 0.7990 - loss: 0.4173 - val_accuracy: 0.7786 - val_loss: 0.4413\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - accuracy: 0.8085 - loss: 0.4045 - val_accuracy: 0.7855 - val_loss: 0.4386\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - accuracy: 0.8085 - loss: 0.3963 - val_accuracy: 0.7803 - val_loss: 0.4373\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - accuracy: 0.8148 - loss: 0.4053 - val_accuracy: 0.7826 - val_loss: 0.4394\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - accuracy: 0.8069 - loss: 0.4018 - val_accuracy: 0.7757 - val_loss: 0.4356\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - accuracy: 0.8133 - loss: 0.3984 - val_accuracy: 0.7826 - val_loss: 0.4354\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - accuracy: 0.8067 - loss: 0.4074 - val_accuracy: 0.7821 - val_loss: 0.4360\n",
      "Epoch 15/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - accuracy: 0.8138 - loss: 0.3986 - val_accuracy: 0.7815 - val_loss: 0.4377\n",
      "Epoch 16/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - accuracy: 0.8072 - loss: 0.3994 - val_accuracy: 0.7844 - val_loss: 0.4347\n",
      "Epoch 17/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8076 - loss: 0.3949 - val_accuracy: 0.7809 - val_loss: 0.4331\n",
      "Epoch 18/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - accuracy: 0.8036 - loss: 0.4071 - val_accuracy: 0.7913 - val_loss: 0.4321\n",
      "Epoch 19/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - accuracy: 0.8222 - loss: 0.3813 - val_accuracy: 0.7821 - val_loss: 0.4351\n",
      "Epoch 20/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - accuracy: 0.8126 - loss: 0.4012 - val_accuracy: 0.7878 - val_loss: 0.4330\n",
      "Epoch 21/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - accuracy: 0.8108 - loss: 0.3934 - val_accuracy: 0.7838 - val_loss: 0.4350\n",
      "Epoch 22/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - accuracy: 0.8174 - loss: 0.3861 - val_accuracy: 0.7821 - val_loss: 0.4304\n",
      "Epoch 23/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - accuracy: 0.8033 - loss: 0.3920 - val_accuracy: 0.7849 - val_loss: 0.4295\n",
      "Epoch 24/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - accuracy: 0.8075 - loss: 0.3973 - val_accuracy: 0.7838 - val_loss: 0.4303\n",
      "Epoch 25/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - accuracy: 0.8119 - loss: 0.3915 - val_accuracy: 0.7907 - val_loss: 0.4277\n",
      "Epoch 26/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - accuracy: 0.8109 - loss: 0.3868 - val_accuracy: 0.7855 - val_loss: 0.4275\n",
      "Epoch 27/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - accuracy: 0.8158 - loss: 0.3847 - val_accuracy: 0.7815 - val_loss: 0.4272\n",
      "Epoch 28/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - accuracy: 0.8160 - loss: 0.3935 - val_accuracy: 0.7884 - val_loss: 0.4273\n",
      "Epoch 29/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - accuracy: 0.8067 - loss: 0.3950 - val_accuracy: 0.7867 - val_loss: 0.4272\n",
      "Epoch 30/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - accuracy: 0.8168 - loss: 0.3855 - val_accuracy: 0.7878 - val_loss: 0.4250\n",
      "Epoch 31/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - accuracy: 0.8188 - loss: 0.3868 - val_accuracy: 0.7855 - val_loss: 0.4260\n",
      "Epoch 32/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8175 - loss: 0.3864 - val_accuracy: 0.7798 - val_loss: 0.4282\n",
      "Epoch 33/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 965us/step - accuracy: 0.8213 - loss: 0.3816 - val_accuracy: 0.7878 - val_loss: 0.4256\n",
      "Epoch 34/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8132 - loss: 0.3897 - val_accuracy: 0.7913 - val_loss: 0.4267\n",
      "Epoch 35/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 965us/step - accuracy: 0.8071 - loss: 0.3889 - val_accuracy: 0.7861 - val_loss: 0.4243\n",
      "Epoch 36/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - accuracy: 0.8233 - loss: 0.3825 - val_accuracy: 0.7838 - val_loss: 0.4262\n",
      "Epoch 37/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8268 - loss: 0.3715 - val_accuracy: 0.7878 - val_loss: 0.4227\n",
      "Epoch 38/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - accuracy: 0.8163 - loss: 0.3778 - val_accuracy: 0.7832 - val_loss: 0.4309\n",
      "Epoch 39/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - accuracy: 0.8244 - loss: 0.3784 - val_accuracy: 0.7838 - val_loss: 0.4298\n",
      "Epoch 40/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - accuracy: 0.8203 - loss: 0.3755 - val_accuracy: 0.7855 - val_loss: 0.4253\n",
      "Epoch 41/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8165 - loss: 0.3790 - val_accuracy: 0.7901 - val_loss: 0.4259\n",
      "Epoch 42/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - accuracy: 0.8242 - loss: 0.3666 - val_accuracy: 0.7872 - val_loss: 0.4294\n",
      "Epoch 43/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - accuracy: 0.8170 - loss: 0.3829 - val_accuracy: 0.7861 - val_loss: 0.4252\n",
      "Epoch 44/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - accuracy: 0.8237 - loss: 0.3707 - val_accuracy: 0.7890 - val_loss: 0.4240\n",
      "Epoch 45/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - accuracy: 0.8170 - loss: 0.3802 - val_accuracy: 0.7901 - val_loss: 0.4250\n",
      "Epoch 46/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - accuracy: 0.8158 - loss: 0.3818 - val_accuracy: 0.7844 - val_loss: 0.4327\n",
      "Epoch 47/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - accuracy: 0.8288 - loss: 0.3662 - val_accuracy: 0.7895 - val_loss: 0.4248\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rahulnundlall/anaconda3/envs/ML/lib/python3.12/site-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 726us/step - accuracy: 0.5285 - loss: 0.6940 - val_accuracy: 0.6786 - val_loss: 0.6184\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.6643 - loss: 0.6265 - val_accuracy: 0.7441 - val_loss: 0.5650\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - accuracy: 0.7253 - loss: 0.5654 - val_accuracy: 0.7568 - val_loss: 0.5255\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.7379 - loss: 0.5348 - val_accuracy: 0.7602 - val_loss: 0.5028\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.7651 - loss: 0.5095 - val_accuracy: 0.7677 - val_loss: 0.4885\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436us/step - accuracy: 0.7595 - loss: 0.5029 - val_accuracy: 0.7665 - val_loss: 0.4810\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - accuracy: 0.7710 - loss: 0.4820 - val_accuracy: 0.7711 - val_loss: 0.4760\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430us/step - accuracy: 0.7780 - loss: 0.4782 - val_accuracy: 0.7723 - val_loss: 0.4722\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.7822 - loss: 0.4693 - val_accuracy: 0.7711 - val_loss: 0.4690\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438us/step - accuracy: 0.7761 - loss: 0.4725 - val_accuracy: 0.7717 - val_loss: 0.4671\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434us/step - accuracy: 0.7840 - loss: 0.4560 - val_accuracy: 0.7729 - val_loss: 0.4641\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427us/step - accuracy: 0.7812 - loss: 0.4587 - val_accuracy: 0.7746 - val_loss: 0.4613\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438us/step - accuracy: 0.7841 - loss: 0.4649 - val_accuracy: 0.7746 - val_loss: 0.4597\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431us/step - accuracy: 0.7713 - loss: 0.4699 - val_accuracy: 0.7757 - val_loss: 0.4583\n",
      "Epoch 15/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433us/step - accuracy: 0.7880 - loss: 0.4567 - val_accuracy: 0.7769 - val_loss: 0.4568\n",
      "Epoch 16/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432us/step - accuracy: 0.7767 - loss: 0.4587 - val_accuracy: 0.7786 - val_loss: 0.4555\n",
      "Epoch 17/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429us/step - accuracy: 0.7906 - loss: 0.4472 - val_accuracy: 0.7798 - val_loss: 0.4542\n",
      "Epoch 18/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432us/step - accuracy: 0.7836 - loss: 0.4521 - val_accuracy: 0.7809 - val_loss: 0.4534\n",
      "Epoch 19/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436us/step - accuracy: 0.7862 - loss: 0.4475 - val_accuracy: 0.7798 - val_loss: 0.4532\n",
      "Epoch 20/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428us/step - accuracy: 0.7914 - loss: 0.4573 - val_accuracy: 0.7798 - val_loss: 0.4513\n",
      "Epoch 21/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431us/step - accuracy: 0.7897 - loss: 0.4492 - val_accuracy: 0.7815 - val_loss: 0.4519\n",
      "Epoch 22/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438us/step - accuracy: 0.7882 - loss: 0.4481 - val_accuracy: 0.7821 - val_loss: 0.4503\n",
      "Epoch 23/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - accuracy: 0.7974 - loss: 0.4377 - val_accuracy: 0.7803 - val_loss: 0.4503\n",
      "Epoch 24/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.7893 - loss: 0.4425 - val_accuracy: 0.7809 - val_loss: 0.4492\n",
      "Epoch 25/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - accuracy: 0.7932 - loss: 0.4352 - val_accuracy: 0.7815 - val_loss: 0.4476\n",
      "Epoch 26/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438us/step - accuracy: 0.7922 - loss: 0.4375 - val_accuracy: 0.7809 - val_loss: 0.4489\n",
      "Epoch 27/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434us/step - accuracy: 0.7963 - loss: 0.4360 - val_accuracy: 0.7809 - val_loss: 0.4467\n",
      "Epoch 28/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - accuracy: 0.7911 - loss: 0.4448 - val_accuracy: 0.7832 - val_loss: 0.4465\n",
      "Epoch 29/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430us/step - accuracy: 0.7931 - loss: 0.4405 - val_accuracy: 0.7809 - val_loss: 0.4454\n",
      "Epoch 30/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438us/step - accuracy: 0.7962 - loss: 0.4340 - val_accuracy: 0.7826 - val_loss: 0.4464\n",
      "Epoch 31/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433us/step - accuracy: 0.7973 - loss: 0.4336 - val_accuracy: 0.7815 - val_loss: 0.4450\n",
      "Epoch 32/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428us/step - accuracy: 0.7929 - loss: 0.4338 - val_accuracy: 0.7815 - val_loss: 0.4448\n",
      "Epoch 33/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430us/step - accuracy: 0.7792 - loss: 0.4522 - val_accuracy: 0.7815 - val_loss: 0.4440\n",
      "Epoch 34/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - accuracy: 0.7947 - loss: 0.4324 - val_accuracy: 0.7826 - val_loss: 0.4433\n",
      "Epoch 35/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - accuracy: 0.7959 - loss: 0.4357 - val_accuracy: 0.7832 - val_loss: 0.4432\n",
      "Epoch 36/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.7924 - loss: 0.4390 - val_accuracy: 0.7849 - val_loss: 0.4432\n",
      "Epoch 37/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439us/step - accuracy: 0.7883 - loss: 0.4347 - val_accuracy: 0.7855 - val_loss: 0.4415\n",
      "Epoch 38/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - accuracy: 0.7901 - loss: 0.4410 - val_accuracy: 0.7844 - val_loss: 0.4414\n",
      "Epoch 39/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421us/step - accuracy: 0.7990 - loss: 0.4184 - val_accuracy: 0.7844 - val_loss: 0.4411\n",
      "Epoch 40/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432us/step - accuracy: 0.7949 - loss: 0.4325 - val_accuracy: 0.7855 - val_loss: 0.4417\n",
      "Epoch 41/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - accuracy: 0.7935 - loss: 0.4396 - val_accuracy: 0.7844 - val_loss: 0.4408\n",
      "Epoch 42/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.8002 - loss: 0.4288 - val_accuracy: 0.7838 - val_loss: 0.4404\n",
      "Epoch 43/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step - accuracy: 0.8044 - loss: 0.4269 - val_accuracy: 0.7872 - val_loss: 0.4400\n",
      "Epoch 44/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443us/step - accuracy: 0.7958 - loss: 0.4369 - val_accuracy: 0.7878 - val_loss: 0.4395\n",
      "Epoch 45/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431us/step - accuracy: 0.7905 - loss: 0.4339 - val_accuracy: 0.7849 - val_loss: 0.4400\n",
      "Epoch 46/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.7928 - loss: 0.4411 - val_accuracy: 0.7878 - val_loss: 0.4389\n",
      "Epoch 47/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - accuracy: 0.7995 - loss: 0.4199 - val_accuracy: 0.7878 - val_loss: 0.4391\n",
      "Epoch 48/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - accuracy: 0.8090 - loss: 0.4179 - val_accuracy: 0.7844 - val_loss: 0.4392\n",
      "Epoch 49/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - accuracy: 0.7935 - loss: 0.4355 - val_accuracy: 0.7867 - val_loss: 0.4393\n",
      "Epoch 50/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - accuracy: 0.8016 - loss: 0.4193 - val_accuracy: 0.7872 - val_loss: 0.4386\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rahulnundlall/anaconda3/envs/ML/lib/python3.12/site-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 687us/step - accuracy: 0.7269 - loss: 0.5447 - val_accuracy: 0.7803 - val_loss: 0.4599\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443us/step - accuracy: 0.7851 - loss: 0.4460 - val_accuracy: 0.7792 - val_loss: 0.4534\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - accuracy: 0.7922 - loss: 0.4425 - val_accuracy: 0.7838 - val_loss: 0.4404\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step - accuracy: 0.7933 - loss: 0.4341 - val_accuracy: 0.7895 - val_loss: 0.4361\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - accuracy: 0.7990 - loss: 0.4161 - val_accuracy: 0.7849 - val_loss: 0.4351\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429us/step - accuracy: 0.7960 - loss: 0.4295 - val_accuracy: 0.7815 - val_loss: 0.4321\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436us/step - accuracy: 0.8003 - loss: 0.4252 - val_accuracy: 0.7924 - val_loss: 0.4259\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - accuracy: 0.8002 - loss: 0.4173 - val_accuracy: 0.7895 - val_loss: 0.4246\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - accuracy: 0.8159 - loss: 0.3978 - val_accuracy: 0.7844 - val_loss: 0.4277\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428us/step - accuracy: 0.8044 - loss: 0.4105 - val_accuracy: 0.7855 - val_loss: 0.4386\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428us/step - accuracy: 0.8109 - loss: 0.4030 - val_accuracy: 0.7901 - val_loss: 0.4230\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432us/step - accuracy: 0.7997 - loss: 0.4030 - val_accuracy: 0.7884 - val_loss: 0.4179\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - accuracy: 0.8114 - loss: 0.3989 - val_accuracy: 0.7844 - val_loss: 0.4201\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429us/step - accuracy: 0.8015 - loss: 0.4084 - val_accuracy: 0.7867 - val_loss: 0.4201\n",
      "Epoch 15/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.8053 - loss: 0.4111 - val_accuracy: 0.7895 - val_loss: 0.4144\n",
      "Epoch 16/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - accuracy: 0.8123 - loss: 0.3975 - val_accuracy: 0.7890 - val_loss: 0.4204\n",
      "Epoch 17/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427us/step - accuracy: 0.8020 - loss: 0.4039 - val_accuracy: 0.7913 - val_loss: 0.4206\n",
      "Epoch 18/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421us/step - accuracy: 0.8105 - loss: 0.3899 - val_accuracy: 0.7861 - val_loss: 0.4414\n",
      "Epoch 19/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426us/step - accuracy: 0.8125 - loss: 0.3909 - val_accuracy: 0.7815 - val_loss: 0.4175\n",
      "Epoch 20/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429us/step - accuracy: 0.8067 - loss: 0.3937 - val_accuracy: 0.7844 - val_loss: 0.4183\n",
      "Epoch 21/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430us/step - accuracy: 0.8158 - loss: 0.3930 - val_accuracy: 0.7947 - val_loss: 0.4135\n",
      "Epoch 22/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430us/step - accuracy: 0.8038 - loss: 0.3930 - val_accuracy: 0.7895 - val_loss: 0.4168\n",
      "Epoch 23/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427us/step - accuracy: 0.8124 - loss: 0.3850 - val_accuracy: 0.7878 - val_loss: 0.4137\n",
      "Epoch 24/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428us/step - accuracy: 0.8135 - loss: 0.3916 - val_accuracy: 0.7884 - val_loss: 0.4137\n",
      "Epoch 25/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426us/step - accuracy: 0.8115 - loss: 0.3908 - val_accuracy: 0.7890 - val_loss: 0.4151\n",
      "Epoch 26/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429us/step - accuracy: 0.8122 - loss: 0.3852 - val_accuracy: 0.7941 - val_loss: 0.4094\n",
      "Epoch 27/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.8126 - loss: 0.3836 - val_accuracy: 0.7895 - val_loss: 0.4163\n",
      "Epoch 28/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - accuracy: 0.8172 - loss: 0.3841 - val_accuracy: 0.7924 - val_loss: 0.4171\n",
      "Epoch 29/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - accuracy: 0.8127 - loss: 0.3800 - val_accuracy: 0.7895 - val_loss: 0.4184\n",
      "Epoch 30/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416us/step - accuracy: 0.8126 - loss: 0.3715 - val_accuracy: 0.7930 - val_loss: 0.4137\n",
      "Epoch 31/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426us/step - accuracy: 0.8129 - loss: 0.3812 - val_accuracy: 0.7901 - val_loss: 0.4141\n",
      "Epoch 32/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418us/step - accuracy: 0.8230 - loss: 0.3716 - val_accuracy: 0.7878 - val_loss: 0.4120\n",
      "Epoch 33/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418us/step - accuracy: 0.8176 - loss: 0.3783 - val_accuracy: 0.7884 - val_loss: 0.4123\n",
      "Epoch 34/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416us/step - accuracy: 0.8127 - loss: 0.3745 - val_accuracy: 0.7924 - val_loss: 0.4121\n",
      "Epoch 35/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419us/step - accuracy: 0.8215 - loss: 0.3748 - val_accuracy: 0.7890 - val_loss: 0.4161\n",
      "Epoch 36/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - accuracy: 0.8117 - loss: 0.3801 - val_accuracy: 0.7895 - val_loss: 0.4130\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rahulnundlall/anaconda3/envs/ML/lib/python3.12/site-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7603 - loss: 0.5087 - val_accuracy: 0.7602 - val_loss: 0.4882\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - accuracy: 0.7896 - loss: 0.4519 - val_accuracy: 0.7769 - val_loss: 0.4447\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - accuracy: 0.7976 - loss: 0.4271 - val_accuracy: 0.7878 - val_loss: 0.4496\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - accuracy: 0.7935 - loss: 0.4374 - val_accuracy: 0.7867 - val_loss: 0.4490\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - accuracy: 0.7993 - loss: 0.4313 - val_accuracy: 0.7815 - val_loss: 0.4459\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step - accuracy: 0.7948 - loss: 0.4343 - val_accuracy: 0.7867 - val_loss: 0.4233\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - accuracy: 0.7950 - loss: 0.4211 - val_accuracy: 0.7844 - val_loss: 0.4358\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - accuracy: 0.7971 - loss: 0.4218 - val_accuracy: 0.7809 - val_loss: 0.4328\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7999 - loss: 0.4247 - val_accuracy: 0.7763 - val_loss: 0.4448\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - accuracy: 0.8057 - loss: 0.4199 - val_accuracy: 0.7688 - val_loss: 0.4424\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - accuracy: 0.8109 - loss: 0.4098 - val_accuracy: 0.7688 - val_loss: 0.4621\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - accuracy: 0.8023 - loss: 0.4088 - val_accuracy: 0.7867 - val_loss: 0.4266\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - accuracy: 0.8045 - loss: 0.4175 - val_accuracy: 0.7832 - val_loss: 0.4257\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - accuracy: 0.8053 - loss: 0.4092 - val_accuracy: 0.7901 - val_loss: 0.4295\n",
      "Epoch 15/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - accuracy: 0.8066 - loss: 0.4110 - val_accuracy: 0.7953 - val_loss: 0.4250\n",
      "Epoch 16/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - accuracy: 0.7956 - loss: 0.4193 - val_accuracy: 0.7947 - val_loss: 0.4171\n",
      "Epoch 17/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - accuracy: 0.8019 - loss: 0.4094 - val_accuracy: 0.7878 - val_loss: 0.4312\n",
      "Epoch 18/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - accuracy: 0.7980 - loss: 0.4050 - val_accuracy: 0.7930 - val_loss: 0.4192\n",
      "Epoch 19/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - accuracy: 0.8025 - loss: 0.4088 - val_accuracy: 0.7936 - val_loss: 0.4250\n",
      "Epoch 20/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - accuracy: 0.8060 - loss: 0.4032 - val_accuracy: 0.7930 - val_loss: 0.4282\n",
      "Epoch 21/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - accuracy: 0.8029 - loss: 0.4100 - val_accuracy: 0.7826 - val_loss: 0.4221\n",
      "Epoch 22/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - accuracy: 0.8080 - loss: 0.3990 - val_accuracy: 0.7826 - val_loss: 0.4224\n",
      "Epoch 23/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - accuracy: 0.8098 - loss: 0.3973 - val_accuracy: 0.7878 - val_loss: 0.4097\n",
      "Epoch 24/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - accuracy: 0.8010 - loss: 0.4000 - val_accuracy: 0.7855 - val_loss: 0.4252\n",
      "Epoch 25/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - accuracy: 0.8036 - loss: 0.3990 - val_accuracy: 0.7826 - val_loss: 0.4342\n",
      "Epoch 26/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - accuracy: 0.8019 - loss: 0.4108 - val_accuracy: 0.7959 - val_loss: 0.4311\n",
      "Epoch 27/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - accuracy: 0.8057 - loss: 0.3905 - val_accuracy: 0.7867 - val_loss: 0.4267\n",
      "Epoch 28/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - accuracy: 0.8031 - loss: 0.3910 - val_accuracy: 0.7809 - val_loss: 0.4247\n",
      "Epoch 29/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 0.8006 - loss: 0.4030 - val_accuracy: 0.7878 - val_loss: 0.4368\n",
      "Epoch 30/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step - accuracy: 0.8069 - loss: 0.3981 - val_accuracy: 0.7821 - val_loss: 0.4231\n",
      "Epoch 31/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - accuracy: 0.8057 - loss: 0.3976 - val_accuracy: 0.7895 - val_loss: 0.4159\n",
      "Epoch 32/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - accuracy: 0.7970 - loss: 0.4050 - val_accuracy: 0.7798 - val_loss: 0.4276\n",
      "Epoch 33/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8034 - loss: 0.3970 - val_accuracy: 0.7872 - val_loss: 0.4285\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rahulnundlall/anaconda3/envs/ML/lib/python3.12/site-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7465 - loss: 0.4995 - val_accuracy: 0.7608 - val_loss: 0.4853\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - accuracy: 0.7937 - loss: 0.4231 - val_accuracy: 0.7729 - val_loss: 0.4409\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - accuracy: 0.7936 - loss: 0.4212 - val_accuracy: 0.7792 - val_loss: 0.4421\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - accuracy: 0.7951 - loss: 0.4211 - val_accuracy: 0.7826 - val_loss: 0.4365\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8046 - loss: 0.4118 - val_accuracy: 0.7815 - val_loss: 0.4410\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8121 - loss: 0.4029 - val_accuracy: 0.7924 - val_loss: 0.4283\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8059 - loss: 0.4002 - val_accuracy: 0.7872 - val_loss: 0.4276\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8093 - loss: 0.3910 - val_accuracy: 0.7901 - val_loss: 0.4236\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8119 - loss: 0.3986 - val_accuracy: 0.7959 - val_loss: 0.4243\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8026 - loss: 0.4107 - val_accuracy: 0.7913 - val_loss: 0.4258\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8049 - loss: 0.4008 - val_accuracy: 0.7947 - val_loss: 0.4210\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - accuracy: 0.8102 - loss: 0.3939 - val_accuracy: 0.7867 - val_loss: 0.4240\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - accuracy: 0.8104 - loss: 0.3979 - val_accuracy: 0.7884 - val_loss: 0.4377\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - accuracy: 0.8089 - loss: 0.3926 - val_accuracy: 0.7861 - val_loss: 0.4276\n",
      "Epoch 15/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 965us/step - accuracy: 0.8031 - loss: 0.3964 - val_accuracy: 0.7890 - val_loss: 0.4196\n",
      "Epoch 16/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987us/step - accuracy: 0.8105 - loss: 0.3871 - val_accuracy: 0.7878 - val_loss: 0.4253\n",
      "Epoch 17/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - accuracy: 0.8150 - loss: 0.3827 - val_accuracy: 0.7901 - val_loss: 0.4234\n",
      "Epoch 18/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8101 - loss: 0.3839 - val_accuracy: 0.7895 - val_loss: 0.4151\n",
      "Epoch 19/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step - accuracy: 0.8116 - loss: 0.3869 - val_accuracy: 0.7826 - val_loss: 0.4173\n",
      "Epoch 20/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - accuracy: 0.8059 - loss: 0.3843 - val_accuracy: 0.7890 - val_loss: 0.4200\n",
      "Epoch 21/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - accuracy: 0.8048 - loss: 0.3922 - val_accuracy: 0.7815 - val_loss: 0.4301\n",
      "Epoch 22/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - accuracy: 0.8050 - loss: 0.3984 - val_accuracy: 0.7861 - val_loss: 0.4249\n",
      "Epoch 23/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - accuracy: 0.8199 - loss: 0.3716 - val_accuracy: 0.7924 - val_loss: 0.4160\n",
      "Epoch 24/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8067 - loss: 0.3862 - val_accuracy: 0.7907 - val_loss: 0.4216\n",
      "Epoch 25/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step - accuracy: 0.8176 - loss: 0.3778 - val_accuracy: 0.7924 - val_loss: 0.4229\n",
      "Epoch 26/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - accuracy: 0.8176 - loss: 0.3760 - val_accuracy: 0.7901 - val_loss: 0.4298\n",
      "Epoch 27/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - accuracy: 0.8105 - loss: 0.3852 - val_accuracy: 0.7878 - val_loss: 0.4259\n",
      "Epoch 28/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - accuracy: 0.8145 - loss: 0.3773 - val_accuracy: 0.7878 - val_loss: 0.4148\n",
      "Epoch 29/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987us/step - accuracy: 0.8114 - loss: 0.3750 - val_accuracy: 0.7861 - val_loss: 0.4316\n",
      "Epoch 30/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step - accuracy: 0.8119 - loss: 0.3746 - val_accuracy: 0.7970 - val_loss: 0.4347\n",
      "Epoch 31/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 975us/step - accuracy: 0.8191 - loss: 0.3648 - val_accuracy: 0.7941 - val_loss: 0.4391\n",
      "Epoch 32/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8253 - loss: 0.3686 - val_accuracy: 0.7930 - val_loss: 0.4284\n",
      "Epoch 33/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - accuracy: 0.8287 - loss: 0.3630 - val_accuracy: 0.7936 - val_loss: 0.4233\n",
      "Epoch 34/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - accuracy: 0.8233 - loss: 0.3680 - val_accuracy: 0.7924 - val_loss: 0.4332\n",
      "Epoch 35/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - accuracy: 0.8175 - loss: 0.3732 - val_accuracy: 0.7895 - val_loss: 0.4266\n",
      "Epoch 36/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - accuracy: 0.8269 - loss: 0.3615 - val_accuracy: 0.7901 - val_loss: 0.4176\n",
      "Epoch 37/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 975us/step - accuracy: 0.8258 - loss: 0.3555 - val_accuracy: 0.7884 - val_loss: 0.4337\n",
      "Epoch 38/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8286 - loss: 0.3508 - val_accuracy: 0.7890 - val_loss: 0.4280\n",
      "Best parameters: [99, 0.43634275659563393, 0.0008855561236207113]\n",
      "Best validation accuracy: 0.796434760093689\n"
     ]
    }
   ],
   "source": [
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "\n",
    "# Define the space of hyperparameters to search\n",
    "space = [\n",
    "    Integer(32, 512, name='layer_size'),\n",
    "    Real(0.01, 0.5, name='dropout_rate'),\n",
    "    Real(1e-4, 1e-2, prior='log-uniform', name='learning_rate')\n",
    "]\n",
    "\n",
    "# Function to optimize (we aim to minimize 1 - accuracy)\n",
    "@use_named_args(space)\n",
    "def objective(**params):\n",
    "    model = create_model(\n",
    "        input_shape=X_train_smote.shape[1], \n",
    "        layers=[params['layer_size']] * 2,  # Example: using the same size for two layers\n",
    "        activation='relu', \n",
    "        dropout_rate=params['dropout_rate'], \n",
    "        learning_rate=params['learning_rate']\n",
    "    )\n",
    "    val_loss, val_acc = train_and_evaluate(model, X_train_smote, y_train_smote, X_val, y_val, \n",
    "                                           batch_size=32, epochs=50, class_weight=class_weight_dict)\n",
    "    return 1 - val_acc  # as we need to minimize\n",
    "\n",
    "# Run Bayesian optimization\n",
    "result = gp_minimize(objective, space, n_calls=20, random_state=0)\n",
    "\n",
    "print(f\"Best parameters: {result.x}\")\n",
    "print(f\"Best validation accuracy: {1 - result.fun}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
