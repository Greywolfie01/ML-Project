{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from scipy.stats import expon, reciprocal\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow import keras\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import keras_tuner as kt\n",
    "import deap\n",
    "import skopt\n",
    "from tensorflow.keras.models import save_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rahulnundlall/anaconda3/envs/ML/lib/python3.12/site-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650us/step - accuracy: 0.7356 - loss: 0.5276 - val_accuracy: 0.7757 - val_loss: 0.4727\n",
      "Epoch 2/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step - accuracy: 0.7865 - loss: 0.4570 - val_accuracy: 0.7734 - val_loss: 0.4646\n",
      "Epoch 3/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - accuracy: 0.7926 - loss: 0.4526 - val_accuracy: 0.7746 - val_loss: 0.4595\n",
      "Epoch 4/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475us/step - accuracy: 0.7838 - loss: 0.4500 - val_accuracy: 0.7752 - val_loss: 0.4580\n",
      "Epoch 5/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - accuracy: 0.7878 - loss: 0.4525 - val_accuracy: 0.7752 - val_loss: 0.4695\n",
      "Epoch 6/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - accuracy: 0.8003 - loss: 0.4279 - val_accuracy: 0.7757 - val_loss: 0.4586\n",
      "Epoch 7/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - accuracy: 0.8011 - loss: 0.4350 - val_accuracy: 0.7832 - val_loss: 0.4538\n",
      "Epoch 8/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - accuracy: 0.7937 - loss: 0.4371 - val_accuracy: 0.7821 - val_loss: 0.4498\n",
      "Epoch 9/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - accuracy: 0.7931 - loss: 0.4297 - val_accuracy: 0.7734 - val_loss: 0.4567\n",
      "Epoch 10/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - accuracy: 0.7947 - loss: 0.4348 - val_accuracy: 0.7803 - val_loss: 0.4389\n",
      "Epoch 11/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - accuracy: 0.7953 - loss: 0.4359 - val_accuracy: 0.7844 - val_loss: 0.4403\n",
      "Epoch 12/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - accuracy: 0.7908 - loss: 0.4323 - val_accuracy: 0.7821 - val_loss: 0.4362\n",
      "Epoch 13/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 666us/step - accuracy: 0.8022 - loss: 0.4230 - val_accuracy: 0.7798 - val_loss: 0.4400\n",
      "Epoch 14/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - accuracy: 0.8063 - loss: 0.4117 - val_accuracy: 0.7763 - val_loss: 0.4343\n",
      "Epoch 15/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 0.7984 - loss: 0.4275 - val_accuracy: 0.7878 - val_loss: 0.4320\n",
      "Epoch 16/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.8058 - loss: 0.4090 - val_accuracy: 0.7803 - val_loss: 0.4340\n",
      "Epoch 17/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - accuracy: 0.8030 - loss: 0.4174 - val_accuracy: 0.7924 - val_loss: 0.4249\n",
      "Epoch 18/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - accuracy: 0.8151 - loss: 0.3995 - val_accuracy: 0.7890 - val_loss: 0.4237\n",
      "Epoch 19/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - accuracy: 0.8014 - loss: 0.4157 - val_accuracy: 0.7918 - val_loss: 0.4175\n",
      "Epoch 20/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - accuracy: 0.8045 - loss: 0.4118 - val_accuracy: 0.7884 - val_loss: 0.4320\n",
      "Epoch 21/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step - accuracy: 0.8039 - loss: 0.4109 - val_accuracy: 0.7867 - val_loss: 0.4243\n",
      "Epoch 22/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.8135 - loss: 0.3955 - val_accuracy: 0.7844 - val_loss: 0.4220\n",
      "Epoch 23/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - accuracy: 0.8110 - loss: 0.3980 - val_accuracy: 0.7878 - val_loss: 0.4248\n",
      "Epoch 24/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - accuracy: 0.7994 - loss: 0.4135 - val_accuracy: 0.7913 - val_loss: 0.4206\n",
      "Epoch 25/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step - accuracy: 0.8032 - loss: 0.4055 - val_accuracy: 0.7872 - val_loss: 0.4174\n",
      "Epoch 26/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - accuracy: 0.8054 - loss: 0.4088 - val_accuracy: 0.7884 - val_loss: 0.4238\n",
      "Epoch 27/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.8061 - loss: 0.3989 - val_accuracy: 0.7763 - val_loss: 0.4254\n",
      "Epoch 28/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - accuracy: 0.8025 - loss: 0.4067 - val_accuracy: 0.7895 - val_loss: 0.4241\n",
      "Epoch 29/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - accuracy: 0.8009 - loss: 0.4187 - val_accuracy: 0.7930 - val_loss: 0.4162\n",
      "Epoch 30/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - accuracy: 0.8056 - loss: 0.4052 - val_accuracy: 0.7861 - val_loss: 0.4164\n",
      "Epoch 31/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - accuracy: 0.7888 - loss: 0.4145 - val_accuracy: 0.7941 - val_loss: 0.4137\n",
      "Epoch 32/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - accuracy: 0.8101 - loss: 0.4048 - val_accuracy: 0.7941 - val_loss: 0.4155\n",
      "Epoch 33/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step - accuracy: 0.8024 - loss: 0.4108 - val_accuracy: 0.7884 - val_loss: 0.4207\n",
      "Epoch 34/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - accuracy: 0.8039 - loss: 0.4100 - val_accuracy: 0.7844 - val_loss: 0.4255\n",
      "Epoch 35/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.8056 - loss: 0.3971 - val_accuracy: 0.7913 - val_loss: 0.4147\n",
      "Epoch 36/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - accuracy: 0.8031 - loss: 0.4092 - val_accuracy: 0.7987 - val_loss: 0.4144\n",
      "Epoch 37/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - accuracy: 0.8112 - loss: 0.3931 - val_accuracy: 0.7941 - val_loss: 0.4158\n",
      "Epoch 38/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - accuracy: 0.7970 - loss: 0.4046 - val_accuracy: 0.7959 - val_loss: 0.4153\n",
      "Epoch 39/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - accuracy: 0.8190 - loss: 0.3947 - val_accuracy: 0.7878 - val_loss: 0.4179\n",
      "Epoch 40/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - accuracy: 0.8093 - loss: 0.3969 - val_accuracy: 0.7913 - val_loss: 0.4152\n",
      "Epoch 41/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.7951 - loss: 0.4182 - val_accuracy: 0.7924 - val_loss: 0.4168\n",
      "Iteration 0 using ADAM: Validation Accuracy = 0.7941345572471619\n",
      "New best model found and saved.\n",
      "Epoch 1/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.5287 - loss: 0.7051 - val_accuracy: 0.7062 - val_loss: 0.6192\n",
      "Epoch 2/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - accuracy: 0.6418 - loss: 0.6334 - val_accuracy: 0.7441 - val_loss: 0.5754\n",
      "Epoch 3/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - accuracy: 0.7003 - loss: 0.5866 - val_accuracy: 0.7539 - val_loss: 0.5475\n",
      "Epoch 4/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7057 - loss: 0.5756 - val_accuracy: 0.7579 - val_loss: 0.5281\n",
      "Epoch 5/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7232 - loss: 0.5518 - val_accuracy: 0.7625 - val_loss: 0.5138\n",
      "Epoch 6/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.7466 - loss: 0.5325 - val_accuracy: 0.7654 - val_loss: 0.5040\n",
      "Epoch 7/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.7474 - loss: 0.5216 - val_accuracy: 0.7648 - val_loss: 0.4969\n",
      "Epoch 8/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.7516 - loss: 0.5210 - val_accuracy: 0.7665 - val_loss: 0.4917\n",
      "Epoch 9/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7573 - loss: 0.5040 - val_accuracy: 0.7683 - val_loss: 0.4874\n",
      "Epoch 10/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7629 - loss: 0.4962 - val_accuracy: 0.7694 - val_loss: 0.4842\n",
      "Epoch 11/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7690 - loss: 0.5002 - val_accuracy: 0.7683 - val_loss: 0.4815\n",
      "Epoch 12/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.7763 - loss: 0.4876 - val_accuracy: 0.7700 - val_loss: 0.4797\n",
      "Epoch 13/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - accuracy: 0.7722 - loss: 0.4814 - val_accuracy: 0.7694 - val_loss: 0.4780\n",
      "Epoch 14/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7596 - loss: 0.4995 - val_accuracy: 0.7683 - val_loss: 0.4762\n",
      "Epoch 15/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.7787 - loss: 0.4899 - val_accuracy: 0.7683 - val_loss: 0.4754\n",
      "Epoch 16/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.7807 - loss: 0.4747 - val_accuracy: 0.7683 - val_loss: 0.4746\n",
      "Epoch 17/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7754 - loss: 0.4776 - val_accuracy: 0.7677 - val_loss: 0.4739\n",
      "Epoch 18/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - accuracy: 0.7750 - loss: 0.4853 - val_accuracy: 0.7677 - val_loss: 0.4732\n",
      "Epoch 19/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7812 - loss: 0.4778 - val_accuracy: 0.7688 - val_loss: 0.4727\n",
      "Epoch 20/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7827 - loss: 0.4719 - val_accuracy: 0.7711 - val_loss: 0.4721\n",
      "Epoch 21/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - accuracy: 0.7828 - loss: 0.4688 - val_accuracy: 0.7706 - val_loss: 0.4715\n",
      "Epoch 22/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - accuracy: 0.7794 - loss: 0.4753 - val_accuracy: 0.7711 - val_loss: 0.4713\n",
      "Epoch 23/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - accuracy: 0.7754 - loss: 0.4743 - val_accuracy: 0.7706 - val_loss: 0.4704\n",
      "Epoch 24/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - accuracy: 0.7835 - loss: 0.4668 - val_accuracy: 0.7706 - val_loss: 0.4700\n",
      "Epoch 25/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - accuracy: 0.7880 - loss: 0.4673 - val_accuracy: 0.7706 - val_loss: 0.4697\n",
      "Epoch 26/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.7719 - loss: 0.4811 - val_accuracy: 0.7711 - val_loss: 0.4697\n",
      "Epoch 27/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7909 - loss: 0.4567 - val_accuracy: 0.7711 - val_loss: 0.4691\n",
      "Epoch 28/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.7752 - loss: 0.4767 - val_accuracy: 0.7711 - val_loss: 0.4689\n",
      "Epoch 29/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - accuracy: 0.7778 - loss: 0.4846 - val_accuracy: 0.7734 - val_loss: 0.4685\n",
      "Epoch 30/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.7757 - loss: 0.4743 - val_accuracy: 0.7740 - val_loss: 0.4683\n",
      "Epoch 31/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.7919 - loss: 0.4635 - val_accuracy: 0.7729 - val_loss: 0.4682\n",
      "Epoch 32/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.7737 - loss: 0.4708 - val_accuracy: 0.7757 - val_loss: 0.4677\n",
      "Epoch 33/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.7898 - loss: 0.4669 - val_accuracy: 0.7740 - val_loss: 0.4673\n",
      "Epoch 34/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.7811 - loss: 0.4656 - val_accuracy: 0.7763 - val_loss: 0.4670\n",
      "Epoch 35/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - accuracy: 0.7860 - loss: 0.4557 - val_accuracy: 0.7746 - val_loss: 0.4668\n",
      "Epoch 36/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7808 - loss: 0.4716 - val_accuracy: 0.7769 - val_loss: 0.4664\n",
      "Epoch 37/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - accuracy: 0.7820 - loss: 0.4589 - val_accuracy: 0.7763 - val_loss: 0.4664\n",
      "Epoch 38/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.7788 - loss: 0.4671 - val_accuracy: 0.7752 - val_loss: 0.4664\n",
      "Epoch 39/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - accuracy: 0.7905 - loss: 0.4511 - val_accuracy: 0.7763 - val_loss: 0.4658\n",
      "Epoch 40/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - accuracy: 0.7705 - loss: 0.4802 - val_accuracy: 0.7780 - val_loss: 0.4655\n",
      "Epoch 41/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.7875 - loss: 0.4576 - val_accuracy: 0.7780 - val_loss: 0.4653\n",
      "Epoch 42/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376us/step - accuracy: 0.7893 - loss: 0.4562 - val_accuracy: 0.7780 - val_loss: 0.4653\n",
      "Epoch 43/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - accuracy: 0.7881 - loss: 0.4620 - val_accuracy: 0.7757 - val_loss: 0.4650\n",
      "Epoch 44/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376us/step - accuracy: 0.7850 - loss: 0.4558 - val_accuracy: 0.7775 - val_loss: 0.4651\n",
      "Epoch 45/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - accuracy: 0.7774 - loss: 0.4681 - val_accuracy: 0.7775 - val_loss: 0.4651\n",
      "Epoch 46/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.7803 - loss: 0.4606 - val_accuracy: 0.7780 - val_loss: 0.4652\n",
      "Epoch 47/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - accuracy: 0.7881 - loss: 0.4619 - val_accuracy: 0.7763 - val_loss: 0.4651\n",
      "Epoch 48/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.7775 - loss: 0.4702 - val_accuracy: 0.7775 - val_loss: 0.4649\n",
      "Epoch 49/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - accuracy: 0.7799 - loss: 0.4637 - val_accuracy: 0.7780 - val_loss: 0.4646\n",
      "Epoch 50/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.7887 - loss: 0.4598 - val_accuracy: 0.7792 - val_loss: 0.4644\n",
      "Epoch 51/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.7908 - loss: 0.4520 - val_accuracy: 0.7769 - val_loss: 0.4640\n",
      "Epoch 52/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.7798 - loss: 0.4697 - val_accuracy: 0.7780 - val_loss: 0.4637\n",
      "Epoch 53/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375us/step - accuracy: 0.7906 - loss: 0.4536 - val_accuracy: 0.7780 - val_loss: 0.4638\n",
      "Epoch 54/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.7900 - loss: 0.4512 - val_accuracy: 0.7763 - val_loss: 0.4636\n",
      "Epoch 55/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - accuracy: 0.7877 - loss: 0.4528 - val_accuracy: 0.7792 - val_loss: 0.4638\n",
      "Epoch 56/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - accuracy: 0.7897 - loss: 0.4449 - val_accuracy: 0.7792 - val_loss: 0.4638\n",
      "Epoch 57/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.7799 - loss: 0.4581 - val_accuracy: 0.7780 - val_loss: 0.4636\n",
      "Epoch 58/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - accuracy: 0.7964 - loss: 0.4405 - val_accuracy: 0.7769 - val_loss: 0.4638\n",
      "Epoch 59/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - accuracy: 0.7861 - loss: 0.4612 - val_accuracy: 0.7786 - val_loss: 0.4637\n",
      "Epoch 60/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376us/step - accuracy: 0.7896 - loss: 0.4568 - val_accuracy: 0.7786 - val_loss: 0.4634\n",
      "Epoch 61/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.7897 - loss: 0.4463 - val_accuracy: 0.7798 - val_loss: 0.4637\n",
      "Epoch 62/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - accuracy: 0.7869 - loss: 0.4602 - val_accuracy: 0.7798 - val_loss: 0.4632\n",
      "Epoch 63/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376us/step - accuracy: 0.7892 - loss: 0.4520 - val_accuracy: 0.7786 - val_loss: 0.4630\n",
      "Epoch 64/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - accuracy: 0.7928 - loss: 0.4455 - val_accuracy: 0.7786 - val_loss: 0.4632\n",
      "Epoch 65/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.7907 - loss: 0.4522 - val_accuracy: 0.7769 - val_loss: 0.4634\n",
      "Epoch 66/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - accuracy: 0.7969 - loss: 0.4462 - val_accuracy: 0.7798 - val_loss: 0.4634\n",
      "Epoch 67/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.7905 - loss: 0.4547 - val_accuracy: 0.7792 - val_loss: 0.4632\n",
      "Epoch 68/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376us/step - accuracy: 0.7913 - loss: 0.4496 - val_accuracy: 0.7809 - val_loss: 0.4631\n",
      "Epoch 69/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - accuracy: 0.7870 - loss: 0.4490 - val_accuracy: 0.7809 - val_loss: 0.4628\n",
      "Epoch 70/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.7944 - loss: 0.4477 - val_accuracy: 0.7803 - val_loss: 0.4630\n",
      "Epoch 71/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7844 - loss: 0.4571 - val_accuracy: 0.7809 - val_loss: 0.4624\n",
      "Epoch 72/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376us/step - accuracy: 0.7880 - loss: 0.4584 - val_accuracy: 0.7809 - val_loss: 0.4626\n",
      "Epoch 73/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375us/step - accuracy: 0.7893 - loss: 0.4511 - val_accuracy: 0.7809 - val_loss: 0.4628\n",
      "Epoch 74/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.7831 - loss: 0.4644 - val_accuracy: 0.7803 - val_loss: 0.4626\n",
      "Epoch 75/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - accuracy: 0.7883 - loss: 0.4626 - val_accuracy: 0.7803 - val_loss: 0.4628\n",
      "Epoch 76/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - accuracy: 0.7913 - loss: 0.4536 - val_accuracy: 0.7815 - val_loss: 0.4629\n",
      "Epoch 77/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376us/step - accuracy: 0.7830 - loss: 0.4506 - val_accuracy: 0.7803 - val_loss: 0.4625\n",
      "Epoch 78/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7861 - loss: 0.4501 - val_accuracy: 0.7815 - val_loss: 0.4627\n",
      "Epoch 79/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - accuracy: 0.7853 - loss: 0.4589 - val_accuracy: 0.7803 - val_loss: 0.4624\n",
      "Epoch 80/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.7919 - loss: 0.4499 - val_accuracy: 0.7803 - val_loss: 0.4625\n",
      "Epoch 81/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.7868 - loss: 0.4458 - val_accuracy: 0.7803 - val_loss: 0.4625\n",
      "Epoch 82/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.7883 - loss: 0.4582 - val_accuracy: 0.7815 - val_loss: 0.4625\n",
      "Epoch 83/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.7829 - loss: 0.4532 - val_accuracy: 0.7821 - val_loss: 0.4623\n",
      "Epoch 84/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - accuracy: 0.7898 - loss: 0.4470 - val_accuracy: 0.7821 - val_loss: 0.4623\n",
      "Epoch 85/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - accuracy: 0.7861 - loss: 0.4507 - val_accuracy: 0.7815 - val_loss: 0.4622\n",
      "Epoch 86/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426us/step - accuracy: 0.7822 - loss: 0.4597 - val_accuracy: 0.7798 - val_loss: 0.4622\n",
      "Epoch 87/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - accuracy: 0.8013 - loss: 0.4401 - val_accuracy: 0.7832 - val_loss: 0.4622\n",
      "Epoch 88/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422us/step - accuracy: 0.7859 - loss: 0.4511 - val_accuracy: 0.7815 - val_loss: 0.4623\n",
      "Epoch 89/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - accuracy: 0.7910 - loss: 0.4502 - val_accuracy: 0.7821 - val_loss: 0.4618\n",
      "Epoch 90/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - accuracy: 0.7905 - loss: 0.4448 - val_accuracy: 0.7815 - val_loss: 0.4616\n",
      "Epoch 91/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7899 - loss: 0.4501 - val_accuracy: 0.7815 - val_loss: 0.4618\n",
      "Epoch 92/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7952 - loss: 0.4399 - val_accuracy: 0.7826 - val_loss: 0.4615\n",
      "Epoch 93/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7933 - loss: 0.4459 - val_accuracy: 0.7821 - val_loss: 0.4617\n",
      "Epoch 94/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - accuracy: 0.7858 - loss: 0.4571 - val_accuracy: 0.7809 - val_loss: 0.4618\n",
      "Epoch 95/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - accuracy: 0.7928 - loss: 0.4459 - val_accuracy: 0.7832 - val_loss: 0.4616\n",
      "Epoch 96/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376us/step - accuracy: 0.7826 - loss: 0.4568 - val_accuracy: 0.7826 - val_loss: 0.4615\n",
      "Epoch 97/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473us/step - accuracy: 0.7933 - loss: 0.4483 - val_accuracy: 0.7809 - val_loss: 0.4616\n",
      "Epoch 98/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375us/step - accuracy: 0.7961 - loss: 0.4458 - val_accuracy: 0.7815 - val_loss: 0.4616\n",
      "Epoch 99/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376us/step - accuracy: 0.7955 - loss: 0.4401 - val_accuracy: 0.7815 - val_loss: 0.4616\n",
      "Epoch 100/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.7987 - loss: 0.4415 - val_accuracy: 0.7809 - val_loss: 0.4616\n",
      "Iteration 1 using SGD: Validation Accuracy = 0.7826337218284607\n",
      "Epoch 1/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 609us/step - accuracy: 0.7294 - loss: 0.5310 - val_accuracy: 0.7717 - val_loss: 0.4815\n",
      "Epoch 2/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - accuracy: 0.7804 - loss: 0.4698 - val_accuracy: 0.7769 - val_loss: 0.4655\n",
      "Epoch 3/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474us/step - accuracy: 0.7818 - loss: 0.4615 - val_accuracy: 0.7734 - val_loss: 0.4688\n",
      "Epoch 4/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - accuracy: 0.7989 - loss: 0.4391 - val_accuracy: 0.7798 - val_loss: 0.4637\n",
      "Epoch 5/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.7979 - loss: 0.4372 - val_accuracy: 0.7763 - val_loss: 0.4533\n",
      "Epoch 6/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.7909 - loss: 0.4491 - val_accuracy: 0.7798 - val_loss: 0.4549\n",
      "Epoch 7/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.7933 - loss: 0.4382 - val_accuracy: 0.7717 - val_loss: 0.4570\n",
      "Epoch 8/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step - accuracy: 0.7999 - loss: 0.4223 - val_accuracy: 0.7752 - val_loss: 0.4482\n",
      "Epoch 9/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537us/step - accuracy: 0.7949 - loss: 0.4337 - val_accuracy: 0.7792 - val_loss: 0.4514\n",
      "Epoch 10/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - accuracy: 0.8037 - loss: 0.4235 - val_accuracy: 0.7826 - val_loss: 0.4331\n",
      "Epoch 11/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 0.7906 - loss: 0.4295 - val_accuracy: 0.7792 - val_loss: 0.4468\n",
      "Epoch 12/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.8071 - loss: 0.4160 - val_accuracy: 0.7792 - val_loss: 0.4340\n",
      "Epoch 13/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - accuracy: 0.8052 - loss: 0.4239 - val_accuracy: 0.7867 - val_loss: 0.4351\n",
      "Epoch 14/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.7978 - loss: 0.4245 - val_accuracy: 0.7798 - val_loss: 0.4355\n",
      "Epoch 15/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.8048 - loss: 0.4118 - val_accuracy: 0.7821 - val_loss: 0.4311\n",
      "Epoch 16/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - accuracy: 0.8000 - loss: 0.4171 - val_accuracy: 0.7895 - val_loss: 0.4293\n",
      "Epoch 17/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - accuracy: 0.7962 - loss: 0.4175 - val_accuracy: 0.7849 - val_loss: 0.4329\n",
      "Epoch 18/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - accuracy: 0.8088 - loss: 0.4127 - val_accuracy: 0.7872 - val_loss: 0.4260\n",
      "Epoch 19/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.7928 - loss: 0.4229 - val_accuracy: 0.7815 - val_loss: 0.4278\n",
      "Epoch 20/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 551us/step - accuracy: 0.7977 - loss: 0.4218 - val_accuracy: 0.7855 - val_loss: 0.4264\n",
      "Epoch 21/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.8061 - loss: 0.4048 - val_accuracy: 0.7861 - val_loss: 0.4287\n",
      "Epoch 22/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.8022 - loss: 0.4176 - val_accuracy: 0.7769 - val_loss: 0.4395\n",
      "Epoch 23/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.8078 - loss: 0.3989 - val_accuracy: 0.7786 - val_loss: 0.4286\n",
      "Epoch 24/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.8077 - loss: 0.4068 - val_accuracy: 0.7918 - val_loss: 0.4192\n",
      "Epoch 25/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.8014 - loss: 0.4097 - val_accuracy: 0.7838 - val_loss: 0.4268\n",
      "Epoch 26/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - accuracy: 0.8043 - loss: 0.4051 - val_accuracy: 0.7849 - val_loss: 0.4217\n",
      "Epoch 27/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.8168 - loss: 0.4020 - val_accuracy: 0.8010 - val_loss: 0.4203\n",
      "Epoch 28/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.8094 - loss: 0.4173 - val_accuracy: 0.7855 - val_loss: 0.4230\n",
      "Epoch 29/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.8016 - loss: 0.4143 - val_accuracy: 0.7901 - val_loss: 0.4175\n",
      "Epoch 30/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - accuracy: 0.8043 - loss: 0.4085 - val_accuracy: 0.7878 - val_loss: 0.4184\n",
      "Epoch 31/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.8042 - loss: 0.4017 - val_accuracy: 0.7798 - val_loss: 0.4241\n",
      "Epoch 32/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.8032 - loss: 0.4067 - val_accuracy: 0.7913 - val_loss: 0.4199\n",
      "Epoch 33/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.8076 - loss: 0.4004 - val_accuracy: 0.7872 - val_loss: 0.4159\n",
      "Epoch 34/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - accuracy: 0.8136 - loss: 0.4026 - val_accuracy: 0.7878 - val_loss: 0.4244\n",
      "Epoch 35/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - accuracy: 0.8032 - loss: 0.4055 - val_accuracy: 0.7821 - val_loss: 0.4138\n",
      "Epoch 36/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - accuracy: 0.8061 - loss: 0.4010 - val_accuracy: 0.7964 - val_loss: 0.4126\n",
      "Epoch 37/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.8064 - loss: 0.3950 - val_accuracy: 0.7878 - val_loss: 0.4183\n",
      "Epoch 38/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - accuracy: 0.7989 - loss: 0.4117 - val_accuracy: 0.7959 - val_loss: 0.4186\n",
      "Epoch 39/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - accuracy: 0.7990 - loss: 0.4012 - val_accuracy: 0.7884 - val_loss: 0.4183\n",
      "Epoch 40/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - accuracy: 0.7977 - loss: 0.4097 - val_accuracy: 0.7878 - val_loss: 0.4134\n",
      "Epoch 41/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - accuracy: 0.8114 - loss: 0.3855 - val_accuracy: 0.7918 - val_loss: 0.4157\n",
      "Epoch 42/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - accuracy: 0.8107 - loss: 0.3922 - val_accuracy: 0.7941 - val_loss: 0.4166\n",
      "Epoch 43/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step - accuracy: 0.8099 - loss: 0.3943 - val_accuracy: 0.7947 - val_loss: 0.4150\n",
      "Epoch 44/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - accuracy: 0.8106 - loss: 0.3895 - val_accuracy: 0.7959 - val_loss: 0.4161\n",
      "Epoch 45/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - accuracy: 0.8128 - loss: 0.3880 - val_accuracy: 0.7930 - val_loss: 0.4120\n",
      "Epoch 46/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - accuracy: 0.8169 - loss: 0.3842 - val_accuracy: 0.7953 - val_loss: 0.4148\n",
      "Epoch 47/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step - accuracy: 0.8091 - loss: 0.3928 - val_accuracy: 0.7947 - val_loss: 0.4101\n",
      "Epoch 48/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.8077 - loss: 0.3989 - val_accuracy: 0.7878 - val_loss: 0.4180\n",
      "Epoch 49/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - accuracy: 0.8070 - loss: 0.3914 - val_accuracy: 0.7867 - val_loss: 0.4143\n",
      "Epoch 50/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - accuracy: 0.8118 - loss: 0.3805 - val_accuracy: 0.7895 - val_loss: 0.4125\n",
      "Epoch 51/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.8172 - loss: 0.3780 - val_accuracy: 0.7918 - val_loss: 0.4095\n",
      "Epoch 52/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.8132 - loss: 0.3888 - val_accuracy: 0.7941 - val_loss: 0.4108\n",
      "Epoch 53/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.8145 - loss: 0.3948 - val_accuracy: 0.7941 - val_loss: 0.4076\n",
      "Epoch 54/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.8138 - loss: 0.3882 - val_accuracy: 0.7953 - val_loss: 0.4075\n",
      "Epoch 55/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - accuracy: 0.8224 - loss: 0.3894 - val_accuracy: 0.7959 - val_loss: 0.4122\n",
      "Epoch 56/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - accuracy: 0.8202 - loss: 0.3850 - val_accuracy: 0.7953 - val_loss: 0.4098\n",
      "Epoch 57/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - accuracy: 0.8190 - loss: 0.3795 - val_accuracy: 0.7947 - val_loss: 0.4071\n",
      "Epoch 58/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - accuracy: 0.8176 - loss: 0.3847 - val_accuracy: 0.7936 - val_loss: 0.4161\n",
      "Epoch 59/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - accuracy: 0.8173 - loss: 0.3866 - val_accuracy: 0.7941 - val_loss: 0.4101\n",
      "Epoch 60/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - accuracy: 0.8247 - loss: 0.3762 - val_accuracy: 0.7959 - val_loss: 0.4076\n",
      "Epoch 61/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.8143 - loss: 0.3870 - val_accuracy: 0.7918 - val_loss: 0.4121\n",
      "Epoch 62/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - accuracy: 0.8128 - loss: 0.3892 - val_accuracy: 0.7936 - val_loss: 0.4116\n",
      "Epoch 63/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - accuracy: 0.8161 - loss: 0.3785 - val_accuracy: 0.7907 - val_loss: 0.4112\n",
      "Epoch 64/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step - accuracy: 0.8137 - loss: 0.3785 - val_accuracy: 0.7941 - val_loss: 0.4079\n",
      "Epoch 65/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.8183 - loss: 0.3778 - val_accuracy: 0.7941 - val_loss: 0.4119\n",
      "Epoch 66/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.8141 - loss: 0.3850 - val_accuracy: 0.7907 - val_loss: 0.4089\n",
      "Epoch 67/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - accuracy: 0.8087 - loss: 0.3860 - val_accuracy: 0.7930 - val_loss: 0.4115\n",
      "Iteration 2 using ADAM: Validation Accuracy = 0.7947096228599548\n",
      "New best model found and saved.\n",
      "Epoch 1/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 0.5700 - loss: 0.6796 - val_accuracy: 0.7338 - val_loss: 0.5978\n",
      "Epoch 2/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443us/step - accuracy: 0.6365 - loss: 0.6278 - val_accuracy: 0.7573 - val_loss: 0.5567\n",
      "Epoch 3/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - accuracy: 0.7075 - loss: 0.5798 - val_accuracy: 0.7648 - val_loss: 0.5292\n",
      "Epoch 4/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7239 - loss: 0.5559 - val_accuracy: 0.7671 - val_loss: 0.5097\n",
      "Epoch 5/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - accuracy: 0.7456 - loss: 0.5351 - val_accuracy: 0.7677 - val_loss: 0.4963\n",
      "Epoch 6/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - accuracy: 0.7606 - loss: 0.5085 - val_accuracy: 0.7711 - val_loss: 0.4867\n",
      "Epoch 7/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - accuracy: 0.7584 - loss: 0.5056 - val_accuracy: 0.7717 - val_loss: 0.4804\n",
      "Epoch 8/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7632 - loss: 0.5061 - val_accuracy: 0.7752 - val_loss: 0.4762\n",
      "Epoch 9/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7702 - loss: 0.5008 - val_accuracy: 0.7734 - val_loss: 0.4734\n",
      "Epoch 10/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - accuracy: 0.7728 - loss: 0.4863 - val_accuracy: 0.7729 - val_loss: 0.4712\n",
      "Epoch 11/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.7586 - loss: 0.4990 - val_accuracy: 0.7729 - val_loss: 0.4702\n",
      "Epoch 12/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - accuracy: 0.7719 - loss: 0.4819 - val_accuracy: 0.7740 - val_loss: 0.4691\n",
      "Epoch 13/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.7709 - loss: 0.4813 - val_accuracy: 0.7729 - val_loss: 0.4688\n",
      "Epoch 14/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - accuracy: 0.7740 - loss: 0.4812 - val_accuracy: 0.7729 - val_loss: 0.4682\n",
      "Epoch 15/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7717 - loss: 0.4752 - val_accuracy: 0.7706 - val_loss: 0.4675\n",
      "Epoch 16/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7771 - loss: 0.4712 - val_accuracy: 0.7700 - val_loss: 0.4673\n",
      "Epoch 17/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - accuracy: 0.7851 - loss: 0.4658 - val_accuracy: 0.7711 - val_loss: 0.4668\n",
      "Epoch 18/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - accuracy: 0.7737 - loss: 0.4803 - val_accuracy: 0.7752 - val_loss: 0.4665\n",
      "Epoch 19/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7713 - loss: 0.4814 - val_accuracy: 0.7752 - val_loss: 0.4662\n",
      "Epoch 20/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.7809 - loss: 0.4750 - val_accuracy: 0.7752 - val_loss: 0.4660\n",
      "Epoch 21/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.7757 - loss: 0.4751 - val_accuracy: 0.7752 - val_loss: 0.4658\n",
      "Epoch 22/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7804 - loss: 0.4686 - val_accuracy: 0.7752 - val_loss: 0.4657\n",
      "Epoch 23/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.7847 - loss: 0.4710 - val_accuracy: 0.7746 - val_loss: 0.4658\n",
      "Epoch 24/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7730 - loss: 0.4810 - val_accuracy: 0.7752 - val_loss: 0.4657\n",
      "Epoch 25/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7805 - loss: 0.4626 - val_accuracy: 0.7757 - val_loss: 0.4656\n",
      "Epoch 26/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7822 - loss: 0.4678 - val_accuracy: 0.7746 - val_loss: 0.4654\n",
      "Epoch 27/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - accuracy: 0.7948 - loss: 0.4555 - val_accuracy: 0.7740 - val_loss: 0.4651\n",
      "Epoch 28/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7916 - loss: 0.4525 - val_accuracy: 0.7740 - val_loss: 0.4653\n",
      "Epoch 29/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7856 - loss: 0.4579 - val_accuracy: 0.7763 - val_loss: 0.4644\n",
      "Epoch 30/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.7822 - loss: 0.4648 - val_accuracy: 0.7752 - val_loss: 0.4644\n",
      "Epoch 31/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - accuracy: 0.7829 - loss: 0.4574 - val_accuracy: 0.7752 - val_loss: 0.4643\n",
      "Epoch 32/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7766 - loss: 0.4658 - val_accuracy: 0.7746 - val_loss: 0.4645\n",
      "Epoch 33/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7858 - loss: 0.4546 - val_accuracy: 0.7757 - val_loss: 0.4639\n",
      "Epoch 34/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7845 - loss: 0.4650 - val_accuracy: 0.7752 - val_loss: 0.4640\n",
      "Epoch 35/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.7826 - loss: 0.4637 - val_accuracy: 0.7757 - val_loss: 0.4638\n",
      "Epoch 36/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7832 - loss: 0.4646 - val_accuracy: 0.7752 - val_loss: 0.4638\n",
      "Epoch 37/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.7868 - loss: 0.4522 - val_accuracy: 0.7763 - val_loss: 0.4638\n",
      "Epoch 38/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - accuracy: 0.7880 - loss: 0.4557 - val_accuracy: 0.7757 - val_loss: 0.4635\n",
      "Epoch 39/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.7895 - loss: 0.4569 - val_accuracy: 0.7757 - val_loss: 0.4636\n",
      "Epoch 40/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7887 - loss: 0.4596 - val_accuracy: 0.7757 - val_loss: 0.4634\n",
      "Epoch 41/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.7886 - loss: 0.4603 - val_accuracy: 0.7786 - val_loss: 0.4633\n",
      "Epoch 42/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.7871 - loss: 0.4605 - val_accuracy: 0.7780 - val_loss: 0.4630\n",
      "Epoch 43/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7855 - loss: 0.4526 - val_accuracy: 0.7780 - val_loss: 0.4628\n",
      "Epoch 44/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7883 - loss: 0.4603 - val_accuracy: 0.7769 - val_loss: 0.4627\n",
      "Epoch 45/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7863 - loss: 0.4541 - val_accuracy: 0.7775 - val_loss: 0.4627\n",
      "Epoch 46/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.7908 - loss: 0.4627 - val_accuracy: 0.7775 - val_loss: 0.4627\n",
      "Epoch 47/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.7861 - loss: 0.4539 - val_accuracy: 0.7780 - val_loss: 0.4630\n",
      "Epoch 48/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.7940 - loss: 0.4562 - val_accuracy: 0.7780 - val_loss: 0.4626\n",
      "Epoch 49/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7692 - loss: 0.4739 - val_accuracy: 0.7780 - val_loss: 0.4626\n",
      "Epoch 50/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - accuracy: 0.7827 - loss: 0.4684 - val_accuracy: 0.7786 - val_loss: 0.4625\n",
      "Epoch 51/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.7977 - loss: 0.4402 - val_accuracy: 0.7775 - val_loss: 0.4624\n",
      "Epoch 52/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - accuracy: 0.7865 - loss: 0.4550 - val_accuracy: 0.7780 - val_loss: 0.4624\n",
      "Epoch 53/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7897 - loss: 0.4530 - val_accuracy: 0.7769 - val_loss: 0.4622\n",
      "Epoch 54/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.7837 - loss: 0.4582 - val_accuracy: 0.7792 - val_loss: 0.4623\n",
      "Epoch 55/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - accuracy: 0.7894 - loss: 0.4497 - val_accuracy: 0.7786 - val_loss: 0.4625\n",
      "Epoch 56/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.7975 - loss: 0.4499 - val_accuracy: 0.7780 - val_loss: 0.4627\n",
      "Epoch 57/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7961 - loss: 0.4392 - val_accuracy: 0.7780 - val_loss: 0.4623\n",
      "Epoch 58/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - accuracy: 0.7864 - loss: 0.4600 - val_accuracy: 0.7780 - val_loss: 0.4621\n",
      "Epoch 59/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.7852 - loss: 0.4573 - val_accuracy: 0.7769 - val_loss: 0.4622\n",
      "Epoch 60/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7887 - loss: 0.4622 - val_accuracy: 0.7780 - val_loss: 0.4621\n",
      "Epoch 61/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7872 - loss: 0.4502 - val_accuracy: 0.7786 - val_loss: 0.4620\n",
      "Epoch 62/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.7902 - loss: 0.4507 - val_accuracy: 0.7780 - val_loss: 0.4616\n",
      "Epoch 63/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - accuracy: 0.7871 - loss: 0.4518 - val_accuracy: 0.7786 - val_loss: 0.4619\n",
      "Epoch 64/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - accuracy: 0.7909 - loss: 0.4454 - val_accuracy: 0.7792 - val_loss: 0.4621\n",
      "Epoch 65/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - accuracy: 0.7952 - loss: 0.4495 - val_accuracy: 0.7792 - val_loss: 0.4617\n",
      "Epoch 66/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.7822 - loss: 0.4642 - val_accuracy: 0.7786 - val_loss: 0.4616\n",
      "Epoch 67/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7869 - loss: 0.4591 - val_accuracy: 0.7792 - val_loss: 0.4615\n",
      "Epoch 68/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.7918 - loss: 0.4558 - val_accuracy: 0.7792 - val_loss: 0.4614\n",
      "Epoch 69/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.7867 - loss: 0.4636 - val_accuracy: 0.7798 - val_loss: 0.4615\n",
      "Epoch 70/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - accuracy: 0.7927 - loss: 0.4476 - val_accuracy: 0.7809 - val_loss: 0.4613\n",
      "Epoch 71/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.7821 - loss: 0.4600 - val_accuracy: 0.7786 - val_loss: 0.4614\n",
      "Epoch 72/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.7803 - loss: 0.4635 - val_accuracy: 0.7792 - val_loss: 0.4613\n",
      "Epoch 73/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7862 - loss: 0.4551 - val_accuracy: 0.7786 - val_loss: 0.4612\n",
      "Epoch 74/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.7940 - loss: 0.4462 - val_accuracy: 0.7798 - val_loss: 0.4614\n",
      "Epoch 75/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7864 - loss: 0.4547 - val_accuracy: 0.7792 - val_loss: 0.4615\n",
      "Epoch 76/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.7884 - loss: 0.4519 - val_accuracy: 0.7809 - val_loss: 0.4617\n",
      "Epoch 77/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - accuracy: 0.7858 - loss: 0.4559 - val_accuracy: 0.7798 - val_loss: 0.4616\n",
      "Epoch 78/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7870 - loss: 0.4583 - val_accuracy: 0.7792 - val_loss: 0.4616\n",
      "Epoch 79/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.7801 - loss: 0.4533 - val_accuracy: 0.7798 - val_loss: 0.4613\n",
      "Epoch 80/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7855 - loss: 0.4562 - val_accuracy: 0.7792 - val_loss: 0.4613\n",
      "Epoch 81/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7995 - loss: 0.4421 - val_accuracy: 0.7786 - val_loss: 0.4610\n",
      "Epoch 82/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7920 - loss: 0.4560 - val_accuracy: 0.7786 - val_loss: 0.4612\n",
      "Epoch 83/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7989 - loss: 0.4485 - val_accuracy: 0.7792 - val_loss: 0.4613\n",
      "Epoch 84/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - accuracy: 0.7768 - loss: 0.4676 - val_accuracy: 0.7792 - val_loss: 0.4613\n",
      "Epoch 85/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.7978 - loss: 0.4427 - val_accuracy: 0.7780 - val_loss: 0.4615\n",
      "Epoch 86/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - accuracy: 0.7902 - loss: 0.4435 - val_accuracy: 0.7792 - val_loss: 0.4614\n",
      "Epoch 87/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7803 - loss: 0.4656 - val_accuracy: 0.7780 - val_loss: 0.4614\n",
      "Epoch 88/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375us/step - accuracy: 0.7895 - loss: 0.4488 - val_accuracy: 0.7798 - val_loss: 0.4611\n",
      "Epoch 89/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.7927 - loss: 0.4429 - val_accuracy: 0.7803 - val_loss: 0.4610\n",
      "Epoch 90/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - accuracy: 0.7891 - loss: 0.4592 - val_accuracy: 0.7798 - val_loss: 0.4610\n",
      "Epoch 91/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - accuracy: 0.7843 - loss: 0.4534 - val_accuracy: 0.7792 - val_loss: 0.4612\n",
      "Epoch 92/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - accuracy: 0.7811 - loss: 0.4555 - val_accuracy: 0.7786 - val_loss: 0.4612\n",
      "Epoch 93/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - accuracy: 0.8027 - loss: 0.4309 - val_accuracy: 0.7780 - val_loss: 0.4610\n",
      "Epoch 94/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7911 - loss: 0.4543 - val_accuracy: 0.7792 - val_loss: 0.4609\n",
      "Epoch 95/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7951 - loss: 0.4449 - val_accuracy: 0.7798 - val_loss: 0.4611\n",
      "Epoch 96/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7893 - loss: 0.4487 - val_accuracy: 0.7780 - val_loss: 0.4609\n",
      "Epoch 97/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.7922 - loss: 0.4487 - val_accuracy: 0.7775 - val_loss: 0.4606\n",
      "Epoch 98/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7928 - loss: 0.4436 - val_accuracy: 0.7786 - val_loss: 0.4608\n",
      "Epoch 99/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376us/step - accuracy: 0.7871 - loss: 0.4483 - val_accuracy: 0.7792 - val_loss: 0.4609\n",
      "Epoch 100/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - accuracy: 0.7846 - loss: 0.4555 - val_accuracy: 0.7786 - val_loss: 0.4613\n",
      "Iteration 3 using SGD: Validation Accuracy = 0.7774583101272583\n",
      "Epoch 1/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 826us/step - accuracy: 0.7393 - loss: 0.5275 - val_accuracy: 0.7677 - val_loss: 0.4719\n",
      "Epoch 2/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - accuracy: 0.7809 - loss: 0.4676 - val_accuracy: 0.7746 - val_loss: 0.4738\n",
      "Epoch 3/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552us/step - accuracy: 0.7827 - loss: 0.4654 - val_accuracy: 0.7792 - val_loss: 0.4597\n",
      "Epoch 4/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - accuracy: 0.7853 - loss: 0.4519 - val_accuracy: 0.7752 - val_loss: 0.4670\n",
      "Epoch 5/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475us/step - accuracy: 0.7874 - loss: 0.4514 - val_accuracy: 0.7717 - val_loss: 0.4556\n",
      "Epoch 6/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - accuracy: 0.7963 - loss: 0.4433 - val_accuracy: 0.7786 - val_loss: 0.4535\n",
      "Epoch 7/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - accuracy: 0.7924 - loss: 0.4364 - val_accuracy: 0.7809 - val_loss: 0.4569\n",
      "Epoch 8/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.7954 - loss: 0.4350 - val_accuracy: 0.7809 - val_loss: 0.4436\n",
      "Epoch 9/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - accuracy: 0.7904 - loss: 0.4304 - val_accuracy: 0.7763 - val_loss: 0.4514\n",
      "Epoch 10/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - accuracy: 0.8034 - loss: 0.4192 - val_accuracy: 0.7826 - val_loss: 0.4388\n",
      "Epoch 11/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - accuracy: 0.7982 - loss: 0.4277 - val_accuracy: 0.7849 - val_loss: 0.4440\n",
      "Epoch 12/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step - accuracy: 0.8004 - loss: 0.4237 - val_accuracy: 0.7872 - val_loss: 0.4348\n",
      "Epoch 13/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - accuracy: 0.8034 - loss: 0.4156 - val_accuracy: 0.7815 - val_loss: 0.4425\n",
      "Epoch 14/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step - accuracy: 0.7964 - loss: 0.4295 - val_accuracy: 0.7849 - val_loss: 0.4461\n",
      "Epoch 15/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474us/step - accuracy: 0.7889 - loss: 0.4274 - val_accuracy: 0.7844 - val_loss: 0.4301\n",
      "Epoch 16/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.7982 - loss: 0.4183 - val_accuracy: 0.7890 - val_loss: 0.4253\n",
      "Epoch 17/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546us/step - accuracy: 0.7990 - loss: 0.4155 - val_accuracy: 0.7849 - val_loss: 0.4254\n",
      "Epoch 18/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step - accuracy: 0.7979 - loss: 0.4190 - val_accuracy: 0.7867 - val_loss: 0.4273\n",
      "Epoch 19/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - accuracy: 0.7937 - loss: 0.4138 - val_accuracy: 0.7826 - val_loss: 0.4340\n",
      "Epoch 20/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - accuracy: 0.8024 - loss: 0.4084 - val_accuracy: 0.7872 - val_loss: 0.4272\n",
      "Epoch 21/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 666us/step - accuracy: 0.8114 - loss: 0.4007 - val_accuracy: 0.7936 - val_loss: 0.4209\n",
      "Epoch 22/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 0.7970 - loss: 0.4068 - val_accuracy: 0.7924 - val_loss: 0.4239\n",
      "Epoch 23/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537us/step - accuracy: 0.7993 - loss: 0.4039 - val_accuracy: 0.7861 - val_loss: 0.4229\n",
      "Epoch 24/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - accuracy: 0.8052 - loss: 0.4043 - val_accuracy: 0.7901 - val_loss: 0.4200\n",
      "Epoch 25/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540us/step - accuracy: 0.7962 - loss: 0.4070 - val_accuracy: 0.7844 - val_loss: 0.4192\n",
      "Epoch 26/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - accuracy: 0.8059 - loss: 0.4123 - val_accuracy: 0.7878 - val_loss: 0.4237\n",
      "Epoch 27/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - accuracy: 0.7950 - loss: 0.4182 - val_accuracy: 0.7855 - val_loss: 0.4176\n",
      "Epoch 28/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - accuracy: 0.7990 - loss: 0.4017 - val_accuracy: 0.7913 - val_loss: 0.4202\n",
      "Epoch 29/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - accuracy: 0.8102 - loss: 0.4006 - val_accuracy: 0.7913 - val_loss: 0.4212\n",
      "Epoch 30/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - accuracy: 0.8078 - loss: 0.4062 - val_accuracy: 0.7918 - val_loss: 0.4184\n",
      "Epoch 31/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - accuracy: 0.8128 - loss: 0.3993 - val_accuracy: 0.7890 - val_loss: 0.4184\n",
      "Epoch 32/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - accuracy: 0.8121 - loss: 0.3947 - val_accuracy: 0.7930 - val_loss: 0.4141\n",
      "Epoch 33/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - accuracy: 0.8173 - loss: 0.3965 - val_accuracy: 0.7930 - val_loss: 0.4150\n",
      "Epoch 34/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475us/step - accuracy: 0.8003 - loss: 0.4024 - val_accuracy: 0.7895 - val_loss: 0.4171\n",
      "Epoch 35/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 0.8167 - loss: 0.3812 - val_accuracy: 0.7895 - val_loss: 0.4146\n",
      "Epoch 36/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step - accuracy: 0.8078 - loss: 0.3935 - val_accuracy: 0.7924 - val_loss: 0.4147\n",
      "Epoch 37/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - accuracy: 0.8135 - loss: 0.3900 - val_accuracy: 0.7890 - val_loss: 0.4162\n",
      "Epoch 38/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.8033 - loss: 0.3985 - val_accuracy: 0.7867 - val_loss: 0.4138\n",
      "Epoch 39/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - accuracy: 0.8105 - loss: 0.3961 - val_accuracy: 0.7907 - val_loss: 0.4170\n",
      "Epoch 40/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - accuracy: 0.8114 - loss: 0.3842 - val_accuracy: 0.7936 - val_loss: 0.4141\n",
      "Epoch 41/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - accuracy: 0.8068 - loss: 0.3959 - val_accuracy: 0.7918 - val_loss: 0.4123\n",
      "Epoch 42/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.8194 - loss: 0.3870 - val_accuracy: 0.7953 - val_loss: 0.4075\n",
      "Epoch 43/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - accuracy: 0.8168 - loss: 0.3856 - val_accuracy: 0.8010 - val_loss: 0.4160\n",
      "Epoch 44/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - accuracy: 0.8162 - loss: 0.3897 - val_accuracy: 0.7987 - val_loss: 0.4121\n",
      "Epoch 45/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - accuracy: 0.8212 - loss: 0.3838 - val_accuracy: 0.7970 - val_loss: 0.4094\n",
      "Epoch 46/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - accuracy: 0.8186 - loss: 0.3865 - val_accuracy: 0.7895 - val_loss: 0.4241\n",
      "Epoch 47/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - accuracy: 0.8061 - loss: 0.3989 - val_accuracy: 0.7947 - val_loss: 0.4100\n",
      "Epoch 48/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - accuracy: 0.8089 - loss: 0.3949 - val_accuracy: 0.7924 - val_loss: 0.4161\n",
      "Epoch 49/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - accuracy: 0.8133 - loss: 0.3899 - val_accuracy: 0.7907 - val_loss: 0.4124\n",
      "Epoch 50/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step - accuracy: 0.8220 - loss: 0.3801 - val_accuracy: 0.7976 - val_loss: 0.4056\n",
      "Epoch 51/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.8130 - loss: 0.3865 - val_accuracy: 0.7924 - val_loss: 0.4162\n",
      "Epoch 52/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - accuracy: 0.8017 - loss: 0.4011 - val_accuracy: 0.7964 - val_loss: 0.4139\n",
      "Epoch 53/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step - accuracy: 0.8103 - loss: 0.3900 - val_accuracy: 0.7941 - val_loss: 0.4199\n",
      "Epoch 54/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.8159 - loss: 0.3888 - val_accuracy: 0.7930 - val_loss: 0.4206\n",
      "Epoch 55/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - accuracy: 0.8211 - loss: 0.3844 - val_accuracy: 0.7970 - val_loss: 0.4092\n",
      "Epoch 56/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - accuracy: 0.8176 - loss: 0.3811 - val_accuracy: 0.8016 - val_loss: 0.4087\n",
      "Epoch 57/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - accuracy: 0.8126 - loss: 0.3941 - val_accuracy: 0.7936 - val_loss: 0.4228\n",
      "Epoch 58/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.8173 - loss: 0.3840 - val_accuracy: 0.7970 - val_loss: 0.4108\n",
      "Epoch 59/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.8146 - loss: 0.3914 - val_accuracy: 0.7953 - val_loss: 0.4129\n",
      "Epoch 60/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step - accuracy: 0.8110 - loss: 0.3810 - val_accuracy: 0.7941 - val_loss: 0.4154\n",
      "Iteration 4 using ADAM: Validation Accuracy = 0.7975848317146301\n",
      "New best model found and saved.\n",
      "Epoch 1/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - accuracy: 0.5699 - loss: 0.6901 - val_accuracy: 0.6469 - val_loss: 0.6178\n",
      "Epoch 2/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.6405 - loss: 0.6287 - val_accuracy: 0.7073 - val_loss: 0.5769\n",
      "Epoch 3/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - accuracy: 0.6804 - loss: 0.5966 - val_accuracy: 0.7464 - val_loss: 0.5497\n",
      "Epoch 4/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - accuracy: 0.7115 - loss: 0.5666 - val_accuracy: 0.7619 - val_loss: 0.5298\n",
      "Epoch 5/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.7227 - loss: 0.5608 - val_accuracy: 0.7671 - val_loss: 0.5146\n",
      "Epoch 6/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - accuracy: 0.7479 - loss: 0.5293 - val_accuracy: 0.7671 - val_loss: 0.5033\n",
      "Epoch 7/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - accuracy: 0.7572 - loss: 0.5221 - val_accuracy: 0.7671 - val_loss: 0.4955\n",
      "Epoch 8/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7457 - loss: 0.5250 - val_accuracy: 0.7671 - val_loss: 0.4893\n",
      "Epoch 9/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7590 - loss: 0.5018 - val_accuracy: 0.7671 - val_loss: 0.4849\n",
      "Epoch 10/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.7718 - loss: 0.5000 - val_accuracy: 0.7677 - val_loss: 0.4825\n",
      "Epoch 11/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - accuracy: 0.7591 - loss: 0.5067 - val_accuracy: 0.7683 - val_loss: 0.4801\n",
      "Epoch 12/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430us/step - accuracy: 0.7665 - loss: 0.4898 - val_accuracy: 0.7671 - val_loss: 0.4785\n",
      "Epoch 13/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.7726 - loss: 0.4867 - val_accuracy: 0.7717 - val_loss: 0.4772\n",
      "Epoch 14/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7679 - loss: 0.4813 - val_accuracy: 0.7711 - val_loss: 0.4761\n",
      "Epoch 15/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.7766 - loss: 0.4797 - val_accuracy: 0.7717 - val_loss: 0.4753\n",
      "Epoch 16/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7612 - loss: 0.4903 - val_accuracy: 0.7694 - val_loss: 0.4743\n",
      "Epoch 17/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - accuracy: 0.7884 - loss: 0.4682 - val_accuracy: 0.7706 - val_loss: 0.4738\n",
      "Epoch 18/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - accuracy: 0.7627 - loss: 0.4831 - val_accuracy: 0.7706 - val_loss: 0.4733\n",
      "Epoch 19/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - accuracy: 0.7918 - loss: 0.4675 - val_accuracy: 0.7700 - val_loss: 0.4727\n",
      "Epoch 20/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - accuracy: 0.7873 - loss: 0.4661 - val_accuracy: 0.7706 - val_loss: 0.4723\n",
      "Epoch 21/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - accuracy: 0.7829 - loss: 0.4747 - val_accuracy: 0.7694 - val_loss: 0.4712\n",
      "Epoch 22/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7896 - loss: 0.4624 - val_accuracy: 0.7711 - val_loss: 0.4711\n",
      "Epoch 23/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - accuracy: 0.7733 - loss: 0.4736 - val_accuracy: 0.7717 - val_loss: 0.4709\n",
      "Epoch 24/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545us/step - accuracy: 0.7751 - loss: 0.4824 - val_accuracy: 0.7711 - val_loss: 0.4703\n",
      "Epoch 25/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7806 - loss: 0.4719 - val_accuracy: 0.7711 - val_loss: 0.4702\n",
      "Epoch 26/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - accuracy: 0.7917 - loss: 0.4598 - val_accuracy: 0.7706 - val_loss: 0.4700\n",
      "Epoch 27/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - accuracy: 0.7868 - loss: 0.4671 - val_accuracy: 0.7711 - val_loss: 0.4697\n",
      "Epoch 28/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - accuracy: 0.7761 - loss: 0.4749 - val_accuracy: 0.7723 - val_loss: 0.4690\n",
      "Epoch 29/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - accuracy: 0.7960 - loss: 0.4517 - val_accuracy: 0.7723 - val_loss: 0.4688\n",
      "Epoch 30/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - accuracy: 0.7862 - loss: 0.4641 - val_accuracy: 0.7757 - val_loss: 0.4686\n",
      "Epoch 31/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - accuracy: 0.7711 - loss: 0.4775 - val_accuracy: 0.7740 - val_loss: 0.4689\n",
      "Epoch 32/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.7866 - loss: 0.4597 - val_accuracy: 0.7746 - val_loss: 0.4683\n",
      "Epoch 33/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - accuracy: 0.7779 - loss: 0.4780 - val_accuracy: 0.7757 - val_loss: 0.4678\n",
      "Epoch 34/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362us/step - accuracy: 0.7794 - loss: 0.4703 - val_accuracy: 0.7757 - val_loss: 0.4678\n",
      "Epoch 35/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364us/step - accuracy: 0.7777 - loss: 0.4624 - val_accuracy: 0.7763 - val_loss: 0.4671\n",
      "Epoch 36/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475us/step - accuracy: 0.7929 - loss: 0.4622 - val_accuracy: 0.7769 - val_loss: 0.4668\n",
      "Epoch 37/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368us/step - accuracy: 0.7851 - loss: 0.4599 - val_accuracy: 0.7786 - val_loss: 0.4667\n",
      "Epoch 38/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - accuracy: 0.7836 - loss: 0.4620 - val_accuracy: 0.7775 - val_loss: 0.4665\n",
      "Epoch 39/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375us/step - accuracy: 0.7771 - loss: 0.4683 - val_accuracy: 0.7780 - val_loss: 0.4666\n",
      "Epoch 40/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364us/step - accuracy: 0.7871 - loss: 0.4551 - val_accuracy: 0.7757 - val_loss: 0.4663\n",
      "Epoch 41/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365us/step - accuracy: 0.7840 - loss: 0.4597 - val_accuracy: 0.7769 - val_loss: 0.4663\n",
      "Epoch 42/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - accuracy: 0.7821 - loss: 0.4601 - val_accuracy: 0.7792 - val_loss: 0.4659\n",
      "Epoch 43/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - accuracy: 0.7808 - loss: 0.4602 - val_accuracy: 0.7809 - val_loss: 0.4658\n",
      "Epoch 44/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374us/step - accuracy: 0.7818 - loss: 0.4644 - val_accuracy: 0.7803 - val_loss: 0.4660\n",
      "Epoch 45/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - accuracy: 0.7831 - loss: 0.4621 - val_accuracy: 0.7792 - val_loss: 0.4660\n",
      "Epoch 46/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366us/step - accuracy: 0.7780 - loss: 0.4702 - val_accuracy: 0.7780 - val_loss: 0.4653\n",
      "Epoch 47/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.7825 - loss: 0.4691 - val_accuracy: 0.7786 - val_loss: 0.4651\n",
      "Epoch 48/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - accuracy: 0.7807 - loss: 0.4581 - val_accuracy: 0.7780 - val_loss: 0.4653\n",
      "Epoch 49/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - accuracy: 0.7732 - loss: 0.4706 - val_accuracy: 0.7757 - val_loss: 0.4658\n",
      "Epoch 50/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step - accuracy: 0.7811 - loss: 0.4630 - val_accuracy: 0.7763 - val_loss: 0.4658\n",
      "Epoch 51/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - accuracy: 0.7840 - loss: 0.4611 - val_accuracy: 0.7775 - val_loss: 0.4653\n",
      "Epoch 52/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.7871 - loss: 0.4552 - val_accuracy: 0.7792 - val_loss: 0.4651\n",
      "Epoch 53/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - accuracy: 0.7763 - loss: 0.4692 - val_accuracy: 0.7786 - val_loss: 0.4655\n",
      "Epoch 54/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430us/step - accuracy: 0.7881 - loss: 0.4683 - val_accuracy: 0.7775 - val_loss: 0.4649\n",
      "Epoch 55/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547us/step - accuracy: 0.7843 - loss: 0.4550 - val_accuracy: 0.7780 - val_loss: 0.4643\n",
      "Epoch 56/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7790 - loss: 0.4607 - val_accuracy: 0.7780 - val_loss: 0.4640\n",
      "Epoch 57/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - accuracy: 0.7866 - loss: 0.4589 - val_accuracy: 0.7780 - val_loss: 0.4641\n",
      "Epoch 58/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.7774 - loss: 0.4685 - val_accuracy: 0.7798 - val_loss: 0.4640\n",
      "Epoch 59/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.7755 - loss: 0.4655 - val_accuracy: 0.7786 - val_loss: 0.4640\n",
      "Epoch 60/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7861 - loss: 0.4605 - val_accuracy: 0.7786 - val_loss: 0.4641\n",
      "Epoch 61/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - accuracy: 0.7936 - loss: 0.4496 - val_accuracy: 0.7798 - val_loss: 0.4640\n",
      "Epoch 62/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.7862 - loss: 0.4555 - val_accuracy: 0.7780 - val_loss: 0.4640\n",
      "Epoch 63/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7836 - loss: 0.4655 - val_accuracy: 0.7786 - val_loss: 0.4638\n",
      "Epoch 64/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - accuracy: 0.7882 - loss: 0.4548 - val_accuracy: 0.7786 - val_loss: 0.4637\n",
      "Epoch 65/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7841 - loss: 0.4607 - val_accuracy: 0.7803 - val_loss: 0.4640\n",
      "Epoch 66/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step - accuracy: 0.7870 - loss: 0.4619 - val_accuracy: 0.7798 - val_loss: 0.4639\n",
      "Epoch 67/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - accuracy: 0.7705 - loss: 0.4657 - val_accuracy: 0.7803 - val_loss: 0.4636\n",
      "Epoch 68/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.7927 - loss: 0.4567 - val_accuracy: 0.7786 - val_loss: 0.4637\n",
      "Epoch 69/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - accuracy: 0.8037 - loss: 0.4329 - val_accuracy: 0.7775 - val_loss: 0.4633\n",
      "Epoch 70/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413us/step - accuracy: 0.7899 - loss: 0.4569 - val_accuracy: 0.7775 - val_loss: 0.4632\n",
      "Epoch 71/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - accuracy: 0.7768 - loss: 0.4624 - val_accuracy: 0.7786 - val_loss: 0.4633\n",
      "Epoch 72/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - accuracy: 0.7925 - loss: 0.4547 - val_accuracy: 0.7786 - val_loss: 0.4630\n",
      "Epoch 73/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - accuracy: 0.7906 - loss: 0.4522 - val_accuracy: 0.7780 - val_loss: 0.4630\n",
      "Epoch 74/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - accuracy: 0.7847 - loss: 0.4638 - val_accuracy: 0.7786 - val_loss: 0.4632\n",
      "Epoch 75/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.7822 - loss: 0.4598 - val_accuracy: 0.7792 - val_loss: 0.4630\n",
      "Epoch 76/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - accuracy: 0.7892 - loss: 0.4471 - val_accuracy: 0.7780 - val_loss: 0.4628\n",
      "Epoch 77/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - accuracy: 0.7910 - loss: 0.4490 - val_accuracy: 0.7775 - val_loss: 0.4631\n",
      "Epoch 78/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.7932 - loss: 0.4586 - val_accuracy: 0.7775 - val_loss: 0.4628\n",
      "Epoch 79/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - accuracy: 0.7863 - loss: 0.4525 - val_accuracy: 0.7769 - val_loss: 0.4628\n",
      "Epoch 80/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7825 - loss: 0.4646 - val_accuracy: 0.7786 - val_loss: 0.4631\n",
      "Epoch 81/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7792 - loss: 0.4617 - val_accuracy: 0.7786 - val_loss: 0.4632\n",
      "Epoch 82/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - accuracy: 0.7870 - loss: 0.4539 - val_accuracy: 0.7775 - val_loss: 0.4630\n",
      "Epoch 83/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - accuracy: 0.7935 - loss: 0.4399 - val_accuracy: 0.7775 - val_loss: 0.4625\n",
      "Epoch 84/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - accuracy: 0.7884 - loss: 0.4450 - val_accuracy: 0.7786 - val_loss: 0.4624\n",
      "Epoch 85/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - accuracy: 0.7905 - loss: 0.4559 - val_accuracy: 0.7775 - val_loss: 0.4626\n",
      "Epoch 86/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7875 - loss: 0.4546 - val_accuracy: 0.7786 - val_loss: 0.4626\n",
      "Epoch 87/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - accuracy: 0.7854 - loss: 0.4539 - val_accuracy: 0.7780 - val_loss: 0.4624\n",
      "Epoch 88/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7873 - loss: 0.4520 - val_accuracy: 0.7792 - val_loss: 0.4627\n",
      "Epoch 89/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - accuracy: 0.7909 - loss: 0.4492 - val_accuracy: 0.7786 - val_loss: 0.4626\n",
      "Epoch 90/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - accuracy: 0.7838 - loss: 0.4492 - val_accuracy: 0.7786 - val_loss: 0.4625\n",
      "Epoch 91/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420us/step - accuracy: 0.7911 - loss: 0.4526 - val_accuracy: 0.7798 - val_loss: 0.4624\n",
      "Epoch 92/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414us/step - accuracy: 0.7978 - loss: 0.4395 - val_accuracy: 0.7786 - val_loss: 0.4623\n",
      "Epoch 93/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416us/step - accuracy: 0.7791 - loss: 0.4594 - val_accuracy: 0.7798 - val_loss: 0.4624\n",
      "Epoch 94/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - accuracy: 0.7818 - loss: 0.4525 - val_accuracy: 0.7786 - val_loss: 0.4624\n",
      "Epoch 95/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - accuracy: 0.7880 - loss: 0.4477 - val_accuracy: 0.7792 - val_loss: 0.4620\n",
      "Epoch 96/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.7847 - loss: 0.4608 - val_accuracy: 0.7786 - val_loss: 0.4621\n",
      "Epoch 97/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - accuracy: 0.7869 - loss: 0.4569 - val_accuracy: 0.7780 - val_loss: 0.4623\n",
      "Epoch 98/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - accuracy: 0.7807 - loss: 0.4663 - val_accuracy: 0.7775 - val_loss: 0.4622\n",
      "Epoch 99/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - accuracy: 0.7864 - loss: 0.4493 - val_accuracy: 0.7780 - val_loss: 0.4618\n",
      "Epoch 100/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - accuracy: 0.7896 - loss: 0.4432 - val_accuracy: 0.7775 - val_loss: 0.4618\n",
      "Iteration 5 using SGD: Validation Accuracy = 0.7774583101272583\n",
      "Epoch 1/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635us/step - accuracy: 0.7281 - loss: 0.5306 - val_accuracy: 0.7763 - val_loss: 0.4603\n",
      "Epoch 2/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - accuracy: 0.7797 - loss: 0.4665 - val_accuracy: 0.7740 - val_loss: 0.4689\n",
      "Epoch 3/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - accuracy: 0.7716 - loss: 0.4698 - val_accuracy: 0.7723 - val_loss: 0.4710\n",
      "Epoch 4/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - accuracy: 0.8006 - loss: 0.4411 - val_accuracy: 0.7803 - val_loss: 0.4543\n",
      "Epoch 5/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - accuracy: 0.7950 - loss: 0.4408 - val_accuracy: 0.7803 - val_loss: 0.4609\n",
      "Epoch 6/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - accuracy: 0.7981 - loss: 0.4369 - val_accuracy: 0.7821 - val_loss: 0.4499\n",
      "Epoch 7/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.7970 - loss: 0.4306 - val_accuracy: 0.7844 - val_loss: 0.4475\n",
      "Epoch 8/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - accuracy: 0.8000 - loss: 0.4298 - val_accuracy: 0.7815 - val_loss: 0.4439\n",
      "Epoch 9/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - accuracy: 0.7953 - loss: 0.4296 - val_accuracy: 0.7792 - val_loss: 0.4442\n",
      "Epoch 10/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.7953 - loss: 0.4306 - val_accuracy: 0.7809 - val_loss: 0.4316\n",
      "Epoch 11/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - accuracy: 0.7901 - loss: 0.4339 - val_accuracy: 0.7809 - val_loss: 0.4298\n",
      "Epoch 12/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - accuracy: 0.7977 - loss: 0.4123 - val_accuracy: 0.7844 - val_loss: 0.4247\n",
      "Epoch 13/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - accuracy: 0.7922 - loss: 0.4226 - val_accuracy: 0.7832 - val_loss: 0.4362\n",
      "Epoch 14/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - accuracy: 0.8021 - loss: 0.4131 - val_accuracy: 0.7901 - val_loss: 0.4279\n",
      "Epoch 15/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - accuracy: 0.8020 - loss: 0.4111 - val_accuracy: 0.7803 - val_loss: 0.4288\n",
      "Epoch 16/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - accuracy: 0.8103 - loss: 0.4040 - val_accuracy: 0.7855 - val_loss: 0.4251\n",
      "Epoch 17/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - accuracy: 0.8075 - loss: 0.4050 - val_accuracy: 0.7901 - val_loss: 0.4248\n",
      "Epoch 18/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - accuracy: 0.7954 - loss: 0.4166 - val_accuracy: 0.7832 - val_loss: 0.4332\n",
      "Epoch 19/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - accuracy: 0.7963 - loss: 0.4142 - val_accuracy: 0.7953 - val_loss: 0.4229\n",
      "Epoch 20/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - accuracy: 0.8009 - loss: 0.4187 - val_accuracy: 0.7913 - val_loss: 0.4234\n",
      "Epoch 21/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.7982 - loss: 0.4155 - val_accuracy: 0.7861 - val_loss: 0.4268\n",
      "Epoch 22/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.7966 - loss: 0.4177 - val_accuracy: 0.7895 - val_loss: 0.4236\n",
      "Epoch 23/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - accuracy: 0.8108 - loss: 0.3982 - val_accuracy: 0.7832 - val_loss: 0.4233\n",
      "Epoch 24/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - accuracy: 0.8123 - loss: 0.4003 - val_accuracy: 0.7936 - val_loss: 0.4151\n",
      "Epoch 25/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - accuracy: 0.8097 - loss: 0.3942 - val_accuracy: 0.7890 - val_loss: 0.4161\n",
      "Epoch 26/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474us/step - accuracy: 0.8068 - loss: 0.4054 - val_accuracy: 0.7936 - val_loss: 0.4152\n",
      "Epoch 27/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - accuracy: 0.8052 - loss: 0.4050 - val_accuracy: 0.7861 - val_loss: 0.4240\n",
      "Epoch 28/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - accuracy: 0.8179 - loss: 0.3944 - val_accuracy: 0.7855 - val_loss: 0.4180\n",
      "Epoch 29/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.8146 - loss: 0.3912 - val_accuracy: 0.7832 - val_loss: 0.4253\n",
      "Epoch 30/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - accuracy: 0.8096 - loss: 0.3991 - val_accuracy: 0.7964 - val_loss: 0.4133\n",
      "Epoch 31/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - accuracy: 0.7936 - loss: 0.4181 - val_accuracy: 0.7936 - val_loss: 0.4198\n",
      "Epoch 32/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.8066 - loss: 0.3993 - val_accuracy: 0.7918 - val_loss: 0.4182\n",
      "Epoch 33/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - accuracy: 0.8047 - loss: 0.3982 - val_accuracy: 0.7867 - val_loss: 0.4218\n",
      "Epoch 34/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - accuracy: 0.8138 - loss: 0.3954 - val_accuracy: 0.7867 - val_loss: 0.4209\n",
      "Epoch 35/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.8072 - loss: 0.3987 - val_accuracy: 0.7999 - val_loss: 0.4163\n",
      "Epoch 36/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - accuracy: 0.8159 - loss: 0.3941 - val_accuracy: 0.7947 - val_loss: 0.4129\n",
      "Epoch 37/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - accuracy: 0.8104 - loss: 0.4025 - val_accuracy: 0.7930 - val_loss: 0.4172\n",
      "Epoch 38/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - accuracy: 0.8078 - loss: 0.4008 - val_accuracy: 0.7924 - val_loss: 0.4142\n",
      "Epoch 39/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - accuracy: 0.8065 - loss: 0.4011 - val_accuracy: 0.7913 - val_loss: 0.4211\n",
      "Epoch 40/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - accuracy: 0.8113 - loss: 0.3917 - val_accuracy: 0.7913 - val_loss: 0.4109\n",
      "Epoch 41/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - accuracy: 0.8113 - loss: 0.3967 - val_accuracy: 0.7918 - val_loss: 0.4150\n",
      "Epoch 42/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - accuracy: 0.8011 - loss: 0.4068 - val_accuracy: 0.7953 - val_loss: 0.4153\n",
      "Epoch 43/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - accuracy: 0.8072 - loss: 0.3940 - val_accuracy: 0.7901 - val_loss: 0.4185\n",
      "Epoch 44/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475us/step - accuracy: 0.8131 - loss: 0.3916 - val_accuracy: 0.7947 - val_loss: 0.4161\n",
      "Epoch 45/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473us/step - accuracy: 0.8193 - loss: 0.3855 - val_accuracy: 0.7924 - val_loss: 0.4093\n",
      "Epoch 46/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - accuracy: 0.8135 - loss: 0.3889 - val_accuracy: 0.7913 - val_loss: 0.4162\n",
      "Epoch 47/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - accuracy: 0.8104 - loss: 0.3911 - val_accuracy: 0.7867 - val_loss: 0.4198\n",
      "Epoch 48/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - accuracy: 0.8129 - loss: 0.3832 - val_accuracy: 0.7895 - val_loss: 0.4098\n",
      "Epoch 49/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - accuracy: 0.8010 - loss: 0.4064 - val_accuracy: 0.7970 - val_loss: 0.4158\n",
      "Epoch 50/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - accuracy: 0.8075 - loss: 0.3890 - val_accuracy: 0.7884 - val_loss: 0.4119\n",
      "Epoch 51/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - accuracy: 0.8139 - loss: 0.3910 - val_accuracy: 0.7936 - val_loss: 0.4083\n",
      "Epoch 52/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - accuracy: 0.8074 - loss: 0.3920 - val_accuracy: 0.7970 - val_loss: 0.4118\n",
      "Epoch 53/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - accuracy: 0.8086 - loss: 0.3907 - val_accuracy: 0.7936 - val_loss: 0.4073\n",
      "Epoch 54/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - accuracy: 0.8185 - loss: 0.3816 - val_accuracy: 0.7993 - val_loss: 0.4100\n",
      "Epoch 55/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473us/step - accuracy: 0.8066 - loss: 0.4037 - val_accuracy: 0.7976 - val_loss: 0.4149\n",
      "Epoch 56/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - accuracy: 0.8104 - loss: 0.3907 - val_accuracy: 0.7976 - val_loss: 0.4064\n",
      "Epoch 57/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - accuracy: 0.8262 - loss: 0.3771 - val_accuracy: 0.7953 - val_loss: 0.4108\n",
      "Epoch 58/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - accuracy: 0.8214 - loss: 0.3829 - val_accuracy: 0.7849 - val_loss: 0.4169\n",
      "Epoch 59/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - accuracy: 0.8192 - loss: 0.3809 - val_accuracy: 0.7936 - val_loss: 0.4143\n",
      "Epoch 60/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step - accuracy: 0.8147 - loss: 0.3893 - val_accuracy: 0.8010 - val_loss: 0.4106\n",
      "Epoch 61/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - accuracy: 0.8085 - loss: 0.3940 - val_accuracy: 0.7901 - val_loss: 0.4152\n",
      "Epoch 62/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - accuracy: 0.8148 - loss: 0.3878 - val_accuracy: 0.7987 - val_loss: 0.4126\n",
      "Epoch 63/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - accuracy: 0.8246 - loss: 0.3818 - val_accuracy: 0.7987 - val_loss: 0.4227\n",
      "Epoch 64/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474us/step - accuracy: 0.8130 - loss: 0.3782 - val_accuracy: 0.7941 - val_loss: 0.4161\n",
      "Epoch 65/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574us/step - accuracy: 0.8156 - loss: 0.3874 - val_accuracy: 0.7947 - val_loss: 0.4148\n",
      "Epoch 66/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - accuracy: 0.8111 - loss: 0.3898 - val_accuracy: 0.7930 - val_loss: 0.4140\n",
      "Iteration 6 using ADAM: Validation Accuracy = 0.7975848317146301\n",
      "Epoch 1/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - accuracy: 0.5675 - loss: 0.6797 - val_accuracy: 0.6820 - val_loss: 0.6074\n",
      "Epoch 2/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step - accuracy: 0.6529 - loss: 0.6250 - val_accuracy: 0.7355 - val_loss: 0.5681\n",
      "Epoch 3/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - accuracy: 0.7030 - loss: 0.5816 - val_accuracy: 0.7470 - val_loss: 0.5421\n",
      "Epoch 4/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - accuracy: 0.7223 - loss: 0.5640 - val_accuracy: 0.7585 - val_loss: 0.5234\n",
      "Epoch 5/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - accuracy: 0.7216 - loss: 0.5561 - val_accuracy: 0.7677 - val_loss: 0.5097\n",
      "Epoch 6/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.7363 - loss: 0.5298 - val_accuracy: 0.7688 - val_loss: 0.5001\n",
      "Epoch 7/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - accuracy: 0.7510 - loss: 0.5263 - val_accuracy: 0.7706 - val_loss: 0.4929\n",
      "Epoch 8/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - accuracy: 0.7617 - loss: 0.5095 - val_accuracy: 0.7717 - val_loss: 0.4875\n",
      "Epoch 9/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419us/step - accuracy: 0.7645 - loss: 0.4986 - val_accuracy: 0.7717 - val_loss: 0.4838\n",
      "Epoch 10/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - accuracy: 0.7596 - loss: 0.5040 - val_accuracy: 0.7700 - val_loss: 0.4807\n",
      "Epoch 11/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - accuracy: 0.7645 - loss: 0.4922 - val_accuracy: 0.7683 - val_loss: 0.4785\n",
      "Epoch 12/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.7660 - loss: 0.4878 - val_accuracy: 0.7683 - val_loss: 0.4764\n",
      "Epoch 13/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - accuracy: 0.7744 - loss: 0.4854 - val_accuracy: 0.7706 - val_loss: 0.4753\n",
      "Epoch 14/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - accuracy: 0.7740 - loss: 0.4857 - val_accuracy: 0.7723 - val_loss: 0.4746\n",
      "Epoch 15/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - accuracy: 0.7789 - loss: 0.4779 - val_accuracy: 0.7700 - val_loss: 0.4732\n",
      "Epoch 16/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step - accuracy: 0.7741 - loss: 0.4864 - val_accuracy: 0.7688 - val_loss: 0.4728\n",
      "Epoch 17/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - accuracy: 0.7822 - loss: 0.4727 - val_accuracy: 0.7688 - val_loss: 0.4726\n",
      "Epoch 18/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - accuracy: 0.7773 - loss: 0.4830 - val_accuracy: 0.7700 - val_loss: 0.4718\n",
      "Epoch 19/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.7763 - loss: 0.4719 - val_accuracy: 0.7706 - val_loss: 0.4712\n",
      "Epoch 20/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - accuracy: 0.7896 - loss: 0.4648 - val_accuracy: 0.7706 - val_loss: 0.4713\n",
      "Epoch 21/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - accuracy: 0.7726 - loss: 0.4885 - val_accuracy: 0.7700 - val_loss: 0.4704\n",
      "Epoch 22/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - accuracy: 0.7753 - loss: 0.4791 - val_accuracy: 0.7723 - val_loss: 0.4698\n",
      "Epoch 23/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.7685 - loss: 0.4787 - val_accuracy: 0.7734 - val_loss: 0.4693\n",
      "Epoch 24/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - accuracy: 0.7899 - loss: 0.4693 - val_accuracy: 0.7729 - val_loss: 0.4690\n",
      "Epoch 25/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - accuracy: 0.7880 - loss: 0.4667 - val_accuracy: 0.7717 - val_loss: 0.4689\n",
      "Epoch 26/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.7774 - loss: 0.4744 - val_accuracy: 0.7734 - val_loss: 0.4689\n",
      "Epoch 27/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - accuracy: 0.7836 - loss: 0.4649 - val_accuracy: 0.7734 - val_loss: 0.4688\n",
      "Epoch 28/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7841 - loss: 0.4658 - val_accuracy: 0.7734 - val_loss: 0.4680\n",
      "Epoch 29/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - accuracy: 0.7897 - loss: 0.4692 - val_accuracy: 0.7757 - val_loss: 0.4676\n",
      "Epoch 30/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - accuracy: 0.7818 - loss: 0.4683 - val_accuracy: 0.7757 - val_loss: 0.4671\n",
      "Epoch 31/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - accuracy: 0.7746 - loss: 0.4810 - val_accuracy: 0.7763 - val_loss: 0.4672\n",
      "Epoch 32/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.7826 - loss: 0.4676 - val_accuracy: 0.7740 - val_loss: 0.4667\n",
      "Epoch 33/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7816 - loss: 0.4696 - val_accuracy: 0.7740 - val_loss: 0.4665\n",
      "Epoch 34/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - accuracy: 0.7697 - loss: 0.4777 - val_accuracy: 0.7746 - val_loss: 0.4664\n",
      "Epoch 35/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - accuracy: 0.7876 - loss: 0.4594 - val_accuracy: 0.7746 - val_loss: 0.4661\n",
      "Epoch 36/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.7836 - loss: 0.4617 - val_accuracy: 0.7734 - val_loss: 0.4658\n",
      "Epoch 37/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - accuracy: 0.7812 - loss: 0.4695 - val_accuracy: 0.7734 - val_loss: 0.4654\n",
      "Epoch 38/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7831 - loss: 0.4663 - val_accuracy: 0.7734 - val_loss: 0.4655\n",
      "Epoch 39/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - accuracy: 0.7733 - loss: 0.4778 - val_accuracy: 0.7729 - val_loss: 0.4647\n",
      "Epoch 40/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376us/step - accuracy: 0.7975 - loss: 0.4479 - val_accuracy: 0.7734 - val_loss: 0.4647\n",
      "Epoch 41/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - accuracy: 0.7839 - loss: 0.4602 - val_accuracy: 0.7740 - val_loss: 0.4647\n",
      "Epoch 42/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.7817 - loss: 0.4687 - val_accuracy: 0.7740 - val_loss: 0.4648\n",
      "Epoch 43/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.7819 - loss: 0.4626 - val_accuracy: 0.7752 - val_loss: 0.4646\n",
      "Epoch 44/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.7762 - loss: 0.4661 - val_accuracy: 0.7763 - val_loss: 0.4646\n",
      "Epoch 45/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.7748 - loss: 0.4797 - val_accuracy: 0.7769 - val_loss: 0.4642\n",
      "Epoch 46/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - accuracy: 0.7857 - loss: 0.4539 - val_accuracy: 0.7746 - val_loss: 0.4640\n",
      "Epoch 47/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - accuracy: 0.7865 - loss: 0.4577 - val_accuracy: 0.7752 - val_loss: 0.4643\n",
      "Epoch 48/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - accuracy: 0.7824 - loss: 0.4608 - val_accuracy: 0.7734 - val_loss: 0.4642\n",
      "Epoch 49/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.7839 - loss: 0.4565 - val_accuracy: 0.7752 - val_loss: 0.4639\n",
      "Epoch 50/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7799 - loss: 0.4623 - val_accuracy: 0.7746 - val_loss: 0.4641\n",
      "Epoch 51/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - accuracy: 0.7859 - loss: 0.4578 - val_accuracy: 0.7757 - val_loss: 0.4639\n",
      "Epoch 52/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422us/step - accuracy: 0.7966 - loss: 0.4505 - val_accuracy: 0.7752 - val_loss: 0.4640\n",
      "Epoch 53/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - accuracy: 0.7896 - loss: 0.4524 - val_accuracy: 0.7763 - val_loss: 0.4637\n",
      "Epoch 54/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7802 - loss: 0.4572 - val_accuracy: 0.7752 - val_loss: 0.4633\n",
      "Epoch 55/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - accuracy: 0.7879 - loss: 0.4422 - val_accuracy: 0.7763 - val_loss: 0.4633\n",
      "Epoch 56/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - accuracy: 0.7864 - loss: 0.4606 - val_accuracy: 0.7763 - val_loss: 0.4632\n",
      "Epoch 57/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.7875 - loss: 0.4530 - val_accuracy: 0.7757 - val_loss: 0.4633\n",
      "Epoch 58/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - accuracy: 0.7891 - loss: 0.4520 - val_accuracy: 0.7752 - val_loss: 0.4631\n",
      "Epoch 59/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.7873 - loss: 0.4573 - val_accuracy: 0.7757 - val_loss: 0.4633\n",
      "Epoch 60/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - accuracy: 0.7865 - loss: 0.4508 - val_accuracy: 0.7780 - val_loss: 0.4629\n",
      "Epoch 61/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.7896 - loss: 0.4563 - val_accuracy: 0.7763 - val_loss: 0.4628\n",
      "Epoch 62/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422us/step - accuracy: 0.7764 - loss: 0.4703 - val_accuracy: 0.7780 - val_loss: 0.4633\n",
      "Epoch 63/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - accuracy: 0.7844 - loss: 0.4570 - val_accuracy: 0.7780 - val_loss: 0.4634\n",
      "Epoch 64/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419us/step - accuracy: 0.7952 - loss: 0.4431 - val_accuracy: 0.7780 - val_loss: 0.4628\n",
      "Epoch 65/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - accuracy: 0.7824 - loss: 0.4626 - val_accuracy: 0.7775 - val_loss: 0.4628\n",
      "Epoch 66/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - accuracy: 0.7856 - loss: 0.4548 - val_accuracy: 0.7763 - val_loss: 0.4624\n",
      "Epoch 67/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428us/step - accuracy: 0.7913 - loss: 0.4517 - val_accuracy: 0.7775 - val_loss: 0.4626\n",
      "Epoch 68/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475us/step - accuracy: 0.7884 - loss: 0.4523 - val_accuracy: 0.7769 - val_loss: 0.4626\n",
      "Epoch 69/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.7856 - loss: 0.4609 - val_accuracy: 0.7775 - val_loss: 0.4628\n",
      "Epoch 70/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - accuracy: 0.7940 - loss: 0.4542 - val_accuracy: 0.7769 - val_loss: 0.4627\n",
      "Epoch 71/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7914 - loss: 0.4532 - val_accuracy: 0.7775 - val_loss: 0.4629\n",
      "Epoch 72/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - accuracy: 0.7830 - loss: 0.4549 - val_accuracy: 0.7786 - val_loss: 0.4631\n",
      "Epoch 73/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - accuracy: 0.7849 - loss: 0.4503 - val_accuracy: 0.7780 - val_loss: 0.4630\n",
      "Epoch 74/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - accuracy: 0.7918 - loss: 0.4455 - val_accuracy: 0.7780 - val_loss: 0.4628\n",
      "Epoch 75/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - accuracy: 0.7917 - loss: 0.4505 - val_accuracy: 0.7769 - val_loss: 0.4624\n",
      "Epoch 76/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - accuracy: 0.7870 - loss: 0.4558 - val_accuracy: 0.7775 - val_loss: 0.4625\n",
      "Iteration 7 using SGD: Validation Accuracy = 0.7763082385063171\n",
      "Epoch 1/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 602us/step - accuracy: 0.7252 - loss: 0.5374 - val_accuracy: 0.7740 - val_loss: 0.4649\n",
      "Epoch 2/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - accuracy: 0.7892 - loss: 0.4596 - val_accuracy: 0.7608 - val_loss: 0.4705\n",
      "Epoch 3/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.7860 - loss: 0.4500 - val_accuracy: 0.7763 - val_loss: 0.4610\n",
      "Epoch 4/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - accuracy: 0.7903 - loss: 0.4498 - val_accuracy: 0.7740 - val_loss: 0.4656\n",
      "Epoch 5/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.7918 - loss: 0.4513 - val_accuracy: 0.7798 - val_loss: 0.4574\n",
      "Epoch 6/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - accuracy: 0.7970 - loss: 0.4463 - val_accuracy: 0.7769 - val_loss: 0.4573\n",
      "Epoch 7/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - accuracy: 0.7830 - loss: 0.4481 - val_accuracy: 0.7671 - val_loss: 0.4643\n",
      "Epoch 8/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - accuracy: 0.8013 - loss: 0.4259 - val_accuracy: 0.7803 - val_loss: 0.4430\n",
      "Epoch 9/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - accuracy: 0.7948 - loss: 0.4354 - val_accuracy: 0.7838 - val_loss: 0.4407\n",
      "Epoch 10/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step - accuracy: 0.7915 - loss: 0.4314 - val_accuracy: 0.7792 - val_loss: 0.4593\n",
      "Epoch 11/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step - accuracy: 0.7958 - loss: 0.4275 - val_accuracy: 0.7798 - val_loss: 0.4334\n",
      "Epoch 12/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - accuracy: 0.7886 - loss: 0.4318 - val_accuracy: 0.7780 - val_loss: 0.4484\n",
      "Epoch 13/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - accuracy: 0.7966 - loss: 0.4240 - val_accuracy: 0.7838 - val_loss: 0.4346\n",
      "Epoch 14/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.7974 - loss: 0.4135 - val_accuracy: 0.7780 - val_loss: 0.4291\n",
      "Epoch 15/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - accuracy: 0.7926 - loss: 0.4224 - val_accuracy: 0.7884 - val_loss: 0.4262\n",
      "Epoch 16/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - accuracy: 0.7948 - loss: 0.4232 - val_accuracy: 0.7803 - val_loss: 0.4345\n",
      "Epoch 17/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step - accuracy: 0.7942 - loss: 0.4201 - val_accuracy: 0.7901 - val_loss: 0.4226\n",
      "Epoch 18/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - accuracy: 0.8088 - loss: 0.4077 - val_accuracy: 0.7832 - val_loss: 0.4260\n",
      "Epoch 19/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - accuracy: 0.8021 - loss: 0.4136 - val_accuracy: 0.7815 - val_loss: 0.4366\n",
      "Epoch 20/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - accuracy: 0.8118 - loss: 0.4032 - val_accuracy: 0.7815 - val_loss: 0.4287\n",
      "Epoch 21/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - accuracy: 0.8067 - loss: 0.4019 - val_accuracy: 0.7867 - val_loss: 0.4263\n",
      "Epoch 22/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - accuracy: 0.8094 - loss: 0.4052 - val_accuracy: 0.7815 - val_loss: 0.4278\n",
      "Epoch 23/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - accuracy: 0.8014 - loss: 0.4059 - val_accuracy: 0.7987 - val_loss: 0.4151\n",
      "Epoch 24/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - accuracy: 0.8068 - loss: 0.3937 - val_accuracy: 0.7890 - val_loss: 0.4179\n",
      "Epoch 25/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - accuracy: 0.8072 - loss: 0.4048 - val_accuracy: 0.7907 - val_loss: 0.4213\n",
      "Epoch 26/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - accuracy: 0.8061 - loss: 0.3981 - val_accuracy: 0.7895 - val_loss: 0.4171\n",
      "Epoch 27/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - accuracy: 0.8068 - loss: 0.4032 - val_accuracy: 0.7890 - val_loss: 0.4309\n",
      "Epoch 28/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - accuracy: 0.8092 - loss: 0.3963 - val_accuracy: 0.7838 - val_loss: 0.4285\n",
      "Epoch 29/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - accuracy: 0.8032 - loss: 0.3959 - val_accuracy: 0.7878 - val_loss: 0.4252\n",
      "Epoch 30/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - accuracy: 0.8075 - loss: 0.4026 - val_accuracy: 0.7947 - val_loss: 0.4184\n",
      "Epoch 31/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - accuracy: 0.8162 - loss: 0.3931 - val_accuracy: 0.7884 - val_loss: 0.4167\n",
      "Epoch 32/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - accuracy: 0.8082 - loss: 0.4085 - val_accuracy: 0.7878 - val_loss: 0.4195\n",
      "Epoch 33/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - accuracy: 0.8046 - loss: 0.4011 - val_accuracy: 0.7895 - val_loss: 0.4182\n",
      "Iteration 8 using ADAM: Validation Accuracy = 0.7987349033355713\n",
      "New best model found and saved.\n",
      "Epoch 1/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543us/step - accuracy: 0.5428 - loss: 0.7083 - val_accuracy: 0.7067 - val_loss: 0.6156\n",
      "Epoch 2/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - accuracy: 0.6413 - loss: 0.6332 - val_accuracy: 0.7476 - val_loss: 0.5686\n",
      "Epoch 3/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - accuracy: 0.6864 - loss: 0.5895 - val_accuracy: 0.7568 - val_loss: 0.5390\n",
      "Epoch 4/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.7267 - loss: 0.5584 - val_accuracy: 0.7591 - val_loss: 0.5188\n",
      "Epoch 5/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - accuracy: 0.7414 - loss: 0.5390 - val_accuracy: 0.7642 - val_loss: 0.5047\n",
      "Epoch 6/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step - accuracy: 0.7519 - loss: 0.5306 - val_accuracy: 0.7671 - val_loss: 0.4954\n",
      "Epoch 7/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.7583 - loss: 0.5079 - val_accuracy: 0.7694 - val_loss: 0.4886\n",
      "Epoch 8/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - accuracy: 0.7608 - loss: 0.5105 - val_accuracy: 0.7683 - val_loss: 0.4844\n",
      "Epoch 9/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - accuracy: 0.7683 - loss: 0.4918 - val_accuracy: 0.7665 - val_loss: 0.4812\n",
      "Epoch 10/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - accuracy: 0.7508 - loss: 0.5077 - val_accuracy: 0.7671 - val_loss: 0.4784\n",
      "Epoch 11/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - accuracy: 0.7740 - loss: 0.4796 - val_accuracy: 0.7648 - val_loss: 0.4768\n",
      "Epoch 12/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420us/step - accuracy: 0.7693 - loss: 0.4947 - val_accuracy: 0.7671 - val_loss: 0.4751\n",
      "Epoch 13/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step - accuracy: 0.7772 - loss: 0.4743 - val_accuracy: 0.7683 - val_loss: 0.4734\n",
      "Epoch 14/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - accuracy: 0.7702 - loss: 0.4906 - val_accuracy: 0.7688 - val_loss: 0.4727\n",
      "Epoch 15/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - accuracy: 0.7803 - loss: 0.4766 - val_accuracy: 0.7706 - val_loss: 0.4714\n",
      "Epoch 16/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.7698 - loss: 0.4872 - val_accuracy: 0.7700 - val_loss: 0.4709\n",
      "Epoch 17/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - accuracy: 0.7737 - loss: 0.4801 - val_accuracy: 0.7694 - val_loss: 0.4704\n",
      "Epoch 18/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - accuracy: 0.7814 - loss: 0.4722 - val_accuracy: 0.7688 - val_loss: 0.4697\n",
      "Epoch 19/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - accuracy: 0.7834 - loss: 0.4750 - val_accuracy: 0.7706 - val_loss: 0.4691\n",
      "Epoch 20/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422us/step - accuracy: 0.7730 - loss: 0.4793 - val_accuracy: 0.7706 - val_loss: 0.4688\n",
      "Epoch 21/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - accuracy: 0.7787 - loss: 0.4720 - val_accuracy: 0.7711 - val_loss: 0.4685\n",
      "Epoch 22/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step - accuracy: 0.7754 - loss: 0.4792 - val_accuracy: 0.7711 - val_loss: 0.4682\n",
      "Epoch 23/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7764 - loss: 0.4747 - val_accuracy: 0.7717 - val_loss: 0.4677\n",
      "Epoch 24/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - accuracy: 0.7747 - loss: 0.4830 - val_accuracy: 0.7717 - val_loss: 0.4673\n",
      "Epoch 25/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - accuracy: 0.7703 - loss: 0.4705 - val_accuracy: 0.7740 - val_loss: 0.4672\n",
      "Epoch 26/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - accuracy: 0.7752 - loss: 0.4672 - val_accuracy: 0.7717 - val_loss: 0.4668\n",
      "Epoch 27/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.7836 - loss: 0.4567 - val_accuracy: 0.7734 - val_loss: 0.4665\n",
      "Epoch 28/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.7718 - loss: 0.4819 - val_accuracy: 0.7734 - val_loss: 0.4660\n",
      "Epoch 29/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - accuracy: 0.7910 - loss: 0.4615 - val_accuracy: 0.7752 - val_loss: 0.4662\n",
      "Epoch 30/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - accuracy: 0.7830 - loss: 0.4742 - val_accuracy: 0.7752 - val_loss: 0.4659\n",
      "Epoch 31/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.7881 - loss: 0.4613 - val_accuracy: 0.7757 - val_loss: 0.4654\n",
      "Epoch 32/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7768 - loss: 0.4701 - val_accuracy: 0.7757 - val_loss: 0.4655\n",
      "Epoch 33/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - accuracy: 0.7883 - loss: 0.4606 - val_accuracy: 0.7757 - val_loss: 0.4652\n",
      "Epoch 34/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421us/step - accuracy: 0.7866 - loss: 0.4590 - val_accuracy: 0.7752 - val_loss: 0.4648\n",
      "Epoch 35/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - accuracy: 0.7809 - loss: 0.4657 - val_accuracy: 0.7769 - val_loss: 0.4649\n",
      "Epoch 36/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - accuracy: 0.7860 - loss: 0.4663 - val_accuracy: 0.7757 - val_loss: 0.4648\n",
      "Epoch 37/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - accuracy: 0.7832 - loss: 0.4624 - val_accuracy: 0.7763 - val_loss: 0.4644\n",
      "Epoch 38/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - accuracy: 0.7802 - loss: 0.4652 - val_accuracy: 0.7769 - val_loss: 0.4641\n",
      "Epoch 39/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step - accuracy: 0.7893 - loss: 0.4612 - val_accuracy: 0.7763 - val_loss: 0.4641\n",
      "Epoch 40/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7760 - loss: 0.4653 - val_accuracy: 0.7803 - val_loss: 0.4637\n",
      "Epoch 41/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step - accuracy: 0.7860 - loss: 0.4543 - val_accuracy: 0.7792 - val_loss: 0.4638\n",
      "Epoch 42/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - accuracy: 0.7935 - loss: 0.4477 - val_accuracy: 0.7752 - val_loss: 0.4639\n",
      "Epoch 43/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.7894 - loss: 0.4548 - val_accuracy: 0.7740 - val_loss: 0.4637\n",
      "Epoch 44/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.7849 - loss: 0.4592 - val_accuracy: 0.7763 - val_loss: 0.4636\n",
      "Epoch 45/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.7910 - loss: 0.4559 - val_accuracy: 0.7763 - val_loss: 0.4636\n",
      "Epoch 46/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - accuracy: 0.7859 - loss: 0.4572 - val_accuracy: 0.7769 - val_loss: 0.4639\n",
      "Epoch 47/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - accuracy: 0.7846 - loss: 0.4601 - val_accuracy: 0.7757 - val_loss: 0.4635\n",
      "Epoch 48/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.7805 - loss: 0.4714 - val_accuracy: 0.7780 - val_loss: 0.4634\n",
      "Epoch 49/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - accuracy: 0.7872 - loss: 0.4636 - val_accuracy: 0.7780 - val_loss: 0.4630\n",
      "Epoch 50/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - accuracy: 0.7938 - loss: 0.4482 - val_accuracy: 0.7769 - val_loss: 0.4627\n",
      "Epoch 51/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - accuracy: 0.7785 - loss: 0.4607 - val_accuracy: 0.7780 - val_loss: 0.4626\n",
      "Epoch 52/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7909 - loss: 0.4461 - val_accuracy: 0.7786 - val_loss: 0.4624\n",
      "Epoch 53/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7864 - loss: 0.4509 - val_accuracy: 0.7780 - val_loss: 0.4624\n",
      "Epoch 54/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step - accuracy: 0.7892 - loss: 0.4528 - val_accuracy: 0.7780 - val_loss: 0.4623\n",
      "Epoch 55/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - accuracy: 0.7871 - loss: 0.4558 - val_accuracy: 0.7775 - val_loss: 0.4626\n",
      "Epoch 56/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - accuracy: 0.7853 - loss: 0.4529 - val_accuracy: 0.7780 - val_loss: 0.4622\n",
      "Epoch 57/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.7856 - loss: 0.4534 - val_accuracy: 0.7775 - val_loss: 0.4620\n",
      "Epoch 58/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473us/step - accuracy: 0.7965 - loss: 0.4454 - val_accuracy: 0.7786 - val_loss: 0.4618\n",
      "Epoch 59/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - accuracy: 0.7946 - loss: 0.4452 - val_accuracy: 0.7792 - val_loss: 0.4619\n",
      "Epoch 60/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.7964 - loss: 0.4395 - val_accuracy: 0.7798 - val_loss: 0.4620\n",
      "Epoch 61/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - accuracy: 0.7807 - loss: 0.4571 - val_accuracy: 0.7780 - val_loss: 0.4617\n",
      "Epoch 62/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - accuracy: 0.7918 - loss: 0.4403 - val_accuracy: 0.7780 - val_loss: 0.4617\n",
      "Epoch 63/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - accuracy: 0.7844 - loss: 0.4594 - val_accuracy: 0.7798 - val_loss: 0.4620\n",
      "Epoch 64/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - accuracy: 0.7931 - loss: 0.4446 - val_accuracy: 0.7809 - val_loss: 0.4622\n",
      "Epoch 65/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.7888 - loss: 0.4519 - val_accuracy: 0.7809 - val_loss: 0.4620\n",
      "Epoch 66/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.7967 - loss: 0.4510 - val_accuracy: 0.7821 - val_loss: 0.4620\n",
      "Epoch 67/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - accuracy: 0.7916 - loss: 0.4572 - val_accuracy: 0.7803 - val_loss: 0.4616\n",
      "Epoch 68/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - accuracy: 0.7854 - loss: 0.4559 - val_accuracy: 0.7803 - val_loss: 0.4616\n",
      "Epoch 69/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.7911 - loss: 0.4477 - val_accuracy: 0.7809 - val_loss: 0.4615\n",
      "Epoch 70/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.7981 - loss: 0.4384 - val_accuracy: 0.7815 - val_loss: 0.4617\n",
      "Epoch 71/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.7903 - loss: 0.4526 - val_accuracy: 0.7803 - val_loss: 0.4618\n",
      "Epoch 72/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - accuracy: 0.7891 - loss: 0.4510 - val_accuracy: 0.7792 - val_loss: 0.4616\n",
      "Epoch 73/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.7870 - loss: 0.4579 - val_accuracy: 0.7803 - val_loss: 0.4614\n",
      "Epoch 74/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - accuracy: 0.7922 - loss: 0.4444 - val_accuracy: 0.7803 - val_loss: 0.4613\n",
      "Epoch 75/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - accuracy: 0.7831 - loss: 0.4680 - val_accuracy: 0.7809 - val_loss: 0.4614\n",
      "Epoch 76/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7802 - loss: 0.4623 - val_accuracy: 0.7798 - val_loss: 0.4613\n",
      "Epoch 77/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - accuracy: 0.7909 - loss: 0.4540 - val_accuracy: 0.7815 - val_loss: 0.4613\n",
      "Epoch 78/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.7845 - loss: 0.4539 - val_accuracy: 0.7798 - val_loss: 0.4611\n",
      "Epoch 79/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - accuracy: 0.7905 - loss: 0.4542 - val_accuracy: 0.7803 - val_loss: 0.4609\n",
      "Epoch 80/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - accuracy: 0.7893 - loss: 0.4481 - val_accuracy: 0.7809 - val_loss: 0.4612\n",
      "Epoch 81/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - accuracy: 0.7814 - loss: 0.4600 - val_accuracy: 0.7809 - val_loss: 0.4611\n",
      "Epoch 82/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7847 - loss: 0.4552 - val_accuracy: 0.7803 - val_loss: 0.4613\n",
      "Epoch 83/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.7922 - loss: 0.4521 - val_accuracy: 0.7798 - val_loss: 0.4614\n",
      "Epoch 84/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - accuracy: 0.7882 - loss: 0.4577 - val_accuracy: 0.7803 - val_loss: 0.4612\n",
      "Epoch 85/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - accuracy: 0.7857 - loss: 0.4642 - val_accuracy: 0.7798 - val_loss: 0.4612\n",
      "Epoch 86/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - accuracy: 0.7962 - loss: 0.4476 - val_accuracy: 0.7798 - val_loss: 0.4614\n",
      "Epoch 87/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371us/step - accuracy: 0.7851 - loss: 0.4570 - val_accuracy: 0.7803 - val_loss: 0.4614\n",
      "Epoch 88/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - accuracy: 0.7878 - loss: 0.4524 - val_accuracy: 0.7798 - val_loss: 0.4614\n",
      "Epoch 89/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374us/step - accuracy: 0.7898 - loss: 0.4468 - val_accuracy: 0.7803 - val_loss: 0.4611\n",
      "Iteration 9 using SGD: Validation Accuracy = 0.7803335189819336\n",
      "Target accuracy not reached after maximum iterations.\n",
      "Final Model Validation Accuracy: 0.7987349033355713\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rahulnundlall/anaconda3/envs/ML/lib/python3.12/site-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 408us/step - accuracy: 0.7375 - loss: 0.5183\n",
      "Epoch 2/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - accuracy: 0.7735 - loss: 0.4726\n",
      "Epoch 3/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - accuracy: 0.7885 - loss: 0.4554\n",
      "Epoch 4/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.7954 - loss: 0.4458\n",
      "Epoch 5/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - accuracy: 0.7816 - loss: 0.4521\n",
      "Epoch 6/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.7830 - loss: 0.4497\n",
      "Epoch 7/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.7904 - loss: 0.4405\n",
      "Epoch 8/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.7917 - loss: 0.4322\n",
      "Epoch 9/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - accuracy: 0.7897 - loss: 0.4336\n",
      "Epoch 10/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - accuracy: 0.8013 - loss: 0.4304\n",
      "Epoch 11/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - accuracy: 0.7927 - loss: 0.4215\n",
      "Epoch 12/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - accuracy: 0.8083 - loss: 0.4094\n",
      "Epoch 13/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.8012 - loss: 0.4161\n",
      "Epoch 14/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - accuracy: 0.8067 - loss: 0.4089\n",
      "Epoch 15/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - accuracy: 0.8015 - loss: 0.4129\n",
      "Epoch 16/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step - accuracy: 0.7982 - loss: 0.4141\n",
      "Epoch 17/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - accuracy: 0.8042 - loss: 0.4118\n",
      "Epoch 18/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.7997 - loss: 0.4096\n",
      "Epoch 19/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423us/step - accuracy: 0.7989 - loss: 0.4056\n",
      "Epoch 20/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.7952 - loss: 0.4150\n",
      "Epoch 21/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - accuracy: 0.8170 - loss: 0.3898\n",
      "Epoch 22/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438us/step - accuracy: 0.8004 - loss: 0.4129\n",
      "Epoch 23/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - accuracy: 0.7903 - loss: 0.4281\n",
      "Epoch 24/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - accuracy: 0.8105 - loss: 0.4070\n",
      "Epoch 25/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - accuracy: 0.8040 - loss: 0.4058\n",
      "Epoch 26/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.8041 - loss: 0.4053\n",
      "Epoch 27/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.8025 - loss: 0.4049\n",
      "Epoch 28/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.8031 - loss: 0.4105\n",
      "Epoch 29/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - accuracy: 0.8050 - loss: 0.4054\n",
      "Epoch 30/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - accuracy: 0.8006 - loss: 0.4101\n",
      "Epoch 31/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420us/step - accuracy: 0.8094 - loss: 0.4005\n",
      "Epoch 32/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - accuracy: 0.8023 - loss: 0.4046\n",
      "Epoch 33/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step - accuracy: 0.8064 - loss: 0.4063\n",
      "Epoch 34/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.8111 - loss: 0.4011\n",
      "Epoch 35/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - accuracy: 0.8066 - loss: 0.3980\n",
      "Epoch 36/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.8108 - loss: 0.3896\n",
      "Epoch 37/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step - accuracy: 0.8130 - loss: 0.3908\n",
      "Epoch 38/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - accuracy: 0.8018 - loss: 0.4054\n",
      "Epoch 39/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.8055 - loss: 0.4044\n",
      "Epoch 40/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - accuracy: 0.8045 - loss: 0.3964\n",
      "Epoch 41/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - accuracy: 0.8093 - loss: 0.3948\n",
      "Epoch 42/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.8057 - loss: 0.4003\n",
      "Epoch 43/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422us/step - accuracy: 0.8034 - loss: 0.4034\n",
      "Epoch 44/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.8120 - loss: 0.3956\n",
      "Epoch 45/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431us/step - accuracy: 0.8131 - loss: 0.3845\n",
      "Epoch 46/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step - accuracy: 0.8082 - loss: 0.3850\n",
      "Epoch 47/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434us/step - accuracy: 0.8036 - loss: 0.3946\n",
      "Epoch 48/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - accuracy: 0.8042 - loss: 0.4018\n",
      "Epoch 49/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.8121 - loss: 0.3883\n",
      "Epoch 50/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433us/step - accuracy: 0.8099 - loss: 0.3947\n",
      "Epoch 51/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - accuracy: 0.8116 - loss: 0.3874\n",
      "Epoch 52/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - accuracy: 0.8109 - loss: 0.3990\n",
      "Epoch 53/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.8123 - loss: 0.3930\n",
      "Epoch 54/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416us/step - accuracy: 0.8011 - loss: 0.3940\n",
      "Epoch 55/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - accuracy: 0.8054 - loss: 0.3828\n",
      "Epoch 56/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - accuracy: 0.8094 - loss: 0.3912\n",
      "Epoch 57/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.8144 - loss: 0.3912\n",
      "Epoch 58/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.8148 - loss: 0.3896\n",
      "Epoch 59/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - accuracy: 0.8141 - loss: 0.3903\n",
      "Epoch 60/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418us/step - accuracy: 0.8127 - loss: 0.3958\n",
      "Epoch 61/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.8232 - loss: 0.3813\n",
      "Epoch 62/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.8101 - loss: 0.3877\n",
      "Epoch 63/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.8150 - loss: 0.3879\n",
      "Epoch 64/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - accuracy: 0.8116 - loss: 0.3909\n",
      "Epoch 65/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - accuracy: 0.8174 - loss: 0.3831\n",
      "Epoch 66/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - accuracy: 0.8089 - loss: 0.3881\n",
      "Epoch 67/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step - accuracy: 0.8092 - loss: 0.4024\n",
      "Epoch 68/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.8187 - loss: 0.3846\n",
      "Epoch 69/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - accuracy: 0.8107 - loss: 0.3896\n",
      "Epoch 70/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438us/step - accuracy: 0.8143 - loss: 0.3920\n",
      "Epoch 71/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.8085 - loss: 0.3899\n",
      "Epoch 72/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414us/step - accuracy: 0.8185 - loss: 0.3913\n",
      "Epoch 73/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.8172 - loss: 0.3879\n",
      "Epoch 74/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.8152 - loss: 0.3839\n",
      "Epoch 75/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.8108 - loss: 0.3891\n",
      "Epoch 76/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - accuracy: 0.8100 - loss: 0.3900\n",
      "Epoch 77/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - accuracy: 0.8078 - loss: 0.3995\n",
      "Epoch 78/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416us/step - accuracy: 0.8241 - loss: 0.3754\n",
      "Epoch 79/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - accuracy: 0.8146 - loss: 0.3838\n",
      "Epoch 80/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - accuracy: 0.8161 - loss: 0.3805\n",
      "Epoch 81/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - accuracy: 0.8069 - loss: 0.3901\n",
      "Epoch 82/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - accuracy: 0.8146 - loss: 0.3837\n",
      "Epoch 83/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - accuracy: 0.8130 - loss: 0.3876\n",
      "Epoch 84/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420us/step - accuracy: 0.8112 - loss: 0.3892\n",
      "Epoch 85/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - accuracy: 0.8122 - loss: 0.3819\n",
      "Epoch 86/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.8096 - loss: 0.3886\n",
      "Epoch 87/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.8151 - loss: 0.3808\n",
      "Epoch 88/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.8206 - loss: 0.3794\n",
      "Epoch 89/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.8218 - loss: 0.3804\n",
      "Epoch 90/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418us/step - accuracy: 0.8184 - loss: 0.3822\n",
      "Epoch 91/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.8134 - loss: 0.3776\n",
      "Epoch 92/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.8083 - loss: 0.3927\n",
      "Epoch 93/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.8155 - loss: 0.3887\n",
      "Epoch 94/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.8075 - loss: 0.3973\n",
      "Epoch 95/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.8094 - loss: 0.3769\n",
      "Epoch 96/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429us/step - accuracy: 0.8157 - loss: 0.3888\n",
      "Epoch 97/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - accuracy: 0.8166 - loss: 0.3833\n",
      "Epoch 98/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - accuracy: 0.8136 - loss: 0.3856\n",
      "Epoch 99/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - accuracy: 0.8229 - loss: 0.3765\n",
      "Epoch 100/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435us/step - accuracy: 0.8200 - loss: 0.3808\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "# Load and preprocess the data\n",
    "def preprocess_data(file_path, is_train=True):\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Convert binary categorical features to 0 and 1\n",
    "    binary_features = ['CryoSleep', 'VIP']\n",
    "    df[binary_features] = df[binary_features].astype(bool).astype(int)\n",
    "\n",
    "    # Extract components from 'Cabin' and treat them as separate features\n",
    "    if 'Cabin' in df.columns:\n",
    "        df[['Cabin_Deck', 'Cabin_Number', 'Cabin_Side']] = df['Cabin'].str.split('/', expand=True)\n",
    "        df['Cabin_Side'] = df['Cabin_Side'].map({'P': 1, 'S': 0})\n",
    "        df['Cabin_Number'] = pd.to_numeric(df['Cabin_Number'], errors='coerce')\n",
    "        df.drop('Cabin', axis=1, inplace=True)\n",
    "\n",
    "    # One-hot encode multi-category features\n",
    "    multi_cat_features = ['HomePlanet', 'Destination']\n",
    "    global one_hot_encoder  # Ensure the encoder is fit only once\n",
    "    if is_train:\n",
    "        one_hot_encoder = OneHotEncoder(drop='first')\n",
    "        encoded_features = one_hot_encoder.fit_transform(df[multi_cat_features])\n",
    "    else:\n",
    "        encoded_features = one_hot_encoder.transform(df[multi_cat_features])\n",
    "\n",
    "    encoded_feature_names = one_hot_encoder.get_feature_names_out(multi_cat_features)\n",
    "    encoded_features_df = pd.DataFrame(encoded_features.toarray(), columns=encoded_feature_names)\n",
    "    df = pd.concat([df, encoded_features_df], axis=1)\n",
    "    df.drop(multi_cat_features, axis=1, inplace=True)\n",
    "\n",
    "    # Imputation and Scaling for numeric features\n",
    "    numeric_features = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'Cabin_Number', 'Cabin_Side']\n",
    "    global imputer, scaler  # Ensure the imputer and scaler are fit only once\n",
    "    if is_train:\n",
    "        imputer = SimpleImputer(strategy='median')\n",
    "        scaler = StandardScaler()\n",
    "        df[numeric_features] = imputer.fit_transform(df[numeric_features])\n",
    "        df[numeric_features] = scaler.fit_transform(df[numeric_features])\n",
    "    else:\n",
    "        df[numeric_features] = imputer.transform(df[numeric_features])\n",
    "        df[numeric_features] = scaler.transform(df[numeric_features])\n",
    "\n",
    "    if is_train:\n",
    "        # Convert 'Transported' to integer (True=1, False=0) for modeling\n",
    "        df['Transported'] = df['Transported'].astype(int)\n",
    "\n",
    "    return df\n",
    "\n",
    "train_df = preprocess_data('csv_files/train.csv', is_train=True)\n",
    "test_df = preprocess_data('csv_files/test.csv', is_train=False)\n",
    "\n",
    "# Prepare features and target for the model\n",
    "features = [col for col in train_df.columns if col not in ['PassengerId', 'Name', 'Transported', 'Cabin_Deck']]\n",
    "X = train_df[features]\n",
    "y = train_df['Transported']\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Handling class imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train_smote),\n",
    "    y=y_train_smote)\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "\n",
    "# Function to create the model, now with an optimizer parameter\n",
    "def create_model(input_shape, layers, activation, dropout_rate, learning_rate, optimizer_type='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(layers[0], activation=activation, input_shape=(input_shape,)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    for layer_size in layers[1:]:\n",
    "        model.add(Dense(layer_size, activation=activation))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Choose the optimizer\n",
    "    if optimizer_type == 'sgd':\n",
    "        optimizer = SGD(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Function to train and evaluate the model\n",
    "def train_and_evaluate(model, X_train, y_train, X_val, y_val, batch_size, epochs, class_weight):\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, \n",
    "              validation_data=(X_val, y_val), class_weight=class_weight, \n",
    "              callbacks=[early_stopping])\n",
    "    val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
    "    return val_loss, val_acc\n",
    "\n",
    "# Optimization loop\n",
    "target_accuracy = 0.85\n",
    "max_iterations = 40\n",
    "current_iteration = 0\n",
    "best_val_acc = 0\n",
    "best_params = {'layers': [128, 128, 64], 'activation': 'tanh', 'dropout_rate': 0.3, 'learning_rate': 0.001}\n",
    "# Initialization outside the loop\n",
    "best_model = None\n",
    "\n",
    "while current_iteration < max_iterations:\n",
    "    # Use best parameters from previous iterations\n",
    "    layers = best_params['layers']\n",
    "    activation = best_params['activation']\n",
    "    dropout_rate = best_params['dropout_rate']\n",
    "    learning_rate = best_params['learning_rate']\n",
    "    \n",
    "    # Here you can decide to use SGD or Adam based on some condition, e.g., alternate between them\n",
    "    if current_iteration % 2 == 0:\n",
    "        optimizer_type = 'adam'\n",
    "    else:\n",
    "        optimizer_type = 'sgd'\n",
    "    # Create and train the model\n",
    "    model = create_model(input_shape=X_train_smote.shape[1], \n",
    "                         layers=layers, \n",
    "                         activation=activation, \n",
    "                         dropout_rate=dropout_rate, \n",
    "                         learning_rate=learning_rate,\n",
    "                         optimizer_type=optimizer_type)\n",
    "\n",
    "    val_loss, val_acc = train_and_evaluate(model, X_train_smote, y_train_smote, X_val, y_val, \n",
    "                                           batch_size=16, epochs=100, class_weight=class_weight_dict)\n",
    "\n",
    "    print(f'Iteration {current_iteration} using {optimizer_type.upper()}: Validation Accuracy = {val_acc}')\n",
    "\n",
    "    # Update best parameters if current model is better\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_params = {'layers': layers, 'activation': activation, 'dropout_rate': dropout_rate, 'learning_rate': learning_rate ,'optimizer_type' : optimizer_type }\n",
    "        best_model = model  \n",
    "        print(\"New best model found and saved.\")\n",
    "    # Example of implementing learning rate decay\n",
    "    if current_iteration > 0 and val_acc < best_val_acc:\n",
    "        learning_rate *= 0.9  # decay learning rate by 10% if no improvement\n",
    "\n",
    "# Example of adjusting model complexity based on performance \n",
    "    if val_acc < best_val_acc - 0.05:  # significant drop in performance\n",
    "        layers = [max(l // 2, 32) for l in layers]  # reduce complexity\n",
    "    elif val_acc > best_val_acc:\n",
    "        layers = [min(l * 2, 512) for l in layers]  # increase complexity if showing improvement\n",
    "\n",
    "    if best_val_acc >= target_accuracy:\n",
    "        print(\"Target accuracy reached.\")\n",
    "        break\n",
    "\n",
    "    current_iteration += 1\n",
    "\n",
    "# Final evaluation\n",
    "if best_val_acc < target_accuracy:\n",
    "    print(\"Target accuracy not reached after maximum iterations.\")\n",
    "    print(f\"Final Model Validation Accuracy: {best_val_acc}\")\n",
    "else:\n",
    "    print(f\"Final Model Validation Accuracy: {best_val_acc}\")\n",
    "\n",
    "model_enhanced = best_model\n",
    "# Combine the original training and validation sets for final training\n",
    "X_full, y_full = smote.fit_resample(X, y)\n",
    "\n",
    "# Create and train the final model using the best parameters\n",
    "final_model = create_model(\n",
    "    input_shape=X_full.shape[1], \n",
    "    layers=best_params['layers'], \n",
    "    activation=best_params['activation'], \n",
    "    dropout_rate=best_params['dropout_rate'], \n",
    "    learning_rate=best_params['learning_rate'], \n",
    "    optimizer_type=best_params['optimizer_type']\n",
    ")\n",
    "# Train the final model\n",
    "final_model.fit(X_full, y_full, batch_size=16, epochs=100, class_weight=class_weight_dict)\n",
    "# Save the final model\n",
    "final_model.save('model_enhanced.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the best model\n",
    "model_enhanced = load_model('model_enhanced.keras')\n",
    "X_test = test_df[features]\n",
    "\n",
    "# Assuming model_enhanced is your trained model with the best parameters\n",
    "y_pred_test_proba = model_enhanced.predict(X_test)\n",
    "y_pred_test = (y_pred_test_proba > 0.5).astype(int).flatten()\n",
    "\n",
    "# Prepare the submission dataframe\n",
    "submission_df = pd.DataFrame({\n",
    "    'PassengerId': test_df['PassengerId'],\n",
    "    'Transported': y_pred_test\n",
    "})\n",
    "\n",
    "# Convert predictions back to boolean (True/False) if necessary\n",
    "submission_df['Transported'] = submission_df['Transported'].astype(bool)\n",
    "\n",
    "# Save the submission file\n",
    "submission_df.to_csv('enhanced_tensorflow_resultzz.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "\n",
    "# Define the space of hyperparameters to search\n",
    "space = [\n",
    "    Integer(32, 512, name='layer_size'),\n",
    "    Real(0.01, 0.5, name='dropout_rate'),\n",
    "    Real(1e-4, 1e-2, prior='log-uniform', name='learning_rate')\n",
    "]\n",
    "\n",
    "# Function to optimize (we aim to minimize 1 - accuracy)\n",
    "@use_named_args(space)\n",
    "def objective(**params):\n",
    "    model = create_model(\n",
    "        input_shape=X_train_smote.shape[1], \n",
    "        layers=[params['layer_size']] * 2,  # Example: using the same size for two layers\n",
    "        activation='relu', \n",
    "        dropout_rate=params['dropout_rate'], \n",
    "        learning_rate=params['learning_rate']\n",
    "    )\n",
    "    val_loss, val_acc = train_and_evaluate(model, X_train_smote, y_train_smote, X_val, y_val, \n",
    "                                           batch_size=32, epochs=50, class_weight=class_weight_dict)\n",
    "    return 1 - val_acc  # as we need to minimize\n",
    "\n",
    "# Run Bayesian optimization\n",
    "result = gp_minimize(objective, space, n_calls=20, random_state=0)\n",
    "\n",
    "print(f\"Best parameters: {result.x}\")\n",
    "print(f\"Best validation accuracy: {1 - result.fun}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
