{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from scipy.stats import expon, reciprocal\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rahulnundlall/anaconda3/envs/ML/lib/python3.12/site-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - accuracy: 0.7297 - loss: 0.5732 - val_accuracy: 0.7677 - val_loss: 0.5038\n",
      "Epoch 2/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.7921 - loss: 0.4745 - val_accuracy: 0.7769 - val_loss: 0.4945\n",
      "Epoch 3/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375us/step - accuracy: 0.7975 - loss: 0.4731 - val_accuracy: 0.7775 - val_loss: 0.4945\n",
      "Epoch 4/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.7901 - loss: 0.4807 - val_accuracy: 0.7780 - val_loss: 0.5035\n",
      "Epoch 5/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - accuracy: 0.7914 - loss: 0.4730 - val_accuracy: 0.7803 - val_loss: 0.4915\n",
      "Epoch 6/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - accuracy: 0.7952 - loss: 0.4770 - val_accuracy: 0.7752 - val_loss: 0.4926\n",
      "Epoch 7/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.7929 - loss: 0.4672 - val_accuracy: 0.7769 - val_loss: 0.4924\n",
      "Epoch 8/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - accuracy: 0.7926 - loss: 0.4723 - val_accuracy: 0.7780 - val_loss: 0.4968\n",
      "Epoch 9/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.7937 - loss: 0.4715 - val_accuracy: 0.7809 - val_loss: 0.4884\n",
      "Epoch 10/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.8006 - loss: 0.4617 - val_accuracy: 0.7769 - val_loss: 0.4931\n",
      "Epoch 11/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.7925 - loss: 0.4718 - val_accuracy: 0.7786 - val_loss: 0.4962\n",
      "Epoch 12/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7953 - loss: 0.4670 - val_accuracy: 0.7792 - val_loss: 0.4936\n",
      "Epoch 13/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - accuracy: 0.7968 - loss: 0.4680 - val_accuracy: 0.7809 - val_loss: 0.4923\n",
      "Epoch 14/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7934 - loss: 0.4707 - val_accuracy: 0.7792 - val_loss: 0.4940\n",
      "Epoch 15/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.7949 - loss: 0.4720 - val_accuracy: 0.7798 - val_loss: 0.4886\n",
      "Epoch 16/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.7952 - loss: 0.4670 - val_accuracy: 0.7786 - val_loss: 0.4899\n",
      "Epoch 17/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - accuracy: 0.8001 - loss: 0.4576 - val_accuracy: 0.7763 - val_loss: 0.5002\n",
      "Epoch 18/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376us/step - accuracy: 0.7900 - loss: 0.4757 - val_accuracy: 0.7780 - val_loss: 0.4905\n",
      "Epoch 19/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373us/step - accuracy: 0.7924 - loss: 0.4703 - val_accuracy: 0.7780 - val_loss: 0.4910\n",
      "Epoch 20/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.8005 - loss: 0.4653 - val_accuracy: 0.7798 - val_loss: 0.4910\n",
      "Epoch 21/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376us/step - accuracy: 0.7948 - loss: 0.4638 - val_accuracy: 0.7803 - val_loss: 0.4970\n",
      "Epoch 22/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - accuracy: 0.8020 - loss: 0.4588 - val_accuracy: 0.7803 - val_loss: 0.4913\n",
      "Epoch 23/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.7953 - loss: 0.4621 - val_accuracy: 0.7780 - val_loss: 0.4899\n",
      "Epoch 24/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374us/step - accuracy: 0.7958 - loss: 0.4633 - val_accuracy: 0.7786 - val_loss: 0.4922\n",
      "Epoch 25/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371us/step - accuracy: 0.7926 - loss: 0.4637 - val_accuracy: 0.7809 - val_loss: 0.4873\n",
      "Epoch 26/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - accuracy: 0.7942 - loss: 0.4653 - val_accuracy: 0.7792 - val_loss: 0.4933\n",
      "Epoch 27/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.7940 - loss: 0.4708 - val_accuracy: 0.7780 - val_loss: 0.4926\n",
      "Epoch 28/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376us/step - accuracy: 0.7965 - loss: 0.4626 - val_accuracy: 0.7792 - val_loss: 0.4929\n",
      "Epoch 29/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376us/step - accuracy: 0.8075 - loss: 0.4488 - val_accuracy: 0.7757 - val_loss: 0.4918\n",
      "Epoch 30/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374us/step - accuracy: 0.7856 - loss: 0.4759 - val_accuracy: 0.7815 - val_loss: 0.4924\n",
      "Epoch 31/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - accuracy: 0.8124 - loss: 0.4406 - val_accuracy: 0.7792 - val_loss: 0.4966\n",
      "Epoch 32/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376us/step - accuracy: 0.7936 - loss: 0.4634 - val_accuracy: 0.7821 - val_loss: 0.4918\n",
      "Epoch 33/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374us/step - accuracy: 0.8031 - loss: 0.4543 - val_accuracy: 0.7821 - val_loss: 0.4894\n",
      "Epoch 34/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376us/step - accuracy: 0.7990 - loss: 0.4624 - val_accuracy: 0.7803 - val_loss: 0.4918\n",
      "Epoch 35/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373us/step - accuracy: 0.7943 - loss: 0.4663 - val_accuracy: 0.7815 - val_loss: 0.4928\n",
      "Epoch 36/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370us/step - accuracy: 0.8010 - loss: 0.4543 - val_accuracy: 0.7826 - val_loss: 0.4916\n",
      "Epoch 37/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372us/step - accuracy: 0.7937 - loss: 0.4682 - val_accuracy: 0.7775 - val_loss: 0.4929\n",
      "Epoch 38/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372us/step - accuracy: 0.8028 - loss: 0.4547 - val_accuracy: 0.7775 - val_loss: 0.4925\n",
      "Epoch 39/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374us/step - accuracy: 0.7969 - loss: 0.4615 - val_accuracy: 0.7809 - val_loss: 0.4935\n",
      "Epoch 40/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375us/step - accuracy: 0.8020 - loss: 0.4560 - val_accuracy: 0.7792 - val_loss: 0.4950\n",
      "Epoch 41/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375us/step - accuracy: 0.7992 - loss: 0.4606 - val_accuracy: 0.7832 - val_loss: 0.4919\n",
      "Epoch 42/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - accuracy: 0.7993 - loss: 0.4617 - val_accuracy: 0.7821 - val_loss: 0.4923\n",
      "Epoch 43/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - accuracy: 0.8024 - loss: 0.4514 - val_accuracy: 0.7798 - val_loss: 0.4892\n",
      "Epoch 44/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step - accuracy: 0.8042 - loss: 0.4531 - val_accuracy: 0.7798 - val_loss: 0.4961\n",
      "Epoch 45/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - accuracy: 0.7973 - loss: 0.4638 - val_accuracy: 0.7832 - val_loss: 0.4882\n",
      "Epoch 46/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - accuracy: 0.8000 - loss: 0.4571 - val_accuracy: 0.7832 - val_loss: 0.4913\n",
      "Epoch 47/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - accuracy: 0.8050 - loss: 0.4533 - val_accuracy: 0.7809 - val_loss: 0.4926\n",
      "Epoch 48/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.8037 - loss: 0.4488 - val_accuracy: 0.7780 - val_loss: 0.4984\n",
      "Epoch 49/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373us/step - accuracy: 0.7934 - loss: 0.4653 - val_accuracy: 0.7821 - val_loss: 0.4893\n",
      "Epoch 50/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376us/step - accuracy: 0.8024 - loss: 0.4543 - val_accuracy: 0.7821 - val_loss: 0.4896\n",
      "Epoch 51/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7947 - loss: 0.4631 - val_accuracy: 0.7821 - val_loss: 0.4915\n",
      "Epoch 52/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - accuracy: 0.8080 - loss: 0.4521 - val_accuracy: 0.7798 - val_loss: 0.4945\n",
      "Epoch 53/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.8032 - loss: 0.4553 - val_accuracy: 0.7740 - val_loss: 0.5083\n",
      "Epoch 54/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - accuracy: 0.7969 - loss: 0.4659 - val_accuracy: 0.7821 - val_loss: 0.4959\n",
      "Epoch 55/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - accuracy: 0.7962 - loss: 0.4599 - val_accuracy: 0.7803 - val_loss: 0.4889\n",
      "Epoch 56/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.8039 - loss: 0.4566 - val_accuracy: 0.7815 - val_loss: 0.4891\n",
      "Epoch 57/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375us/step - accuracy: 0.7969 - loss: 0.4598 - val_accuracy: 0.7786 - val_loss: 0.4939\n",
      "Epoch 58/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - accuracy: 0.8053 - loss: 0.4517 - val_accuracy: 0.7832 - val_loss: 0.4896\n",
      "Epoch 59/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371us/step - accuracy: 0.8009 - loss: 0.4563 - val_accuracy: 0.7798 - val_loss: 0.4916\n",
      "Epoch 60/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373us/step - accuracy: 0.7970 - loss: 0.4558 - val_accuracy: 0.7803 - val_loss: 0.4911\n",
      "Epoch 61/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376us/step - accuracy: 0.7990 - loss: 0.4553 - val_accuracy: 0.7803 - val_loss: 0.4912\n",
      "Epoch 62/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371us/step - accuracy: 0.7989 - loss: 0.4587 - val_accuracy: 0.7832 - val_loss: 0.4905\n",
      "Epoch 63/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.8072 - loss: 0.4480 - val_accuracy: 0.7803 - val_loss: 0.4895\n",
      "Epoch 64/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374us/step - accuracy: 0.7942 - loss: 0.4655 - val_accuracy: 0.7769 - val_loss: 0.5043\n",
      "Epoch 65/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374us/step - accuracy: 0.8038 - loss: 0.4458 - val_accuracy: 0.7803 - val_loss: 0.4891\n",
      "Epoch 66/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375us/step - accuracy: 0.7972 - loss: 0.4489 - val_accuracy: 0.7821 - val_loss: 0.4894\n",
      "Epoch 67/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - accuracy: 0.7965 - loss: 0.4559 - val_accuracy: 0.7821 - val_loss: 0.4907\n",
      "Epoch 68/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - accuracy: 0.8013 - loss: 0.4530 - val_accuracy: 0.7803 - val_loss: 0.4935\n",
      "Epoch 69/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - accuracy: 0.7979 - loss: 0.4581 - val_accuracy: 0.7809 - val_loss: 0.4974\n",
      "Epoch 70/70\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - accuracy: 0.7981 - loss: 0.4547 - val_accuracy: 0.7867 - val_loss: 0.4971\n",
      "55/55 - 0s - 355us/step - accuracy: 0.7867 - loss: 0.4971\n",
      "Validation Accuracy: 0.7866590023040771\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "train_df = pd.read_csv('csv_files/train.csv')\n",
    "\n",
    "# Convert 'Transported' to integer (True=1, False=0) for modeling\n",
    "train_df['Transported'] = train_df['Transported'].astype(int)\n",
    "\n",
    "# Feature engineering (if any)\n",
    "# Assuming your feature engineering steps here\n",
    "\n",
    "# Prepare features and target\n",
    "features = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'Age']  # Replace with your actual features\n",
    "X = train_df[features]\n",
    "y = train_df['Transported']\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_imputed)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=70, batch_size=32, validation_data=(X_val, y_val), verbose=1)\n",
    "# Evaluate on validation set\n",
    "val_loss, val_acc = model.evaluate(X_val, y_val, verbose=2)\n",
    "print(f'Validation Accuracy: {val_acc}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365us/step\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv('csv_files/test.csv')\n",
    "# Impute missing values\n",
    "X_test_imputed = imputer.transform(test_df[features])  # Use the same imputer as for the training data\n",
    "\n",
    "# Scale the features\n",
    "X_test_scaled = scaler.transform(X_test_imputed)  # Use the same scaler as for the training data\n",
    "# Make predictions with the TensorFlow model\n",
    "y_pred_test_proba = model.predict(X_test_scaled)\n",
    "y_pred_test = (y_pred_test_proba > 0.5).astype(int).flatten()  # Convert probabilities to binary predictions\n",
    "# Prepare the submission dataframe\n",
    "submission_df = pd.DataFrame({\n",
    "    'PassengerId': test_df['PassengerId'],\n",
    "    'Transported': y_pred_test\n",
    "})\n",
    "\n",
    "# Convert predictions back to boolean (True/False) if necessary\n",
    "submission_df['Transported'] = submission_df['Transported'].astype(bool)\n",
    "\n",
    "# Save the submission file\n",
    "submission_df.to_csv('tensorflow_result.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
